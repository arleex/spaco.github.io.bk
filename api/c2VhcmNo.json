[{"title":"Spring Cloud Stream","date":"2019-09-17T00:00:00.000Z","updated":"2019-09-17T00:00:00.000Z","content":"Spring Cloud Stream\nIntroductionSpring Cloud Stream是一种用于构建具有共享消息系统连接高度可扩展的事件驱动微服务的框架。 该框架提供了一个灵活的编程模型建立在已建立的和熟悉的Spring最佳实践，包括持续的pub / sub （消息的发布（Publish）和订阅（Subscribe）是事件驱动的经典模式），消费群体和状态分区的支持。\nAdvantage\n解耦\n扩展性\n可恢复性\n异步通信\n无缝切换消息队列选型\n\nDevelopment Environment\nSpring Boot : 2.1.7\ngradle : 5.6\nJava : jdk1.8\nKafka : kafka_2.12\nintelliji\n\nKey Words\n@Input\n类似于Consumer，消息消费者\n\n@Output\n类似于 Producer，消息生产者\n\nBinder\nBinder 是 Spring Cloud Stream 的一个抽象概念，是应用与消息中间件之间的粘合剂\n\nDestination\n通过 binder ，可以很方便的连接中间件，可以动态的改变消息的destinations（对应于 Kafka 的topic，Rabbit MQ 的 exchanges），这些都可以通过外部配置项来做到。\n\nConsumer Group\nGroup，如果使用过 Kafka 的并不会陌生。Spring Cloud Stream 的这个分组概念的意思基本和 Kafka 一致。微服务中动态的缩放同一个应用的数量以此来达到更高的处理能力是非常必须的。对于这种情况，同一个事件防止被重复消费，只要把这些应用放置于同一个 “group” 中，就能够保证消息只会被其中一个应用消费一次。\n\nPartition\n\n\nBuild Producer Client配置Gradle1234567891011121314151617dependencies &#123;    implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos;    implementation &apos;org.springframework.boot:spring-boot-starter-web&apos;    implementation &apos;org.apache.kafka:kafka-streams&apos;    implementation &apos;org.springframework.cloud:spring-cloud-function-web&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter-task&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream-binder-kafka-streams&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream-binder-kafka&apos;    compileOnly &apos;org.projectlombok:lombok&apos;    developmentOnly &apos;org.springframework.boot:spring-boot-devtools&apos;    annotationProcessor &apos;org.springframework.boot:spring-boot-configuration-processor&apos;    annotationProcessor &apos;org.projectlombok:lombok&apos;    testImplementation &apos;org.springframework.boot:spring-boot-starter-test&apos;    testImplementation &apos;org.springframework.cloud:spring-cloud-stream-test-support&apos;&#125;\n配置 application.properties123456server.port=8085spring.application.name=stream-outputspring.cloud.stream.kafka.binder.brokers=localhost:9092spring.cloud.stream.kafka.binder.auto-create-topics=truespring.cloud.stream.bindings.refuel.destination=destination-demospring.cloud.stream.bindings.refuel.content-type=application/json\nCode : Producer控制器提供外部访问接口，调取Producer,Producer 通过 消息通道 生产消息，\n自定义消息通道 Channel123456789import org.springframework.cloud.stream.annotation.Output;import org.springframework.messaging.MessageChannel;public interface RefuelChannel &#123;    String OUTPUT = \"refuel\";    @Output(OUTPUT)    MessageChannel output();&#125;\n自定义 Producer1234567891011121314151617181920import com.spaco.streamoutput.channel.RefuelChannel;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.messaging.support.MessageBuilder;@EnableBinding(RefuelChannel.class)public class RefuelProducer &#123;    private RefuelChannel refuelChannel;    \t@Autowired    public RefuelProducer(RefuelChannel refuelChannel)    &#123;        this.refuelChannel = refuelChannel;    &#125;    public void send(String message)    &#123;        refuelChannel.output().send(MessageBuilder.withPayload(message).build());    &#125;&#125;\nController1234567891011121314151617181920212223import com.spaco.streamoutput.producer.RefuelProducer;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class RefuelController &#123;    private RefuelProducer refuelProducer;    public RefuelController(RefuelProducer refuelProducer)&#123;        this.refuelProducer = refuelProducer;    &#125;    @GetMapping(\"/refuel\")    public String send(@RequestBody Object message)    &#123;        log.error(\"sent message: &#123;&#125;\",message);        this.refuelProducer.send(message);        return message.toString();    &#125;&#125;\n启动服务Test Cases命令行执行\n1curl -X  GET http://127.0.0.1:8085/refuel -H 'Content-Type: application/json' -d '&#123;\"message\":\"hello\"&#125;'\n可以看到接口返回值，且消息已经发送成功\n1&#123;message=hello&#125;\n测试通过\nBuild Consumer Client配置Gradle123456789101112131415161718dependencies &#123;    implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos;    implementation &apos;org.springframework.boot:spring-boot-starter-web&apos;    implementation &apos;org.springframework.boot:spring-boot-starter-data-mongodb&apos;    implementation &apos;org.apache.kafka:kafka-streams&apos;    implementation &apos;org.springframework.cloud:spring-cloud-function-web&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter-task&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream-binder-kafka-streams&apos;    implementation &apos;org.springframework.cloud:spring-cloud-stream-binder-kafka&apos;    compileOnly &apos;org.projectlombok:lombok&apos;    developmentOnly &apos;org.springframework.boot:spring-boot-devtools&apos;    annotationProcessor &apos;org.springframework.boot:spring-boot-configuration-processor&apos;    annotationProcessor &apos;org.projectlombok:lombok&apos;    testImplementation &apos;org.springframework.boot:spring-boot-starter-test&apos;    testImplementation &apos;org.springframework.cloud:spring-cloud-stream-test-support&apos;&#125;\n配置 application.properties12345678server.port=8086spring.application.name=stream-inputspring.cloud.stream.kafka.binder.brokers=localhost:9092spring.cloud.stream.kafka.binder.auto-create-topics=true#spring.cloud.stream.bindings.message-channel.destination=destination-demospring.cloud.stream.bindings.refuel.destination=destination-demospring.cloud.stream.bindings.refuel.content-type=application/jsonspring.cloud.stream.bindings.refuel.group=group-name\nCode : Consumer自定义消息通道 Channel123456789import org.springframework.cloud.stream.annotation.Input;import org.springframework.messaging.MessageChannel;public interface RefuelChannel &#123;    String INPUT = \"refuel\";    @Input(INPUT)    MessageChannel input();&#125;\n自定义Consumer12345678910111213package com.spaco.streaminput.consumer;import com.spaco.streaminput.channel.RefuelChannel;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;@EnableBinding(RefuelChannel.class)public class RefuelConsumer&#123;    @StreamListener(RefuelChannel.INPUT)    public void receive(Object payload) &#123;        System.out.println(\"received message: \"+ payload);    &#125;&#125;\n启动服务Test Casesproducer 信息发送成功后，可以在 consumer 的Console 打印台看到如下信息\n1received message: &#123;\"message\":\"hello\"&#125;\n测试通过，效果与我们希望的结果一致。producer 发送消息成功后，consumer 消费消息。\nQuestions\n重复执行\n\n执行日志，记录每个消费操作执行的结果，失败可以通过定时任务重试\n\n保证消息不丢失\n\n幂等性设计\n\n\nReferences\n项目Demo地址\n官方文档\nSpringCloud实战9-Stream消息驱动\n微服务中消息总线架构设计应用\n构建消息驱动微服务的框架 Spring Cloud Stream\nSpring Cloud Stream 体系及原理介绍\n\n","plink":"https://spaco.github.io/post/spring-cloud-stream/"},{"title":"Implementing the openssl_encrypt method of PHP using Java","date":"2019-09-11T00:00:00.000Z","updated":"2019-09-11T00:00:00.000Z","content":"使用 Java 实现 PHP openssl_encrypt加密方法\nPHP Implement123456789101112   public static function encrypt($input, $key)   &#123;       $data = openssl_encrypt($input, 'AES-128-ECB', $key, OPENSSL_RAW_DATA);       $data = base64_encode($data);       return $data;   &#125;   public static function decrypt($input, $key)&#123;\t$decrypted = openssl_decrypt(base64_decode($input), 'AES-128-ECB', $key, OPENSSL_RAW_DATA);\treturn $decrypted;&#125;\nJava Implement123456789101112131415public static String encrypt(String data, String password) throws Exception &#123;    byte[] key = new byte[16];    for (int i = 0; i &lt; 16; i++) &#123;        if (i &lt; password.getBytes().length) &#123;            key[i] = password.getBytes()[i];        &#125; else &#123;            key[i] = 0;        &#125;    &#125;    Cipher cipher = Cipher.getInstance(\"AES/ECB/PKCS5Padding\");    cipher.init(Cipher.ENCRYPT_MODE, new SecretKeySpec(key, \"AES\"));    return Base64.getEncoder().encodeToString(cipher.doFinal(data.getBytes()));&#125;\n注意： 如果采用的是 AES-128-CBC，那么 Java Implement 则要改成\n1234567891011121314151617    public static String encrypt(String data, String password, String iv) throws Exception &#123;        byte[] key = new byte[16];        for (int i = 0; i &lt; 16; i++) &#123;            if (i &lt; password.getBytes().length) &#123;                key[i] = password.getBytes()[i];            &#125; else &#123;                key[i] = 0;            &#125;        &#125;        Cipher cipher = Cipher.getInstance(\"AES/CBC/PKCS5Padding\");//        byte[] ivs= &#123;0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0&#125;;        cipher.init(Cipher.ENCRYPT_MODE, new SecretKeySpec(key, \"AES\"),                new IvParameterSpec(iv.getBytes()));        return  Base64.getEncoder().encodeToString(cipher.doFinal(data.getBytes()));    &#125;","plink":"https://spaco.github.io/post/Implementing-the-openssl_encrypt-method-of-PHP-using-Java/"},{"title":"Spring Cloud Netflix Eureka","date":"2019-09-03T00:00:00.000Z","updated":"2019-09-03T00:00:00.000Z","content":"Spring Cloud Netflix EurekaIntroductionService Discovery是基于微服务的体系结构的关键原则之一。尝试手动配置每个客户端或某种形式的约定可能很难做到并且可能很脆弱。Eureka是Netflix服务发现服务器和客户端。可以配置和部署服务器以使其具有高可用性，每个服务器将注册服务的状态复制到其他服务器\nDevelopment Environment\nSpring Boot : 2.1.7\ngradle : 5.6\nJava : jdk1.8\n\nKey Words\nEureka Server\nEureka Client\n\nBuild Eureka Server配置Gradle","plink":"https://spaco.github.io/post/spring-cloud-Netflix-eureka/"},{"title":"Spring Cloud Config","date":"2019-09-01T00:00:00.000Z","updated":"2019-09-01T00:00:00.000Z","content":"Spring Cloud ConfigIntroductionSpring Cloud Config为分布式系统中的外部化配置提供服务器端和客户端支持。使用Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器上的概念映射与Spring Environment和PropertySource抽象，因此它们非常适合Spring应用程序，但可以与任何语言运行的任何应用程序一起使用。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容。服务器存储后端的默认实现使用git，因此它可以轻松支持配置环境的标签版本，以及可用于管理内容的各种工具。添加替代实现并使用Spring配置插入它们很容易。\nDevelopment Environment\nSpring Boot : 2.1.7\ngradle : 5.6\nJava : jdk1.8\n\nKey Words\nConfig Server\nConfig Client\nbootstrap.[yml | properties]\nzookeeper\nvault\nconsul\n\nBuild Config Server配置Gradle12345678910implementation 'org.springframework.boot:spring-boot-starter-web'implementation 'org.springframework.cloud:spring-cloud-config-server'implementation 'org.springframework.cloud:spring-cloud-function-web'implementation 'org.springframework.cloud:spring-cloud-starter'implementation 'org.springframework.cloud:spring-cloud-starter-task'compileOnly 'org.projectlombok:lombok'developmentOnly 'org.springframework.boot:spring-boot-devtools'annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'annotationProcessor 'org.projectlombok:lombok'testImplementation 'org.springframework.boot:spring-boot-starter-test'\n配置 application.properties12server.port=8081spring.cloud.config.server.git.uri=https://github.com/spaco/spring-cloud-config-repo-samples\ngit仓库文件如下：\n12\n配置启动器主要是@EnableConfigServer注解\n123456789@SpringBootApplication@EnableConfigServerpublic class ConfigServerApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(ConfigServerApplication.class, args);\t&#125;&#125;\n启动服务Test Cases在测试之前，开发者需要知道Config Server寻找配置文件的规则\n开发者请求 Config Server 的端点可以获取配置文件的内容，请求地址与配置文件的映射如下：\n12345/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;]/&#123;application&#125;-&#123;profile&#125;.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties\napplication  profile  label分别对应着什么呢？\n\napplication 意味着项目名称，可以通过spring.cloud.config.name配置修改\nprofile 意味着项目环境，测试服可以配置为dev，正式服可以配置为pro，可以通过spring.cloud.config.profile配置修改\nlabel 意味着git 分支版本，如果是使用的配置文件是本地，那么是无效的，可以通过spring.cloud.config.label配置修改，默认是 master\n\n获取配置文件我们采用两种方式，一种@Value,一种Environment\nTest 1 ：请求 application+profilecurl localhost:8081/config-client/dev\n12application = config-clientprofile = dev\n请求结果如下\n12345678910111213141516171819202122232425262728293031323334353637383940414243&#123;    \"name\": \"config-client\",    \"profiles\": [        \"dev\"    ],    \"label\": null,    \"version\": \"dd39228cf1b62a2a12f6afb26fc49dda0d8cd451\",    \"state\": null,    \"propertySources\": [        &#123;            \"name\": \"https://github.com/spaco/spring-cloud-config-repo-samples/config-client-dev.properties\",            \"source\": &#123;                \"filename\": \"config-client-dev.properties\",                \"config-client-dev.properties\": \"config-client-dev.properties\",                \"config-client-dev.unique\": \"config-client-dev.properties\"            &#125;        &#125;,        &#123;            \"name\": \"https://github.com/spaco/spring-cloud-config-repo-samples/config-client-dev.yml\",            \"source\": &#123;                \"filename\": \"config-client-dev.yml\",                \"config-client-dev.yml\": \"config-client-dev.yml\",                \"config-client-dev.unique\": \"config-client-dev.yml\"            &#125;        &#125;,        &#123;            \"name\": \"https://github.com/spaco/spring-cloud-config-repo-samples/config-client.properties\",            \"source\": &#123;                \"filename\": \"config-client.properties\",                \"config-client.properties\": \"config-client.properties\",                \"config-client.unique\": \"config-client.properties\"            &#125;        &#125;,        &#123;            \"name\": \"https://github.com/spaco/spring-cloud-config-repo-samples/config-client.yml\",            \"source\": &#123;                \"filename\": \"config-client.yml\",                \"config-client.yml\": \"config-client.yml\",                \"config-client.unique\": \"config-client.yml\"            &#125;        &#125;    ]&#125;\n总结：共获得 config-client-dev.properties config-client-dev.yml config-client.properties config-client.yml 的配置信息，不仅会得到配置信息，还存在 git 版本信息\nTest 2 ：请求 application+profile指定文件 .yml | .properties1curl localhost:8081/config-client-dev.yml\n请求结果如下：\n123456789config-client-dev:  properties: config-client-dev.properties  unique: config-client-dev.properties  yml: config-client-dev.ymlconfig-client:  properties: config-client.properties  unique: config-client.properties  yml: config-client.ymlfilename: config-client-dev.properties\n总结： 共获得 config-client-dev.properties config-client-dev.yml config-client.properties config-client.yml 的配置信息。.properties 会覆盖 .yml 配置信息，请求指定文件功能无效，当然，一般来说，不会存在 .yml 与 .properties共存的结果\nBuild Config Client当application.properties配置spring.profiles.active=dev 并且本地配置文件application-dev.properties存在，application-dev.properties配置的优先级是低于远程配置的，即会被覆盖\n配置Gradle123456789101112dependencies &#123;    implementation &apos;org.springframework.boot:spring-boot-starter-web&apos;    implementation &apos;org.springframework.cloud:spring-cloud-function-web&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter-config&apos;    implementation &apos;org.springframework.cloud:spring-cloud-starter-task&apos;    compileOnly &apos;org.projectlombok:lombok&apos;    developmentOnly &apos;org.springframework.boot:spring-boot-devtools&apos;    annotationProcessor &apos;org.springframework.boot:spring-boot-configuration-processor&apos;    annotationProcessor &apos;org.projectlombok:lombok&apos;    testImplementation &apos;org.springframework.boot:spring-boot-starter-test&apos;&#125;\n配置 application.properties1server.port=8082\n配置 bootstrap.properties重点：关于 Spring Cloud Config 的配置需要在 bootstrap.properties中配置\n12345678# 配置中心的具体地址，即 config-serverspring.cloud.config.uri=http://localhost:8081# 对应 &#123;application&#125; 部分spring.cloud.config.name=config-client# 对应 &#123;profile&#125; 部分spring.cloud.config.profile=dev# 对应 &#123;label&#125; 部分，即 Git 的分支。如果配置中心使用的是本地存储，则该参数无用spring.cloud.config.label=master\n原因：\n1而现在我们把获取配置内容的 config client 相关配置放在了 application.properties 中，这样是不是就有点不对了，因为这里会出现一个先后顺序的问题。如果我们把配置放在了 application.properties 中，那么它会先去加载 bootstrap.properties中 的配置属性(如果没有，会加载默认配置)，假如我们在 application.properties 中配置的 uri 端口是 8081，那么它将不会被应用，还是默认的 8888 端口\n123Spring Cloud 有一个 引导上下文 的概念，它是主应用程序的父上下文，这个引导上下文负责从外部源（配置服务器，如Config Server）加载配置属性，及解密外部配置文件中的属性。主应用程序加载的是 application.(properties/yml) 中的属性，引导上下文加载 bootstrap.(properties/yml) 中的属性。这两个上下文共享一个Environment，但配置在 boostrap.* 中的属性有更高的优先级，因此默认情况下不能被本地配置覆盖。设置 spring.cloud.bootstrap.enabled=false 可以禁用引导过程\n不在bootstrap.properties配置的错误示例\n1234567891011# 将所有配置项 写入application.properties中server.port=8082# 配置中心的具体地址，即 config-serverspring.cloud.config.uri=http://localhost:8081# 对应 &#123;application&#125; 部分spring.cloud.config.name=config-client# 对应 &#123;profile&#125; 部分spring.cloud.config.profile=dev# 对应 &#123;label&#125; 部分，即 Git 的分支。如果配置中心使用的是本地存储，则该参数无用spring.cloud.config.label=master\n项目编译时会报错：找不到目标文件，默认启动8888端口\n1234c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888c.c.c.ConfigServicePropertySourceLocator : Connect Timeout Exception on Url - http://localhost:8888. Will be trying the next url if availablec.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for &quot;http://localhost:8888/config-client/dev/master&quot;: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)c.s.c.ConfigClientApplication: No active profile set, falling back to default profiles: default\n控制器123456789101112131415161718192021222324252627package com.spaco.configclient;import org.springframework.beans.factory.annotation.Value;import org.springframework.core.env.Environment;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class IndexController &#123;    @Value(\"$&#123;filename&#125;\")    private String filename;    private final Environment environment;    public IndexController(Environment environment) &#123;        this.environment = environment;    &#125;    @GetMapping(\"/filename\")    public String filename()&#123;        return \"filename is :\"+filename;    &#125;    @GetMapping(\"/filename-env\")    public String filename_env()&#123;        return environment.getProperty(\"filename\",\"undefine\");    &#125;&#125;\n启动服务启动内容：\n1234Fetching config from server at : http://localhost:8081Located environment: name=config-client, profiles=[dev], label=master, version=dd39228cf1b62a2a12f6afb26fc49dda0d8cd451, state=nullLocated property source: CompositePropertySource &#123;name='configService', propertySources=[MapPropertySource &#123;name='configClient'&#125;, MapPropertySource &#123;name='https://github.com/spaco/spring-cloud-config-repo-samples/config-client-dev.properties'&#125;, MapPropertySource &#123;name='https://github.com/spaco/spring-cloud-config-repo-samples/config-client-dev.yml'&#125;, MapPropertySource &#123;name='https://github.com/spaco/spring-cloud-config-repo-samples/config-client.properties'&#125;, MapPropertySource &#123;name='https://github.com/spaco/spring-cloud-config-repo-samples/config-client.yml'&#125;]&#125;No active profile set, falling back to default profiles: default\nTest Cases1curl localhost:8082/filename\n1filename is :config-client-dev.properties\n1curl localhost:8082/filename-env\n1config-client-dev.properties\nConfig Refresh ： ManualSpring Cloud config强大的地方就在可以动态刷新服务的配置信息。然而，Spring Boot应用只能在服务启动的时候才能加载它们的配置信息，所以在Config Server对服务的配置做出的变更，Config Client 服务没办法主动去获取新的配置。所以Spring Boot提供一个@RefreshScope注解来解决这一问题，使用该注解后，开发团队可以使用/actuator/refresh来让应用主动重新读取配置信息。下面是@RefreshScope注解的使用方法：\n配置Gradle1234# 增加依赖 spring-boot-starter-actuatordependencies &#123;    implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos;&#125;\n配置 @RefreshScope 注解：于 Config Client Controller1234567891011121314151617181920212223242526272829package com.spaco.configclient;import org.springframework.beans.factory.annotation.Value;import org.springframework.core.env.Environment;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.cloud.context.config.annotation.RefreshScope;@RestController@RefreshScopepublic class IndexController &#123;    @Value(\"$&#123;filename&#125;\")    private String filename;    private final Environment environment;    public IndexController(Environment environment) &#123;        this.environment = environment;    &#125;    @GetMapping(\"/filename\")    public String filename()&#123;        return \"filename is :\"+filename;    &#125;    @GetMapping(\"/filename-env\")    public String filename_env()&#123;        return environment.getProperty(\"filename\",\"undefine\");    &#125;&#125;\n启动服务Test Cases在不改变Git配置的情况下，调取refeash接口\n1curl -X POST http://localhost:8082/actuator/refresh\n1[]\n结果：空数据，无Git配置修改\n调取 curl localhost:8082/filename\n1filename is :config-client-dev.properties\n更新config-client-dev.properties配置文件，更新filename属性\n1filename=config-client-dev.properties updated\n调取refeash接口:\n1curl -X POST http://localhost:8082/actuator/refresh\n1[\"config.client.version\",\"filename\"]\n结果：返回修改的参数名\n调取 curl localhost:8082/filename\n1filename is :config-client-dev.properties updated\n结果：在不重启服务的情况下，更新的配置已生效\nReferences\nActuator endpoints\n\n\n","plink":"https://spaco.github.io/post/spring-cloud-config/"},{"title":"Java basic grammar","date":"2019-08-21T00:00:00.000Z","updated":"2019-08-21T00:00:00.000Z","content":"Java basic grammar\nJavaBasic grammar编写 Java 程序时，应注意以下几点：\n\n大小写敏感：Java 是大小写敏感的，这就意味着标识符 Hello 与 hello 是不同的。\n类名：对于所有的类来说，类名的首字母应该大写。如果类名由若干单词组成，那么每个单词的首字母应该大写，例如 MyFirstJavaClass。\n方法名：所有的方法名都应该以小写字母开头。如果方法名含有若干单词，则后面的每个单词首字母大写。\n源文件名：源文件名必须和类名相同。当保存文件的时候，你应该使用类名作为文件名保存（切记 Java 是大小写敏感的），文件名的后缀为 .java。（如果文件名和类名不相同则会导致编译错误）。\n主方法入口：所有的 Java 程序由 public static void main(String []args) 方法开始执行。\n\n标识符Java 所有的组成部分都需要名字。类名、变量名以及方法名都被称为标识符。关于 Java 标识符，有以下几点需要注意：\n\n所有的标识符都应该以字母（A-Z 或者 a-z）,美元符（$）、或者下划线（_）开始\n首字符之后可以是字母（A-Z 或者 a-z）,美元符（$）、下划线（_）或数字的任何字符组合\n关键字不能用作标识符\n标识符是大小写敏感的\n合法标识符举例：age、$salary、_value、__1_value\n非法标识符举例：123abc、-salary\n\nJava 修饰符像其他语言一样，Java可以使用修饰符来修饰类中方法和属性。主要有两类修饰符：\n\n访问控制修饰符 : default, public , protected, private\n非访问控制修饰符 : final, abstract, static, synchronized\n\nJava 变量Java 中主要有如下几种类型的变量\n\n局部变量\n类变量（静态变量）\n成员变量（非静态变量）\n\nJava 枚举Java 5.0引入了枚举，枚举限制变量只能是预先设定好的值。使用枚举可以减少代码中的 bug。例如，我们为果汁店设计一个程序，它将限制果汁为小杯、中杯、大杯。这就意味着它不允许顾客点除了这三种尺寸外的果汁。1234567891011class FreshJuice &#123;   enum FreshJuiceSize&#123; SMALL, MEDIUM , LARGE &#125;   FreshJuiceSize size;&#125; public class FreshJuiceTest &#123;   public static void main(String []args)&#123;      FreshJuice juice = new FreshJuice();      juice.size = FreshJuice.FreshJuiceSize.MEDIUM  ;   &#125;&#125;\nJava 关键字\n\n\n类别\n关键字\n说明\n\n\n\n\n访问控制\nprivate\n私有的\n\n\nprotected\n受保护的\n\n\n\npublic\n公共的\n\n\n\n类、方法和变量修饰符\nabstract\n声明抽象\n\n\nclass\n类\n\n\n\nextends\n扩充,继承\n\n\n\nfinal\n最终值,不可改变的\n\n\n\nimplements\n实现（接口）\n\n\n\ninterface\n接口\n\n\n\nnative\n本地，原生方法（非 Java 实现）\n\n\n\nnew\n新,创建\n\n\n\nstatic\n静态\n\n\n\nstrictfp\n严格,精准\n\n\n\nsynchronized\n线程,同步\n\n\n\ntransient\n短暂\n\n\n\nvolatile\n易失\n\n\n\n程序控制语句\nbreak\n跳出循环\n\n\ncase\n定义一个值以供 switch 选择\n\n\n\ncontinue\n继续\n\n\n\ndefault\n默认\n\n\n\ndo\n运行\n\n\n\nelse\n否则\n\n\n\nfor\n循环\n\n\n\nif\n如果\n\n\n\ninstanceof\n实例\n\n\n\nreturn\n返回\n\n\n\nswitch\n根据值选择执行\n\n\n\nwhile\n循环\n\n\n\n错误处理\nassert\n断言表达式是否为真\n\n\ncatch\n捕捉异常\n\n\n\nfinally\n有没有异常都执行\n\n\n\nthrow\n抛出一个异常对象\n\n\n\nthrows\n声明一个异常可能被抛出\n\n\n\ntry\n捕获异常\n\n\n\n包相关\nimport\n引入\n\n\npackage\n包\n\n\n\n基本类型\nboolean\n布尔型\n\n\nbyte\n字节型\n\n\n\nchar\n字符型\n\n\n\ndouble\n双精度浮点\n\n\n\nfloat\n单精度浮点\n\n\n\nint\n整型\n\n\n\nlong\n长整型\n\n\n\nshort\n短整型\n\n\n\n变量引用\nsuper\n父类,超类\n\n\nthis\n本类\n\n\n\nvoid\n无返回值\n\n\n\n保留关键字\ngoto\n是关键字，但不能使用\n\n\nconst\n是关键字，但不能使用\n\n\n\nnull\n空\n\n\n\nJava 空行空白行或者有注释的行，Java 编译器都会忽略掉。\n继承在 Java 中，一个类可以由其他类派生。如果你要创建一个类，而且已经存在一个类具有你所需要的属性或方法，那么你可以将新创建的类继承该类。利用继承的方法，可以重用已存在类的方法和属性，而不用重写这些代码。被继承的类称为超类（super class），派生类称为子类（subclass）。\n接口在 Java 中，接口可理解为对象间相互通信的协议。接口在继承中扮演着很重要的角色。接口只定义派生要用到的方法，但是方法的具体实现完全取决于派生类。\nJava 源程序与编译型运行区别","plink":"https://spaco.github.io/post/Java-basic-grammar/"},{"title":"java exception","date":"2019-08-20T00:00:00.000Z","updated":"2019-08-20T00:00:00.000Z","content":"Java 异常\nJava ExceptionIntroduction异常是程序中的一些错误，但并不是所有的错误都是异常，并且错误有时候是可以避免的。比如说，你的代码少了一个分号，那么运行出来结果是提示是错误 java.lang.Error；如果你用System.out.println(11/0)，那么你是因为你用0做了除数，会抛出 java.lang.ArithmeticException 的异常。异常发生的原因有很多，通常包含以下几大类：\n\n用户输入了非法数据。\n要打开的文件不存在。\n网络通信时连接中断，或者JVM内存溢出。\n\n这些异常有的是因为用户错误引起，有的是程序错误引起的，还有其它一些是因为物理错误引起的。-要理解Java异常处理是如何工作的，你需要掌握以下三种类型的异常：\n\n检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。\n运行时异常： 运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。\n错误： 错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。\n\nException Level所有的异常类是从 java.lang.Exception 类继承的子类。Exception 类是 Throwable 类的子类。除了Exception类外，Throwable还有一个子类Error 。Java 程序通常不捕获错误。错误一般发生在严重故障时，它们在Java程序处理的范畴之外。Error 用来指示运行时环境发生的错误。例如，JVM 内存溢出。一般地，程序不会从错误中恢复。异常类有两个主要的子类：IOException 类和 RuntimeException 类。\nJava Built-in Exceptionsava 语言定义了一些异常类在 java.lang 标准包中。\n标准运行时异常类的子类是最常见的异常类。由于 java.lang 包是默认加载到所有的 Java 程序的，所以大部分从运行时异常类继承而来的异常都可以直接使用。\nJava 根据各个类库也定义了一些其他的异常，下面的表中列出了 Java 的非检查性异常。\n\n\n\n异常\n描述\n\n\n\n\nArithmeticException\n当出现异常的运算条件时，抛出此异常。例如，一个整数”除以零”时，抛出此类的一个实例。\n\n\nArrayIndexOutOfBoundsException\n用非法索引访问数组时抛出的异常。如果索引为负或大于等于数组大小，则该索引为非法索引。\n\n\nArrayStoreException\n试图将错误类型的对象存储到一个对象数组时抛出的异常。\n\n\nClassCastException\n当试图将对象强制转换为不是实例的子类时，抛出该异常。\n\n\nIllegalArgumentException\n抛出的异常表明向方法传递了一个不合法或不正确的参数。\n\n\nIllegalMonitorStateException\n抛出的异常表明某一线程已经试图等待对象的监视器，或者试图通知其他正在等待对象的监视器而本身没有指定监视器的线程。\n\n\nIllegalStateException\n在非法或不适当的时间调用方法时产生的信号。换句话说，即 Java 环境或 Java 应用程序没有处于请求操作所要求的适当状态下。\n\n\nIllegalThreadStateException\n线程没有处于请求操作所要求的适当状态时抛出的异常。\n\n\nIndexOutOfBoundsException\n指示某排序索引（例如对数组、字符串或向量的排序）超出范围时抛出。\n\n\nNegativeArraySizeException\n如果应用程序试图创建大小为负的数组，则抛出该异常。\n\n\nNullPointerException\n当应用程序试图在需要对象的地方使用 null 时，抛出该异常\n\n\nNumberFormatException\n当应用程序试图将字符串转换成一种数值类型，但该字符串不能转换为适当格式时，抛出该异常。\n\n\nSecurityException\n由安全管理器抛出的异常，指示存在安全侵犯。\n\n\nStringIndexOutOfBoundsException\n此异常由 String 方法抛出，指示索引或者为负，或者超出字符串的大小。\n\n\nUnsupportedOperationException\n当不支持请求的操作时，抛出该异常。\n\n\n\n下面的表中列出了 Java 定义在 java.lang 包中的检查性异常类。\n\n\n\n异常\n描述\n\n\n\n\nClassNotFoundException\n应用程序试图加载类时，找不到相应的类，抛出该异常。\n\n\nCloneNotSupportedException\n当调用 Object 类中的 clone 方法克隆对象，但该对象的类无法实现 Cloneable 接口时，抛出该异常。\n\n\nIllegalAccessException\n拒绝访问一个类的时候，抛出该异常。\n\n\nInstantiationException\n当试图使用 Class 类中的 newInstance 方法创建一个类的实例，而指定的类对象因为是一个接口或是一个抽象类而无法实例化时，抛出该异常。\n\n\nInterruptedException\n一个线程被另一个线程中断，抛出该异常。\n\n\nNoSuchFieldException\n请求的变量不存在\n\n\nNoSuchMethodException\n请求的方法不存在\n\n\n\nException Functions下面的列表是 Throwable 类的主要方法:\n\n\n\n序号\n方法及说明\n\n\n\n\n1\npublic String getMessage() 返回关于发生的异常的详细信息。这个消息在Throwable 类的构造函数中初始化了。\n\n\n2\npublic Throwable getCause() 返回一个Throwable 对象代表异常原因。\n\n\n3\npublic String toString() 使用getMessage()的结果返回类的串级名字。\n\n\n4\npublic void printStackTrace() 打印toString()结果和栈层次到System.err，即错误输出流。\n\n\n5\npublic StackTraceElement [] getStackTrace() 返回一个包含堆栈层次的数组。下标为0的元素代表栈顶，最后一个元素代表方法调用堆栈的栈底。\n\n\n6\npublic Throwable fillInStackTrace() 用当前的调用栈层次填充Throwable 对象栈层次，添加到栈层次任何先前信息中。\n\n\n\nCatch Exception使用 try 和 catch 关键字可以捕获异常。try/catch 代码块放在异常可能发生的地方。\ntry/catch代码块中的代码称为保护代码，使用 try/catch 的语法如下：\n1234567try&#123;   // 程序代码&#125;catch(ExceptionName e1)&#123;   //Catch 块&#125;\nCatch 语句包含要捕获异常类型的声明。当保护代码块中发生一个异常时，try 后面的 catch 块就会被检查。如果发生的异常包含在 catch 块中，异常会被传递到该 catch 块，这和传递一个参数到方法是一样。\n下面的例子中声明有两个元素的一个数组，当代码试图访问数组的第三个元素的时候就会抛出一个异常。\n1234567891011121314// 文件名 : ExcepTest.javaimport java.io.*;public class ExcepTest&#123;    public static void main(String args[])&#123;      try&#123;         int a[] = new int[2];         System.out.println(\"Access element three :\" + a[3]);      &#125;catch(ArrayIndexOutOfBoundsException e)&#123;         System.out.println(\"Exception thrown  :\" + e);      &#125;      System.out.println(\"Out of the block\");   &#125;&#125;\n以上代码编译运行输出结果如下：\n12Exception thrown  :java.lang.ArrayIndexOutOfBoundsException: 3Out of the block\n\n多重捕获块一个 try 代码块后面跟随多个 catch 代码块的情况就叫多重捕获。多重捕获块的语法如下所示：\n123456789try&#123;   // 程序代码&#125;catch(异常类型1 异常的变量名1)&#123;  // 程序代码&#125;catch(异常类型2 异常的变量名2)&#123;  // 程序代码&#125;catch(异常类型2 异常的变量名2)&#123;  // 程序代码&#125;\n上面的代码段包含了 3 个 catch块。可以在 try 语句后面添加任意数量的 catch 块。如果保护代码中发生异常，异常被抛给第一个 catch 块。如果抛出异常的数据类型与 ExceptionType1 匹配，它在这里就会被捕获。如果不匹配，它会被传递给第二个 catch 块。如此，直到异常被捕获或者通过所有的 catch 块。\n实例\n该实例展示了怎么使用多重 try/catch。12345678910try &#123;    file = new FileInputStream(fileName);    x = (byte) file.read();&#125; catch(FileNotFoundException f) &#123; // Not valid!    f.printStackTrace();    return -1;&#125; catch(IOException i) &#123;    i.printStackTrace();    return -1;&#125;\nthrows/throw 关键字：如果一个方法没有捕获到一个检查性异常，那么该方法必须使用 throws 关键字来声明。throws 关键字放在方法签名的尾部。也可以使用 throw 关键字抛出一个异常，无论它是新实例化的还是刚捕获到的。下面方法的声明抛出一个 RemoteException 异常：\n12345678910import java.io.*;public class className&#123;  public void deposit(double amount) throws RemoteException  &#123;    // Method implementation    throw new RemoteException();  &#125;  //Remainder of class definition&#125;\n一个方法可以声明抛出多个异常，多个异常之间用逗号隔开。例如，下面的方法声明抛出 RemoteException 和 InsufficientFundsException：12345678910import java.io.*;public class className&#123;   public void withdraw(double amount) throws RemoteException,                              InsufficientFundsException   &#123;       // Method implementation   &#125;   //Remainder of class definition&#125;\nfinally关键字finally 关键字用来创建在 try 代码块后面执行的代码块。无论是否发生异常，finally 代码块中的代码总会被执行。在 finally 代码块中，可以运行清理类型等收尾善后性质的语句。finally 代码块出现在 catch 代码块最后，语法如下：\n123456789try&#123;  // 程序代码&#125;catch(异常类型1 异常的变量名1)&#123;  // 程序代码&#125;catch(异常类型2 异常的变量名2)&#123;  // 程序代码&#125;finally&#123;  // 程序代码&#125;\n实例\n12345678910111213141516// ExcepTest.java 文件public class ExcepTest&#123;  public static void main(String args[])&#123;    int a[] = new int[2];    try&#123;       System.out.println(\"Access element three :\" + a[3]);    &#125;catch(ArrayIndexOutOfBoundsException e)&#123;       System.out.println(\"Exception thrown  :\" + e);    &#125;    finally&#123;       a[0] = 6;       System.out.println(\"First element value: \" +a[0]);       System.out.println(\"The finally statement is executed\");    &#125;  &#125;&#125;\n以上实例编译运行结果如下：\n123Exception thrown  :java.lang.ArrayIndexOutOfBoundsException: 3First element value: 6The finally statement is executed\n注意下面事项：\n\ncatch 不能独立于 try 存在。\n在 try/catch 后面添加 finally 块并非强制性要求的。\ntry 代码后不能既没 catch 块也没 finally 块。\ntry, catch, finally 块之间不能添加任何代码。\n\n声明自定义异常在 Java 中你可以自定义异常。编写自己的异常类时需要记住下面的几点。\n\n所有异常都必须是 Throwable 的子类。\n如果希望写一个检查性异常类，则需要继承 Exception 类。\n如果你想写一个运行时异常类，那么需要继承 RuntimeException 类。\n\n可以像下面这样定义自己的异常类：1class MyException extends Exception&#123; &#125;\n只继承Exception 类来创建的异常类是检查性异常类。下面的 InsufficientFundsException 类是用户定义的异常类，它继承自 Exception。一个异常类和其它任何类一样，包含有变量和方法。\n实例\n以下实例是一个银行账户的模拟，通过银行卡的号码完成识别，可以进行存钱和取钱的操作。\n1234567891011121314151617// 文件名InsufficientFundsException.javaimport java.io.*; //自定义异常类，继承Exception类public class InsufficientFundsException extends Exception&#123;  //此处的amount用来储存当出现异常（取出钱多于余额时）所缺乏的钱  private double amount;  public InsufficientFundsException(double amount)  &#123;    this.amount = amount;  &#125;   public double getAmount()  &#123;    return amount;  &#125;&#125;\n为了展示如何使用我们自定义的异常类，在下面的 CheckingAccount 类中包含一个 withdraw() 方法抛出一个 InsufficientFundsException 异常。\n12345678910111213141516171819202122232425262728293031323334353637383940414243// 文件名称 CheckingAccount.javaimport java.io.*; //此类模拟银行账户public class CheckingAccount&#123;  //balance为余额，number为卡号   private double balance;   private int number;   public CheckingAccount(int number)   &#123;      this.number = number;   &#125;  //方法：存钱   public void deposit(double amount)   &#123;      balance += amount;   &#125;  //方法：取钱   public void withdraw(double amount) throws                              InsufficientFundsException   &#123;      if(amount &lt;= balance)      &#123;         balance -= amount;      &#125;      else      &#123;         double needs = amount - balance;         throw new InsufficientFundsException(needs);      &#125;   &#125;  //方法：返回余额   public double getBalance()   &#123;      return balance;   &#125;  //方法：返回卡号   public int getNumber()   &#123;      return number;   &#125;&#125;\n下面的 BankDemo 程序示范了如何调用 CheckingAccount 类的 deposit() 和 withdraw() 方法。\n12345678910111213141516171819202122//文件名称 BankDemo.javapublic class BankDemo&#123;   public static void main(String [] args)   &#123;      CheckingAccount c = new CheckingAccount(101);      System.out.println(\"Depositing $500...\");      c.deposit(500.00);      try      &#123;         System.out.println(\"\\nWithdrawing $100...\");         c.withdraw(100.00);         System.out.println(\"\\nWithdrawing $600...\");         c.withdraw(600.00);      &#125;catch(InsufficientFundsException e)      &#123;         System.out.println(\"Sorry, but you are short $\"                                  + e.getAmount());         e.printStackTrace();      &#125;    &#125;&#125;\n编译上面三个文件，并运行程序 BankDemo，得到结果如下所示：\n123456789Depositing $500...Withdrawing $100...Withdrawing $600...Sorry, but you are short $200.0InsufficientFundsException        at CheckingAccount.withdraw(CheckingAccount.java:25)        at BankDemo.main(BankDemo.java:13)\n通用异常在Java中定义了两种类型的异常和错误。\n\nJVM(Java**虚拟机**) 异常：由 JVM 抛出的异常或错误。例如：NullPointerException 类，ArrayIndexOutOfBoundsException 类，ClassCastException 类。\n程序级异常：由程序或者API程序抛出的异常。例如 IllegalArgumentException 类，IllegalStateException 类。\n\n","plink":"https://spaco.github.io/post/java-exception/"},{"title":"HTTP2","date":"2019-08-19T00:00:00.000Z","updated":"2019-08-19T00:00:00.000Z","content":"HTTP/2History\nHTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），简称为h2（基于TLS/1.2或以上版本的加密连接）或h2c（非加密连接），是HTTP协议的的第二个主要版本，使用于万维网。\nHTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议。它由互联网工程任务组（IETF）的Hypertext Transfer Protocol Bis（httpbis）工作小组进行开发。该组织于2014年12月将HTTP/2标准提议递交至IESG进行讨论，于2015年2月17日被批准。\nHTTP/2标准于2015年5月以RFC 7540正式发表。HTTP/2的标准化工作由Chrome、Opera、Firefox、Internet Explorer 11、Safari、Amazon Silk及Edge等浏览器提供支持。\n多数主流浏览器已经在2015年底支持了该协议。此外，根据W3Techs的数据，截至2019年6月，全球有36.5%的网站支持了HTTP/2。\n—wiki\n\nKey Points\nSPDY ：SPDY（发音如英语：speedy），一种开放的网络传输协议，由Google开发，SPDY也就是HTTP/2的前身。设计SPDY的目的在于降低网页的加载时间。通过优先级和多路复用，SPDY使得只需要创建一个TCP连接即可传送网页内容及图片等资源。SPDY中广泛应用了TLS加密，传输内容也均以gzip或DEFLATE格式压缩（与HTTP不同，HTTP的头部并不会被压缩）。另外，除了像HTTP的网页服务器被动的等待浏览器发起请求外，SPDY的网页服务器还可以主动推送内容。\n\n多路复用)：多路复用通常表示在一个信道上传输多路信号或数据流的过程和技术。因为多路复用能够将多个低速信道整合到一个高速信道进行传输，从而有效地利用了高速信道。通过使用多路复用\n\nTCP连接\n\n流\n\n消息\n\n帧\n\nHPACK 算法：\nHPACK算法是新引入HTTP/2的一个算法，用于对HTTP头部做压缩。其原理在于：\n\n客户端与服务端根据 RFC 7541 的附录A，维护一份共同的静态字典（Static Table），其中包含了常见头部名及常见头部名称与值的组合的代码；\n客户端和服务端根据先入先出的原则，维护一份可动态添加内容的共同动态字典（Dynamic Table）；\n客户端和服务端根据 RFC 7541 的附录B，支持基于该静态哈夫曼码表的哈夫曼编码（Huffman Coding）。\n\n\n\n\n有别于HTTP/1.1在连接中的明文请求，HTTP/2与SPDY一样，将一个TCP连接分为若干个流（Stream），每个流中可以传输若干消息（Message），每个消息由若干最小的二进制帧（Frame）组成。这也是HTTP/1.1与HTTP/2最大的区别所在。 HTTP/2中，每个用户的操作行为被分配了一个流编号(stream ID)，这意味着用户与服务端之间创建了一个TCP通道；协议将每个请求分割为二进制的控制帧与数据帧部分，以便解析。这个举措在SPDY中的实践表明，相比HTTP/1.1，新页面加载可以加快11.81% 到 47.7%\n—wiki\n\nWhy HTTP/2先看一下案例\nhttps://http1.golang.org/gophertiles\nhttps://http2.akamai.com/demo\nComparisonHTTP/2与HTTP/1.1比较HTTP/2 相比 HTTP/1.1 的修改并不会破坏现有程序的工作，但是新的程序可以借由新特性得到更好的速度。HTTP/2 保留了 HTTP/1.1 的大部分语义，例如请求方法、状态码乃至URI和绝大多数HTTP头部字段一致。而 HTTP/2 采用了新的方法来编码、传输 客户端&lt;——&gt;服务器 间的数据。\nHTTP/1.1与SPDY的区别SPDY (发音为”speedy”) 是一个由 Google 主导的研究项目发明的HTTP替代协议。[13]SPDY一开始主要关注降低延迟，采用了TCP通道，但是使用了不同的协议来达到此目的。其与HTTP/1.1相比，主要的改变有：\n\n实现无需先入先出的多路复用\n为简化客户端和服务器开发的消息 ：帧机制\n强制性压缩（包括HTTP头部）\n优先级排序\n双向通讯\n\nHTTP/2与SPDY的比较HTTP/2的开发基于SPDY进行跃进式改进。在诸多修改中，最显著的改进在于，HTTP/2使用了一份经过定制的压缩算法，基于霍夫曼编码，以此替代了SPDY的动态流压缩算法，以避免对协议的Oracle攻击——这一类攻击以CRIME为代表。此外，HTTP/2禁用了诸多加密包，以保证基于TLS的连接的前向安全。\nBrowser support截至2015年末，主要的浏览器的最新版本已经支持HTTP/2这一协议。其中：\nGoogle Chrome、Mozilla Firefox、Microsoft Edge和Opera已支持HTTP/2，并默认启用。Internet Explorer自IE 11开始支持HTTP/2，并预设激活。\nReferences\n一文读懂 HTTP/2 特性\n维基百科：HTTP/2\nhttp2讲解\n\n","plink":"https://spaco.github.io/post/HTTP2/"},{"title":"oauth2.0","date":"2019-08-01T00:00:00.000Z","updated":"2019-08-01T00:00:00.000Z","content":"开放授权（OAuth）是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。\nOAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的网站（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容。\nOAuth是OpenID的一个补充，但是完全不同的服务。\nWhy Oauth2.0Version and History\nThe OAuth 1.0 protocol was published as RFC 5849, an informational Request for Comments, in April 2010.\nSince 31 August 2010, all third party Twitter applications have been required to use OAuth.[6]\nThe OAuth 2.0 framework was published as RFC 6749, and the Bearer Token Usage as RFC 6750, both standards track Requests for Comments, in October 2012.\n— wiki\n\n概念点\nRFC\n\n请求意见稿（英语：Request for Comments，缩写：RFC）是由互联网工程任务组（IETF）发布的一系列备忘录。文件收集了有关互联网相关信息，以及UNIX和互联网社群的软件文件，以编号排定。当前RFC文件是由互联网协会（ISOC）赞助发行\n\n\nResource Owner\n资源所属者，即用户\n\nClient | Third-party application \n客户端，指第三方应用，得到 Resource Owner 授权后便可以去访问 Resource Owner  的信息，如别名、手机号等等\n\nAuthorization Server\n授权服务器， 认证  Resource Owner 身份，为 Resource Owner 提供授权审批流程，并最终颁发授权令牌(Access Token)\n\nResource Server\n资源服务器，存储 Resource Owner 资源，并处理对资源的访问请求，Client拿到 授权令牌(Access Token)向资源服务器请求相关资源\n\nUser Agent\n浏览器，chrome、safari等等\n\nAccess Token\n授权令牌，一般来说，是有时效性的一段字符串，合法时间内，使用该令牌才可以访问具体资源\n\nAuthorization Code\n授权码，用于获得Access Token的一个key\n\nAuthentication\n认证，通过输入帐号和密码来认证用户\n\nAuthorization\n授权，并非通过帐号和密码，而是授于第三方某权限\n\n\nAuthorization Server和 Resource Server可能是同一台服务器\nAuthorization Patterns授权模式\nAuthorization Code Grant  （授权码）最常用的授权方式\nFlow Chart12345678910111213141516171819202122232425 +----------+| Resource ||   Owner  ||          |+----------+     ^     |    (B)+----|-----+          Client Identifier      +---------------+|         -+----(A)-- &amp; Redirection URI ----&gt;|               ||  User-   |                                 | Authorization ||  Agent  -+----(B)-- User authenticates ---&gt;|     Server    ||          |                                 |               ||         -+----(C)-- Authorization Code ---&lt;|               |+-|----|---+                                 +---------------+  |    |                                         ^      v (A)  (C)                                        |      |  |    |                                         |      |  ^    v                                         |      |+---------+                                      |      ||         |&gt;---(D)-- Authorization Code ---------'      ||  Client |          &amp; Redirection URI                  ||         |                                             ||         |&lt;---(E)----- Access Token -------------------'+---------+       (w/ Optional Refresh Token)\n\n（A）客户端通过url指引用户进入授权页面\n（B） 授权服务器授权服务器验证资源所有者（通过浏览器）并确定资源所有者授予或拒绝客户的访问请求\n（C）假设资源所属者同意授予访问权限，授权服务器使用将通过User Agent重定向至redirect_uri（A步骤中url的redirect_uri属性），重定向的redirect_uri包括authorization code和 早期A步骤已定义的本地state属性\n（D）客户端通过redirect_uri获取 authorization code字段值，（authorization code有时效性）\n（E）客户端通过 authorization code字段值，根据授权服务器指定接口，获取访问令牌（时效性）和（可选）刷新令牌\n\nRequest &amp;&amp; Response\nAuthorization Request\nAuthorization Response\nAccess Token Request\nAccess Token Response\n\nImplicit Grant （隐式）Flow Chart1234567891011121314151617181920212223242526272829303132+----------+  | Resource |  |  Owner   |  |          |  +----------+       ^       |      (B)  +----|-----+          Client Identifier     +---------------+  |         -+----(A)-- &amp; Redirection URI ---&gt;|               |  |  User-   |                                | Authorization |  |  Agent  -|----(B)-- User authenticates --&gt;|     Server    |  |          |                                |               |  |          |&lt;---(C)--- Redirection URI ----&lt;|               |  |          |          with Access Token     +---------------+  |          |            in Fragment  |          |                                +---------------+  |          |----(D)--- Redirection URI ----&gt;|   Web-Hosted  |  |          |          without Fragment      |     Client    |  |          |                                |    Resource   |  |     (F)  |&lt;---(E)------- Script ---------&lt;|               |  |          |                                +---------------+  +-|--------+    |    |   (A)  (G) Access Token    |    |    ^    v  +---------+  |         |  |  Client |  |         |  +---------+\n相当于简化了Authorization Code Grant步骤，取消获取Authorization Code步骤，同意授权后，重定向至redirect_uri的时候就会携带Access Token\nRequest &amp;&amp; Response\nAuthorization Request\nAccess Token Response\n\nResource Owner Password Credentials Grant（密码）Flow Chart1234567891011121314151617+----------+ | Resource | |  Owner   | |          | +----------+      v      |    Resource Owner     (A) Password Credentials      |      v +---------+                                  +---------------+ |         |&gt;--(B)---- Resource Owner -------&gt;|               | |         |         Password Credentials     | Authorization | | Client  |                                  |     Server    | |         |&lt;--(C)---- Access Token ---------&lt;|               | |         |    (w/ Optional Refresh Token)   |               | +---------+                                  +---------------+\n\n资源所有者为客户端提供其用户名和密码\n客户端从授权请求访问令牌服务器的令牌端点，包括收到的凭据来自资源所有者。在提出请求时，客户端使用授权服务器进行身份验证\n授权服务器验证客户端并验证资源所有者凭据，如果有效，则发出访问权限令牌\n\nRequest &amp;&amp; Response\nAuthorization Request and Response\nAccess Token Request\nAccess Token Response\n\nClient Credentials Grant（客户端凭证）由于客户端身份验证用作授权授权，无需其他授权请求\nFlow Chart1234567+---------+                                  +---------------+|         |                                  |               ||         |&gt;--(A)- Client Authentication ---&gt;| Authorization || Client  |                                  |     Server    ||         |&lt;--(B)---- Access Token ---------&lt;|               ||         |                                  |               |+---------+                                  +---------------+\n\n客户端使用授权服务器进行身份验证 从令牌端点请求访问令牌\n授权服务器验证客户端，如果有效，发出访问令牌\n\nRequest &amp;&amp; Response\nAccess Token Request\nAccess Token Response\n\nRefreshing an Access TokenDifference between oauth2 and jwt\nSo the real difference is that JWT is just a token format, OAuth 2.0 is a protocol (that may use a JWT as a token format).\n\n真正的区别在于JWT仅仅是一个令牌格式，OAuth 2.0用户是一个授权协议（即可以使用JWT作为令牌格式）\nReferences\n授权模式RFC\n\nWhat are the main differences between JWT and OAuth authentication\n\nSecurity of mobile OAuth 2.0\n\ngithub Authorization Code Grant实例\n\n简易图解】『 OAuth2.0』 猴子都能懂的图解\n\n\n","plink":"https://spaco.github.io/post/oauth2.0/"},{"title":"difference between mongo mongodb mongod","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"Difference between mongo mongodb mongod\nMongodMongo Daemon 即守护进程\n123456# ps -Aroot@2524adecfdfb:/# ps -APID TTY          TIME CMD  1 ?        00:03:17 mongod 57 pts/0    00:00:00 bash 83 pts/0    00:00:00 ps\nMongocommand-line shell\n1234567891011121314151617181920212223# mongo localhost:27017root@2524adecfdfb:/# mongo localhost:27017MongoDB shell version v4.0.10connecting to: mongodb://localhost:27017/test?gssapiServiceName=mongodbImplicit session: session &#123; \"id\" : UUID(\"d1bfacc3-15b2-41a6-b6fa-cf422e0506fc\") &#125;MongoDB server version: 4.0.10Server has startup warnings:2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten]2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten]---Enable MongoDB's free cloud-based monitoring service, which will then receive and displaymetrics about your deployment (disk utilization, CPU, operation statistics, etc).The monitoring data will be available on a MongoDB website with a unique URL accessible to youand anyone you share the URL with. MongoDB may use this information to make productimprovements and to suggest MongoDB products and deployment options to you.To enable free monitoring, run the following command: db.enableFreeMonitoring()To permanently disable this reminder, run the following command: db.disableFreeMonitoring()---&gt;\n 连接之后，可以进行下一步操作，例如：查询数据库列表\n123456# show dbs&gt; show dbsadmin   0.000GBconfig  0.000GBlocal   0.000GBreport  0.021GB\nMongodbMongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案\n","plink":"https://spaco.github.io/post/difference-between-mongo-mongodb-mongod/"},{"title":"programming noun","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"List commonly used programming nouns\nAbbreviationCommonHTTP HTTP（HyperText Transfer Protocol）：超文本传输协议是一种用于分布式、协作式和超媒体信息系统的应用层协议。\nCAPCAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），在理论计算机科学中，它指出对于一个分布式计算系统来说，不可能同时满足以下三点：\n\n一致性（Consistency） （等同于所有节点访问同一份最新的数据副本）\n可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）\n分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。）\n\n根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项[4]。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。\nACIDACID，是指数据库管理系统（DBMS）在写入或更新资料的过程中，为保证事务（transaction）是正确可靠的，所必须具备的四个特性：原子性（atomicity，或称不可分割性）、一致性&amp;action=edit&amp;redlink=1)（consistency）、隔离性（isolation，又称独立性）、持久性（durability）\nRPCRPC（Remote Procedure Call）：远程过程调用是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。\nORMORM（Object Relational Mapping）：对象关系映射是一种程序设计技术，用于实现面向对象编程语言里不同类型系统的数据之间的转换。从效果上说，它其实是创建了一个可在编程语言里使用的“虚拟对象数据库”。\nMVCMVC（Model–view–controller）：MVC模式是软件工程中的一种软件架构模式，把软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）。\n\n控制器（Controller）- 负责转发请求，对请求进行处理。\n视图（View） - 界面设计人员进行图形界面设计。\n模型（Model） - 程序员编写程序应有的功能（实现算法等等）、数据库专家进行数据管理和数据库设计(可以实现具体的功能)。\n\nGCGC)（Garbage Collection）: 垃圾回收\n在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。垃圾回收最早起源于LISP语言。当前许多语言如Smalltalk、Java、C#和D语言都支持垃圾回收器。\nOOPOOP（Object-oriented programming）：面向对象程序设计\n是种具有对象)概念的程序编程典范，同时也是一种程序开发的抽象方针。\nAOPAOP（Aspect-oriented programming）：面向切面编程\n是计算机科学中的一种程序设计思想，旨在将横切关注点与业务主体进行进一步分离，以提高程序代码的模块化程度。通过在现有代码基础上增加额外的通知（Advice）机制，能够对被声明为“切点（Pointcut）”的代码块进行统一管理与装饰，如“对所有方法名以‘set*’开头的方法添加后台日志”。该思想使得开发人员能够将与代码核心业务逻辑关系不那么密切的功能（如日志功能）添加至程序中，同时又不降低业务代码的可读性。面向切面的程序设计思想也是面向切面软件开发的基础。\nRESTREST（REpresentational State Transfer）：表现层状态转换\n是一种万维网软件架构风格，目的是便于不同软件/程序在网络（例如互联网）中互相传递信息。\nURL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。\nSOAPSOAP（Simple Object Access Protocol）：简单对象访问协议是交换数据的一种协议规范，使用在计算机网络Web服务（web service）中，交换带结构信息。SOAP使用因特网应用层协议作为其传输协议。SMTP以及HTTP协议都可以用来传输SOAP消息，但是由于HTTP在如今的因特网结构中工作得很好，特别是在网络防火墙下仍然正常工作，所以被广泛采纳。SOAP亦可以在HTTPS上传输。SOAP的消息格式采用XML。实际上计算机网络上交换基于XML的消息的协议，通常是用HTTP。\nSOAP 与 REST 的区别\nSOASOA（service-oriented architecture）：面向服务的体系结构\n并不特指一种技术，而是一种分布式运算的软件设计方法\nAPIAPI（）：\n应用程序接口（英语：Application Programming Interface，缩写：API；又称为应用程序编程接口）是软件系统不同组成部分衔接的约定。 由於近年來软件的规模日益庞大，常常需要把复杂的系统划分成小的组成部分，编程接口的设计十分重要。\nAJAXAJAX（Asynchronous JavaScript and XML）：异步的JavaScript与XML技术\n指的是一套综合了多项技术的浏览器端网页开发技术\nJSONJSON（JavaScript Object N**otation）：JavaScript对象表示法\n是一种由轻量级的数据交换语言，该语言以易于让人阅读的文字为基础，用来传输由属性值或者序列性的值组成的数据对象。尽管JSON是JavaScript的一个子集，但JSON是独立于语言的文本格式。\nJSON 数据格式与语言无关，脱胎自JavaScript，但当前很多编程语言都支持 JSON 格式数据的生成和解析。JSON 的官方 MIME 类型是 application/json，文件扩展名是 .json。\nXMLXML（Extensible Markup Language）：可扩展标记语言\n可扩展标记语言（英语：Extensible Markup Language，简称：XML）是一种标记语言。标记指计算机所能理解的信息符号，通过此种标记，计算机之间可以处理包含各种信息的文章等\nDIDependency Injection，依赖注入。在软件工程中，依赖注入是种实现控制反转用于解决依赖性设计模式。一个依赖关系指的是可被利用的一种对象（即服务提供端） 。依赖注入是将所依赖的传递给将使用的从属对象（即客户端）。该服务是将会变成客户端的状态的一部分。 传递服务给客户端，而非允许客户端来建立或寻找服务，是本设计模式的基本要求。\nIoC控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫“依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体，将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。\nDNSDNS（Domain Name S**ystem）：域名系统\n是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。\nGUIGUI（Graphical User I**nterface）：图形用户界面\n是指采用图形方式显示的计算机操作用户界面。与早期计算机使用的命令行界面相比，图形界面对于用户来说在视觉上更易于接受。\nJWTJWT（JSON Web Token）：\n一种用以产生访问令牌的开源标准，适用于分布式站点的单点登录（SSO）场景。\nJavaJPAJPA（Java Persistence API）：Java 持久化 API\n是一个 Java 应用程序接口 规范，描述了使用 Java标准版平台（Java SE） 和 Java企业版平台（Java EE）的应用中的 关系数据 的管理。\n持久化)，在这里包括三个层面的意思：\n\nAPI 本身，定义在 javax.persistence 包内\nJava持久化查询语言 (JPQL)\n对象/关系 元数据\n\nJPQLJPQL（Java Persistence Query Language）：Java持久化查询语言\n对存储在关系数据库中的实体进行查询。查询在语法上类似于SQL查询，但是操作的是实体对象而不是直接对数据库表进行操作。\nEJBEJB（Enterprise JavaBean）：企业级JavaBean\n是一个用来构筑企业级应用的服务器端可被管理组件。 Java企业版API（Java Enterprise Edition）中提供了对EJB的规范。 EJB是一个封装有某个应用程序之业务逻辑服务器端组件。\nPOJOPOJO（Plain Ordinary Java Object）：简单的Java对象\n实际就是普通JavaBeans，是为了避免和EJB混淆所创造的简称。 使用POJO名称是为了避免和EJB混淆起来, 而且简称比较直接.其中有一些属性及其 getter setter 方法的类，没有业务逻辑，有时可以作为VO(Value Object) 或 DTO(Data Transform Object) 来使用。当然，如果你有一个简单的运算属性也是可以的。\nPHPPHP  PHP（全称：PHP：Hypertext Preprocessor，即“PHP：超文本预处理器”）是一种开源的通用计算机脚本语言\nDataBaseSQLSQL（Structured Query Language）：结构化查询语言\n是一种特定目的编程语言，用于管理关系数据库管理系统（RDBMS），或在关系流数据管理系统（RDSMS）中进行流处理。\nNoSQLNoSQL（）：\n是对不同于传统的关系数据库的数据库管理系统的统称。两者存在许多显著的不同点，其中最重要的是NoSQL不使用SQL作为查询语言。其数据存储可以不需要固定的表格模式，也经常会避免使用SQL的JOIN)操作，一般有水平可扩展性的特征。\nFront endSPA单页 Web 应用（single page web application），就是只有一张 Web 页面的应用，是加载单个 HTML 页面并在用户与应用程序交互时动态更新该页面的 Web 应用程序。\n","plink":"https://spaco.github.io/post/programming-noun/"},{"title":"php extension install","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"##List PHP extensions\n123456php -m# show like this[PHP Modules]libeventposixpcntl\n##Install\n###Redis\n可以使用 predis composer 扩展包的方式达成对Redis的操作，效果与Redis扩展大同小异\n####Mac\n####Ubuntu\nReferences\npredis包和phpredis扩展的区别是什么\n\n","plink":"https://spaco.github.io/post/php-extension-install/"},{"title":"laravel Facades","date":"2019-07-26T00:00:00.000Z","updated":"2019-07-26T00:00:00.000Z","content":"Laravel Facade 执行流程分析\nIntroductionFacades 为应用程序提供了一系列的静态方法，提供简洁，富有表现力的语法，同时保持比传统静态方法更多的可测试性和灵活性。\nDemo Used in code123456789101112// cache\\Illuminate\\Support\\Facades\\Cache::get('cacheKey');// redis\\Illuminate\\Support\\Facades\\Redis::get('redisKey');// auth\\Illuminate\\Support\\Facades\\Auth::id();// config\\Illuminate\\Support\\Facades\\Config::get('configKey');// log\\Illuminate\\Support\\Facades\\Log::info('logKey');// request\\Illuminate\\Support\\Facades\\Request::get('requestKey');\nHow Facades Work (以Cache为例)首先是Cache Facade文件\n123456789101112131415161718namespace Illuminate\\Support\\Facades;/*  * @see \\Illuminate\\Cache\\CacheManager * @see \\Illuminate\\Cache\\Repository */class Cache extends Facade&#123;    /**     * Get the registered name of the component.     *     * @return string     */    protected static function getFacadeAccessor()    &#123;        return 'cache';    &#125;&#125;\n代码量很少，只有一个getFacadeAccessor方法，那么它是如何可以调用其他方法的呢，主要是Cache Facade 继承的Facade类，Facade主要代码如下所示:\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081namespace Illuminate\\Support\\Facades;abstract class Facade&#123;        /**     * The application instance being facaded.     *     * @var \\Illuminate\\Contracts\\Foundation\\Application     */    protected static $app;    /**     * The resolved object instances.     *     * @var array     */    protected static $resolvedInstance;        /**     * Handle dynamic, static calls to the object.     *     * @param  string  $method     * @param  array   $args     * @return mixed     *     * @throws \\RuntimeException     */    public static function __callStatic($method, $args)    &#123;        $instance = static::getFacadeRoot();        if (! $instance) &#123;            throw new RuntimeException('A facade root has not been set.');        &#125;        return $instance-&gt;$method(...$args);    &#125;        /**     * Get the root object behind the facade.     *     * @return mixed     */    public static function getFacadeRoot()    &#123;        return static::resolveFacadeInstance(static::getFacadeAccessor());    &#125;        /**     * Resolve the facade root instance from the container.     *     * @param  object|string  $name     * @return mixed     */    protected static function resolveFacadeInstance($name)    &#123;        if (is_object($name)) &#123;            return $name;        &#125;        if (isset(static::$resolvedInstance[$name])) &#123;            return static::$resolvedInstance[$name];        &#125;        return static::$resolvedInstance[$name] = static::$app[$name];    &#125;        /**     * Get the registered name of the component.     *     * @return string     *     * @throws \\RuntimeException     */    protected static function getFacadeAccessor()    &#123;        throw new RuntimeException('Facade does not implement getFacadeAccessor method.');    &#125;  &#125;\n那么   cache 在何处定义的呢？是由框架内部的CacheServiceProvider注册，若想更深一步了解Service Providers可以参考Service Providers\n12345678910111213141516171819202122232425262728namespace Illuminate\\Cache;class CacheServiceProvider extends ServiceProvider implements DeferrableProvider&#123;      /**     * Register the service provider.     *     * @return void     */    public function register()    &#123;        $this-&gt;app-&gt;singleton('cache', function ($app) &#123;            return new CacheManager($app);        &#125;);    &#125;    /**     * Get the services provided by the provider.     *     * @return array     */    public function provides()    &#123;        return [            'cache'        ];    &#125;&#125;\n那么就很明显了，Cache::get() 实际上是调用CacheManager::get()，主要是代码是在CacheManager中，Cache Facade提供了一种便捷使用方法。\n##Find Laravel Predefined Facades\nsearch\n123$this-&gt;app-&gt;singleton('cache'$this-&gt;app-&gt;singleton('redis'$this-&gt;app-&gt;singleton('log'\n","plink":"https://spaco.github.io/post/laravel-facades/"},{"title":"difference between socket and websocket","date":"2019-07-23T00:00:00.000Z","updated":"2019-07-23T00:00:00.000Z","content":"Difference between socket and websocket \nSocket\n套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据，可对其进行像对文件一样的打开、读写和关闭等操作。套接字允许应用程序将I/O插入到网络中，并与网络中的其他应用程序进行通信。网络套接字是IP地址与端口的组合。\n——百度百科\n\nSocket是一套API接口，是建立在TCP和应用程序之间的一个抽象层，就是我们之前说的“面向抽象编程”的这个抽象，Socket这个抽象层帮我们封装了TCP/UDP等网络协议的操作，让我们可以通过Socket提供的接口进行网络通信，可以通过一个图来说明这个抽象的功能\nWebsocketwiki.websocket\n\nWebSocket是一种通信协议，可在单个TCP连接上进行全双工通信。WebSocket协议在2011年由IETF标准化为RFC 6455，后由RFC 7936补充规范。Web IDL中的WebSocket API由W3C标准化。\nWebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。\n\n简介\nWebSocket是一种与HTTP不同的协议。两者都位于OSI模型的应用层，并且都依赖于传输层的TCP协议。 虽然它们不同，但RFC 6455规定：“WebSocket设计为通过80和443端口工作，以及支持HTTP代理和中介”，从而使其与HTTP协议兼容。 为了实现兼容性，WebSocket握手使用HTTP Upgrade头[1]从HTTP协议更改为WebSocket协议。\nWebSocket协议支持Web浏览器（或其他客户端应用程序）与Web服务器之间的交互，具有较低的开销，便于实现客户端与服务器的实时数据传输。 服务器可以通过标准化的方式来实现，而无需客户端首先请求内容，并允许消息在保持连接打开的同时来回传递。通过这种方式，可以在客户端和服务器之间进行双向持续对话。 通信通过TCP端口80或443完成，这在防火墙阻止非Web网络连接的环境下是有益的。另外，Comet)之类的技术以非标准化的方式实现了类似的双向通信。\n大多数浏览器都支持该协议，包括Google Chrome、Firefox、Safari、Microsoft Edge、Internet Explorer和Opera。\n与HTTP不同，WebSocket提供全双工通信。此外，WebSocket还可以在TCP之上启用消息流。TCP单独处理字节流，没有固有的消息概念。 在WebSocket之前，使用Comet可以实现全双工通信。但是Comet存在TCP握手和HTTP头的开销，因此对于小消息来说效率很低。WebSocket协议旨在解决这些问题。\nWebSocket协议规范将ws（WebSocket）和wss（WebSocket Secure）定义为两个新的统一资源标识符（URI）方案，分别对应明文和加密连接。除了方案名称和片段ID（不支持#）之外，其余的URI组件都被定义为此URI的通用语法。\n使用浏览器开发人员工具，开发人员可以检查WebSocket握手以及WebSocket框架。\n\n背景\n现在，很多网站为了实现推送技术，所用的技术都是轮询。轮询是在特定的的时间间隔（如每秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会消耗很多的带宽资源。\n比较新的轮询技术是Comet)。这种技术虽然可以实现双向通信，但仍然需要反复发出请求。而且在Comet中普遍采用的HTTP长连接也会消耗服务器资源。\n在这种情况下，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。\nWebsocket使用ws或wss的统一资源标志符，类似于HTTPS。其中wss表示使用了TLS的Websocket。如：\n123&gt; ws://example.com/wsapi&gt; wss://secure.example.com/wsapi&gt;\n\n\nWebsocket与HTTP和HTTPS使用相同的TCP端口，可以绕过大多数防火墙的限制。默认情况下，Websocket协议使用80端口；运行在TLS之上时，默认使用443端口。\n\n优点\n\n较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。\n\n更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。\n\n保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。\n\n更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。\n\n可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。\n\n更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。\n\n\n\n握手协议\nWebSocket 是独立的、创建在 TCP 上的协议。\nWebsocket 通过 HTTP/1.1 协议的101状态码进行握手。\n为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手)”（handshaking）。\n\nSummaryWebsocket是一种应用层协议，Socket是封装了网络层操作的抽象API接口\nReferences维基WebSocket\n","plink":"https://spaco.github.io/post/difference-between-socke-and-websocket/"},{"title":"OSI - Open System Interconnection Reference Model","date":"2019-07-22T00:00:00.000Z","updated":"2019-07-22T00:00:00.000Z","content":"开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写：OSI；简称为OSI模型）是一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。\n历史在制定计算机网络标准方面，起着重大作用的两大国际组织是：国际电信联盟电信标准化部门，与国际标准组织（ISO），虽然它们工作领域不同，但随着科学技术的发展，通信与信息处理之间的界限开始变得比较模糊，这也成了国际电信联盟电信标准化部门和ISO共同关心的领域。1984年，ISO发布了著名的ISO/IEC 7498标准，它定义了网络互联的7层框架，也就是开放式系统互联参考模型。\n层次划分根据建议X.200，OSI将计算机网络体系结构划分为以下七层，标有1～7，第1层在底部。 现“OSI/RM”是英文“Open Systems Interconnection Reference Model”的缩写。\n第7层 应用层（Application Layer）应用层（Application Layer）提供为应用软件而设的接口，以设置与另一应用软件之间的通信。例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3.HTML.等。\n第6层 表达层（Presentation Layer）表达层（Presentation Layer）把数据转换为能与接收者的系统格式兼容并适合传输的格式。\n第5层 会话层（Session Layer）会话层（Session Layer）负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。\n第4层 传输层（Transport Layer）传输层（Transport Layer）把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。例如:传输控制协议（TCP）等。\n第3层 网络层（Network Layer）网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络数据。例如:互联网协议（IP）等。\n第2层 数据链路层（Data Link Layer）数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。当表头和表尾被加至数据包时，会形成帧。数据链表头（DLH）是包含了物理地址和错误侦测及改错的方法。数据链表尾（DLT）是一串指示数据包末端的字符串。例如以太网、无线局域网（Wi-Fi）和通用分组无线服务（GPRS）等。\n分为两个子层：逻辑链路控制（logical link control，LLC）子层和介质访问控制（Medium access control，MAC）子层。\n第1层 物理层（Physical Layer）物理层（Physical Layer）在局部局域网上传送数据帧（data frame），它负责管理计算机通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等。\n影响OSI是一个定义良好的协议规范集，并有许多可选部分完成类似的任务。它定义了开放系统的层次结构、层次之间的相互关系以及各层所包括的可能的任务，作为一个框架来协调和组织各层所提供的服务。\nOSI参考模型并没有提供一个可以实现的方法，而是描述了一些概念，用来协调进程间通信标准的制定。即OSI参考模型并不是一个标准，而是一个在制定标准时所使用的概念性框架。\n##References\n\nDoD模型（Department of Defense Model）四层是为了ARPANET所开发出来的模型。\n网络传输协议\nTCP/IP，与OSI模型有类似结构的现行网络模型\nOSI模型\n\n","plink":"https://spaco.github.io/post/OSI open-system-interconnection-reference-model/"},{"title":"types-of-dependency-injection","date":"2019-07-15T00:00:00.000Z","updated":"2019-07-15T00:00:00.000Z","content":"Types of Dependency Injection此篇文章使用 Java 代码作为演示\n如果希望了解 Dependency Injection 和  Inversion of Control 可以参考··\nSpring通过DI（依赖注入）实现IoC（控制反转)\n建议看一下这篇文章\nhttps://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#beans-dependencies\nTypesConstructor Injection基于构造函数的DI由容器调用具有多个参数的构造函数来完成，每个参数表示一个依赖项。 调用具有特定参数的静态工厂方法来构造bean几乎是等效的，本讨论同样处理构造函数和静态工厂方法的参数。 以下示例显示了一个只能通过构造函数注入进行依赖注入的类：\n123456789101112public class SimpleMovieLister &#123;    // the SimpleMovieLister has a dependency on a MovieFinder    private MovieFinder movieFinder;    // a constructor so that the Spring container can inject a MovieFinder    public SimpleMovieLister(MovieFinder movieFinder) &#123;        this.movieFinder = movieFinder;    &#125;    // business logic that actually uses the injected MovieFinder is omitted...&#125;\nAdvantages\n能够在构造阶段就创建完整、合法的对象；\n带有参数的构造函数可以明确地告诉你创建一个合法的对象需要哪些参数\n\nDisadvantages\n构造函数依赖的太多，会显得很复杂（事实上，当一个控制器依赖太多service，这个控制器本身就是有问题的，需要拆解）\n1234567891011121314public class SimpleMovieLister &#123;    private A a;\t\tprivate B b;  \tprivate C c;  \tprivate D d;      public SimpleMovieLister(A a,B b,C c,D d) &#123;        this.a = a;      \tthis.b = b;      \tthis.c = c;      \tthis.d = d;    &#125;&#125;\n\n\nSetter Injection | Property Injection在调用无参数构造函数或无参数static工厂方法来实例化bean之后，基于setter的DI由bean上的容器调用setter方法完成。\n以下示例显示了一个只能通过使用纯setter注入进行依赖注入的类。这个类是传统的Java。它是一个POJO，它不依赖于容器特定的接口，基类或注释。\n123456789101112public class SimpleMovieLister &#123;    // the SimpleMovieLister has a dependency on the MovieFinder    private MovieFinder movieFinder;    // a setter method so that the Spring container can inject a MovieFinder    public void setMovieFinder(MovieFinder movieFinder) &#123;        this.movieFinder = movieFinder;    &#125;    // business logic that actually uses the injected MovieFinder is omitted...&#125;\nAdvantages\n如果依赖的「插件」太多时，选择 Setter 注入更优\n\nDisadvantages\n无法在构造阶段就创建完整、合法的对象；\n\n带有参数的构造函数无法明确地告诉你创建一个合法的对象需要哪些参数\n\n\nMethod Injection | Function InjectionWhat is method injection？\nSpring 中 Method Injection 分为 Lookup Method Injection （查找方法注入）和 Arbitrary Method Replacement（任意方法替换）\n在大多数应用程序场景中，容器中的大多数bean都是 单例。当单例bean需要与另一个单例bean协作或非单例bean需要与另一个非单例bean协作时，通常通过将一个bean定义为另一个bean的属性来处理依赖关系。当bean生命周期不同时会出现问题。假设单例bean A需要使用非单例（原型）bean B，可能是在A上的每个方法调用上。容器只创建一次单例bean A，因此只有一次机会来设置属性。每次需要时，容器都不能为bean A提供bean B的新实例。即 需要新实例。\nA solution is to forego some inversion of control. You can make bean A aware of the container by implementing the ApplicationContextAware interface, and by making a getBean(&quot;B&quot;) call to the container ask for (a typically new) bean B instance every time bean A needs it. The following example shows this approach:\nSummaryConstructor Injection 和 Setter Injection | Property Injection 是较常见的的注入方式，Method Injection 使用的较少。\n个人比较推荐 Constructor Injection，优点如上所述。\n还有一些文章说 Annotation Injection （注解注入）：通过注解将类注入到类属性中。个人感觉本质上和 Constructor Injection 没什么区别，都是初始化时将类注入到类属性中。\n不推荐以下写法，自己通过注解初始化类参数：\n随着版本的迭代，开发者更注重于业务本身，而会忽略初始化的参数越来越多\n1234567891011121314151617class Foo&#123;  \t/**     * @Inject A     */    private A a;      /**     * @Inject B     */    private B b;      /**     * @Inject C     */    private C c;&#125;\nReferences\nDI-wiki\nmethod-injection\ndocs.spring.io.beans-dependencies\nA quick intro to Dependency Injection: what it is, and when to use it\nDependency Injection\nspring-framework-reference.core\nJava方法注入（Method_injection）\nUnderstand Dependency Injection: Function/Method Injection\nSpring查找方法注入(Lookup method injection)的底层实现原理\nDifference Between @Resource, @Autowired and @Inject in Spring Injection\n\n","plink":"https://spaco.github.io/post/types-of-dependency-injection/"},{"title":"laravel-queue-timeout-configuration-not-working","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"laravel 设置队列超时时间，但是并没有生效\nDevelopment environmentslaravel : v5.5   \n12# https://laravel.com/docs/5.5/installationlaravel5.5 server requirements : PHP &gt;= 7.0.0\nphp : v7.1.30\ncodeController123456789101112131415&lt;?phpnamespace App\\Http\\Controllers;use App\\Jobs\\Test;class QueueController extends Controller&#123;    public function index()    &#123;        echo 'queue start';        Test::dispatch()-&gt;onQueue('testQueue');        echo 'queue end';    &#125;&#125;\nJob123456789101112131415161718192021222324252627282930&lt;?phpnamespace App\\Jobs;use App\\User;use Illuminate\\Bus\\Queueable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;use Illuminate\\Support\\Facades\\Log;class Test implements ShouldQueue&#123;    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;    public $tries = 5;    public $timeout = 5;    public function __construct()    &#123;    &#125;    public function handle()    &#123;        Log::error('queue start');        sleep(10);        Log::error('queue end');    &#125;&#125;\n调用控制器，会发现，队列设置的超时时间无效\n12[2019-07-04 03:16:38][42] Processing: App\\Jobs\\Test[2019-07-04 03:16:48][42] Processed:  App\\Jobs\\Test\n日志同样会被打印\n12local.ERROR: queue start local.ERROR: queue end\n这是为什么呢\n Timeout settings not kill job in queue Laravel 5.4\n1234Timeouts also require PHP 7.1 to work.Ref: Worker::registerTimeoutHandlerRef: Worker::supportsAsyncSignals\nLaravel Queue Worker\n123456789101112131415161718192021222324252627282930313233# Illuminate\\Queue\\Worker    /**     * Register the worker timeout handler (PHP 7.1+).     *     * @param  \\Illuminate\\Contracts\\Queue\\Job|null  $job     * @param  WorkerOptions  $options     * @return void     */    protected function registerTimeoutHandler($job, WorkerOptions $options)    &#123;        if ($this-&gt;supportsAsyncSignals()) &#123;            // We will register a signal handler for the alarm signal so that we can kill this            // process if it is running too long because it has frozen. This uses the async            // signals supported in recent versions of PHP to accomplish it conveniently.            pcntl_signal(SIGALRM, function () &#123;                $this-&gt;kill(1);            &#125;);            $timeout = $this-&gt;timeoutForJob($job, $options);            pcntl_alarm($timeout &gt; 0 ? $timeout + $options-&gt;sleep : 0);        &#125;    &#125;    /**     * Determine if \"async\" signals are supported.     *     * @return bool     */    protected function supportsAsyncSignals()    &#123;        return version_compare(PHP_VERSION, '7.1.0') &gt;= 0 &amp;&amp;               extension_loaded('pcntl');    &#125;\n从上述代码可以看出，registerTimeoutHandler 超时处理需要两个条件\n\nphp 版本 &gt;= 7.1\n已安装 pcntl 扩展\n\n命令行执行以下命令查看 pcntl 扩展情况\n1php -m | grep pcntl\nSolution\n安装 pcntl 扩展\n\nphp 版本 &gt;= 7.1\n\n\nReferences\nTimeout settings not kill job in queue Laravel 5.4\n\npcntl extension\n\n\n","plink":"https://spaco.github.io/post/laravel-queue-timeout-configuration-not-working/"},{"title":"upgrade-mac-php-version.md","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"mac 本地 php 版本较低，升级至 7.2\nUpgradeupdate brew如未安装 brew，参考 https://brew.sh/ 安装\n123brew updatebrew search php\n12345$ brew search php==&gt; Formulaebrew-php-switcher         php-cs-fixer              phplint                   phpstanphp                       php@7.1                   phpmd                     phpunitphp-code-sniffer          php@7.2                   phpmyadmin\nInstall1brew install php@7.2\n安装完成之后，执行php -v 查看PHP版本，显示仍然是老版本\n修改本地PHP版本1brew link php@7.2\n出现以下提示\n因为mac用的是zsh，所以会将PATH 写入 ~/.zshrc,个人根据提示执行命令即可\n123456$ brew link php@7.2Warning: php@7.2 is keg-only and must be linked with --forceIf you need to have this software first in your PATH instead consider running:  echo 'export PATH=\"/usr/local/opt/php@7.2/bin:$PATH\"' &gt;&gt; ~/.zshrc  echo 'export PATH=\"/usr/local/opt/php@7.2/sbin:$PATH\"' &gt;&gt; ~/.zshrc\n执行完之后，刷新配置\n1source ~/.zshrc\n执行php -v 查看PHP版本\n123php -vPHP 7.2.19 (cli) (built: Jun 17 2019 09:03:55) ( NTS )\nSuccess\n","plink":"https://spaco.github.io/post/upgrade-mac-php-version.md/"},{"title":"phpunit","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"PHPUnit是一个面向PHP程序员的测试框架，这是一个xUnit的体系结构的单元测试框架\nInstall我们用一个 PHP Archive (PHAR) 来包含你需要使用的PHPUnit，可以从这里下载它，使其可执行，并把它放到你的 $PATH 里, 如:\n1234wget http://phar.phpunit.cn/phpunit.pharchmod +x phpunit.pharsudo mv phpunit.phar /usr/local/bin/phpunitphpunit --version\nUsed in phpstormLanguages &amp; Frameworks  -&gt;  PHP  -&gt; Debug  -&gt; Test Frameworks\nPath to phpunit.phar. -&gt; /usr/local/bin/phpunit\n","plink":"https://spaco.github.io/post/phpunit/"},{"title":"laravel-envoy","date":"2019-07-02T00:00:00.000Z","updated":"2019-07-02T00:00:00.000Z","content":"IntroductionWhat is laravel-envoySuppose you hava a samll project of your own,put it on a remote server. Every time you develop a function for thissmall project, you have to go online. The general operation will be the following.\n\nconnect to server ssh username@ip\nenter the project  cd workspace/my project\nupdate local code to the latest  git pull\n\nDoing this thing manually for too long,It feels bad ～\nLaravel Envoy provides a clean, minimal syntax for defining common tasks you run on your remote servers. Using Blade style syntax, you can easily setup tasks for deployment, Artisan commands, and more. Currently, Envoy only supports the Mac and Linux operating systems.\nAllows you to do all of the above with a minimum of configuration,just by executing the following line of commands from the local command line.\n1envoy run deploy\nInstallFirst, install Envoy using the Composer global require command:\n1composer global require laravel/envoy\nSince global Composer libraries can sometimes cause package version conflicts, you may wish to consider using cgr, which is a drop-in replacement for the composer global requirecommand. The cgr library’s installation instructions can be found on GitHub.\nAfter installed,you can see it in the ~/.composer/vendor/bin directory\nMake sure to place the~/.composer/vendor/bindirectory in your PATH so theenvoyexecutable is found when running theenvoycommand in your terminal.\nexecuting the following line of commands from the local command line.\n 1export PATH=\"$PATH:$HOME/.composer/vendor/bin\"\nor \n1234567# i am using zsh, update .bash_profile is also usefulvim ~/.bash_profile# add this lineexport PATH=\"$PATH:$HOME/.composer/vendor/bin\"# refresh .bash_profilesource ~/.bash_profile\nIn order to test whether the installation was successful\n1234envoy --version# show like thisLaravel Envoy 1.5.0\nUpdating Envoy1composer global update\nTo view a list of all available Envoy commands, you may use the list command:\n1envoy list\nWriting TasksFirst, in your project root directory , execute the following command to initialize\n1234envoy init root@127.0.0.1# show like thisEnvoy file created!\nEnvoy.blade.php is created\n123456@servers(['web' =&gt; 'root@127.0.0.1'])@task('deploy')    cd /path/to/site    git pull origin master@endtask\nVariablesIf needed, you may pass option values into Envoy tasks using the command line:\n1envoy run deploy --branch=master\n1234567891011@servers(['web' =&gt; '192.168.1.1'])@task('deploy', ['on' =&gt; 'web'])    cd site    @if ($branch)        git pull origin &#123;&#123; $branch &#125;&#125;    @endif    php artisan migrate@endtask\nStoriesStories group a set of tasks under a single, convenient name, allowing you to group small, focused tasks into large tasks. For instance, a deploy story may run the git and composertasks by listing the task names within its definition:\n1234567891011121314@servers(['web' =&gt; '192.168.1.1'])@story('deploy')    git    composer@endstory@task('git')    git pull origin master@endtask@task('composer')    composer install@endtask\nOnce the story has been written, you may run it just like a typical task:\n1envoy run deploy\nAttention: \n123456789101112131415@servers(['web' =&gt; '192.168.1.1'])@story('deploy')    task1    task2@endstory@task('task1')  \tcd ~/code    pwd@endtask@task('task2')    composer install@endtask\n在story里，只能使用tasks, 并且第一个 task cd 进入 code 目录，不代表第二个 task 在 code 目录中 \n12345@story('deploy')  \tcd /workspace/project   // error!    task1    task2@endstory\n1234567# about pwd# task1/root/code# task2/root\nMultiple ServersEnvoy allows you to easily run a task across multiple servers. First, add additional servers to your @servers declaration. Each server should be assigned a unique name. Once you have defined your additional servers, list each of the servers in the task’s on array:\n1234567@servers(['web-1' =&gt; '192.168.1.1', 'web-2' =&gt; '192.168.1.2'])@task('deploy', ['on' =&gt; ['web-1', 'web-2']])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nParallel Execution默认情况下，将在每个服务器上串行执行任务。换句话说，任务将在继续在第二台服务器上执行之前在第一台服务器上完成运行。如果要并行运行多个服务器上的任务，请将该parallel选项添加到任务声明中：\n1234567@servers(['web-1' =&gt; '192.168.1.1', 'web-2' =&gt; '192.168.1.2'])@task('deploy', ['on' =&gt; ['web-1', 'web-2'], 'parallel' =&gt; true])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nRunning Tasks1envoy run deploy\nConfirming Task Execution如果要在服务器上运行给定任务之前提示您进行确认，则应将该confirm指令添加到任务声明中。此选项对于破坏性操作特别有用：\n12345@task('deploy', ['on' =&gt; 'web', 'confirm' =&gt; true])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nNotificationsto be continued\n","plink":"https://spaco.github.io/post/laravel-envoy/"},{"title":"laravel-login","date":"2019-06-14T00:00:00.000Z","updated":"2019-06-14T00:00:00.000Z","content":"Quick Start123456composer create-project --prefer-dist laravel/laravel principle &amp;&amp; cd principlephp artisan make:auth# database configurationvim .envphp artisan db:seed --class=UsersTableSeederphp artisan serve\nLogin RouteAuth::routes();\n12# config/app.php'Auth' =&gt; Illuminate\\Support\\Facades\\Auth::class\n12345# Illuminate\\Support\\Facades\\Auth  public static function routes(array $options = [])  &#123;      static::$app-&gt;make('router')-&gt;auth($options);  &#125;\n1234567# Illuminate\\Routing\\RoutingServiceProviderprotected function registerRouter()&#123;    $this-&gt;app-&gt;singleton('router', function ($app) &#123;        return new Router($app['events'], $app);    &#125;);&#125;\n123456789101112131415161718192021222324# Illuminate\\Routing\\Routerpublic function auth(array $options = [])&#123;    // Authentication Routes...    $this-&gt;get('login', 'Auth\\LoginController@showLoginForm')-&gt;name('login');    $this-&gt;post('login', 'Auth\\LoginController@login');    $this-&gt;post('logout', 'Auth\\LoginController@logout')-&gt;name('logout');    // Registration Routes...    if ($options['register'] ?? true) &#123;        $this-&gt;get('register', 'Auth\\RegisterController@showRegistrationForm')-&gt;name('register');        $this-&gt;post('register', 'Auth\\RegisterController@register');    &#125;    // Password Reset Routes...    if ($options['reset'] ?? true) &#123;        $this-&gt;resetPassword();    &#125;    // Email Verification Routes...    if ($options['verify'] ?? false) &#123;        $this-&gt;emailVerification();    &#125;&#125;\nLogin Action Explainresource codeaccording to Auth::routes(), source code =&gt; Auth\\LoginController@login\n1234567891011# App\\Http\\Controllers\\Auth\\LoginControllernamespace App\\Http\\Controllers\\Auth;use App\\Http\\Controllers\\Controller;use Illuminate\\Foundation\\Auth\\AuthenticatesUsers;class LoginController extends Controller&#123;    use AuthenticatesUsers;&#125;\nIn fact, the main code implementation is in AuthenticatesUsers Trait\n1234567891011121314151617181920212223242526# Illuminate\\Foundation\\Auth\\    public function login(Request $request)    &#123;        $this-&gt;validateLogin($request);        // If the class is using the ThrottlesLogins trait, we can automatically throttle        // the login attempts for this application. We'll key this by the username and        // the IP address of the client making these requests into this application.        if (method_exists($this, 'hasTooManyLoginAttempts') &amp;&amp;            $this-&gt;hasTooManyLoginAttempts($request)) &#123;            $this-&gt;fireLockoutEvent($request);            return $this-&gt;sendLockoutResponse($request);        &#125;        if ($this-&gt;attemptLogin($request)) &#123;            return $this-&gt;sendLoginResponse($request);        &#125;        // If the login attempt was unsuccessful we will increment the number of attempts        // to login and redirect the user back to the login form. Of course, when this        // user surpasses their maximum number of attempts they will get locked out.        $this-&gt;incrementLoginAttempts($request);        return $this-&gt;sendFailedLoginResponse($request);    &#125;\nexplain\nvalidate login form\nrate limiting\nattempt login &amp;&amp; return success response\nincrement login attempts count for rate limiting\nreturn fail response \n\n\nMore important is attempt login\n\nattempt login12345678910if ($this-&gt;attemptLogin($request)) &#123;    return $this-&gt;sendLoginResponse($request);&#125;protected function attemptLogin(Request $request)&#123;    return $this-&gt;guard()-&gt;attempt(        $this-&gt;credentials($request), $request-&gt;filled('remember')    );&#125;\nIn fact, the main code implementation is in Illuminate\\Auth\\SessionGuard  Class\n\nSessionGuard  attempt method\n\n12345678910111213141516171819202122public function attempt(array $credentials = [], $remember = false)&#123;    $this-&gt;fireAttemptEvent($credentials, $remember);    $this-&gt;lastAttempted = $user = $this-&gt;provider-&gt;retrieveByCredentials($credentials);    // If an implementation of UserInterface was returned, we'll ask the provider    // to validate the user against the given credentials, and if they are in    // fact valid we'll log the users into the application and return true.    if ($this-&gt;hasValidCredentials($user, $credentials)) &#123;        $this-&gt;login($user, $remember);        return true;    &#125;    // If the authentication attempt fails we will fire an event so that the user    // may be notified of any suspicious attempts to access their account from    // an unrecognized user. A developer may listen to this event as needed.    $this-&gt;fireFailedEvent($user, $credentials);    return false;&#125;\n\nThe essence is to save a session\n\n1234567  # Illuminate\\Auth\\SessionGuardprotected function updateSession($id)  &#123;      $this-&gt;session-&gt;put($this-&gt;getName(), $id);      $this-&gt;session-&gt;migrate(true);  &#125;\n12345 # Illuminate\\Auth\\SessionGuardpublic function getName() &#123;     return 'login_'.$this-&gt;name.'_'.sha1(static::class); &#125;\n","plink":"https://spaco.github.io/post/laravel-login/"},{"title":"laravel-reset-password","date":"2019-05-20T00:00:00.000Z","updated":"2019-05-20T00:00:00.000Z","content":"Reset PasswordEnvironment[TOC]\nLarval5.8\n\n首先是 ResetPasswordController 的 reset 方法，其实是由引入的 trait ResetsPasswords 内部实现的\n\n123use Illuminate\\Foundation\\Auth\\ResetsPasswords;use ResetsPasswords;\n","thumbnail":"https://spaco.oss-cn-hangzhou.aliyuncs.com/banners/ZhUwdBwIDiIefFYJ.jpg?x-oss-process=image/resize,m_fixed,h_1280,w_720","plink":"https://spaco.github.io/post/laravel-reset-password/"},{"title":"composer-package-build","date":"2019-02-14T00:00:00.000Z","updated":"2019-02-14T00:00:00.000Z","content":"Build composer packagecomposerbuild your composer package\ncreate package floder\n12mkdir package-namecd package-name\n\ninit\n123456789101112131415161718192021222324252627282930313233343536373839 ashe@ashedeMacBook-Pro  ~/code/composer-package/express   master  composer init  Welcome to the Composer config generatorThis command will guide you through creating your composer.json config.Package name (&lt;vendor&gt;/&lt;name&gt;) [ashe/express]: spaco/expressDescription []: get express phpAuthor [spaco &lt;she.ct@outlook.com&gt;, n to skip]:Minimum Stability []: devPackage Type (e.g. library, project, metapackage, composer-plugin) []: libraryLicense []: MITDefine your dependencies.Would you like to define your dependencies (require) interactively [yes]?Search for a package:Would you like to define your dev dependencies (require-dev) interactively [yes]?Search for a package:&#123;    \"name\": \"spaco/express\",    \"description\": \"get express php\",    \"type\": \"library\",    \"license\": \"MIT\",    \"authors\": [        &#123;            \"name\": \"spaco\",            \"email\": \"she.ct@outlook.com\"        &#125;    ],    \"minimum-stability\": \"dev\",    \"require\": &#123;&#125;&#125;Do you confirm generation [yes]?\n此时composer.json生成完毕\n\n\n","plink":"https://spaco.github.io/post/composer-package-build/"},{"title":"flyway","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"FlywayIntroductionVersion control for your database.Robust schema evolution across all your environments.With ease, pleasure and plain SQL.\n数据库的版本控制。跨所有环境的强大架构演变。轻松，愉快和简单的SQL\n官网\nHow Flyway works\nDevelopment environment\nflyway \n1version : 5.2.4\n\nmysql\n1version : 5.7\n\n\nInstalldocker-boxfuse-flyway\n关注 Supported Volumes\n见底部 docker-compose.yml\nConfiguration见底部  Configuration \nTestCreating the first migrationNow create a first migration in the /sql directory called V1__Create_person_table.sql\n1vim V1__Create_person_table.sql\n1234create table PERSON (    ID int not null,    NAME varchar(100) not null);\nConnect docker12docker-compose up -d flywaydocker-compose exec flyway bash\nMigrating the databaseflyway migrate\n1flyway migrate\nIf all went well, you should see the following output:\n123Creating Schema History table: `default`.`flyway_schema_history`Current version of schema `default`: &lt;&lt; Empty Schema &gt;&gt;Migrating schema `default` to version 1 - Create person table\nversion记录，可以在 db 的 flyway_schema_history 数据表中看到\n\nAdding a second migrationIf you now add a second migration to the /sql directory called V2__Add_people.sql\n1vim ./flyway/sql/V2__Add_people.sql\n123insert into PERSON (ID, NAME) values (1, 'Axel');insert into PERSON (ID, NAME) values (2, 'Mr. Foo');insert into PERSON (ID, NAME) values (3, 'Ms. Bar');\nand execute it by issuing:\n1flyway migrate\nyou now get:\n12345Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)Successfully validated 2 migrations (execution time 00:00.137s)Current version of schema `default`: 1Migrating schema `default` to version 2 - Add peopleSuccessfully applied 1 migration to schema `default` (execution time 00:00.523s)\nmigrate version 同样可以在 db 的 flyway_schema_history 数据表看到\nOther commandflyway clean  ：慎用flyway clean\nDrops all objects (tables, views, procedures, triggers, …) in the configured schemas.\nThe schemas are cleaned in the order specified by theschemasproperty.\n删除所有的 表 视图 过程 触发器     所有～～\n1flyway clean\n123Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)Successfully cleaned schema `default` (execution time 00:00.224s)# 此时所有的表都没了\nflyway infoflyway clean\nPrints the details and status information about all the migrations.\n打印有关所有迁移的详细信息和状态信息。\nflyway validate : 可作为 migration 前置命令flyway validate\n假设 开发A 创建了 V2__Add_user.sql , 开发 B 创建了 `V2__Add_user2.sql’,造成版本差错\n此时：ERROR: Found more than one migration with version 2\n1flyway validate\n12345Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)ERROR: Found more than one migration with version 2   # 版本2 migration more than oneOffenders:-&gt; /flyway/sql/V2__Add_people.sql (SQL)-&gt; /flyway/sql/V2__Add_people2.sql (SQL)\nundo ： not supported by Flyway Community Editionundo the most recently applied versioned migration.\nundo\nundo Important notes  ！！！\n\nThis should be complemented with a proper, well tested, backup and restore strategy ： \n\nundo fail : you end up creating home-made alternatives for restoring backups, which need to be properly tested as well.\n\nmaintain backwards compatibility between the DB and all versions of the code currently deployed in production :This way a failed migration is not a disaster. The old version of the application is still compatible with the DB, so you can simply roll back the application code （即 迁移失败不可怕，回滚code保证老代码适应DB）\n\n撤消最近应用的版本化迁移 -target=** 确定版本名\n1flyway undo\nundo is not supported by Flyway Community Edition\n1ERROR: Flyway Pro Edition or Flyway Enterprise Edition upgrade required: undo is not supported by Flyway Community Edition.\nbaselinebaseline\nBaselines an existing database, excluding all migrations up to and including baselineVersion\n生成 版本历史记录库，按照默认流程，版本记录库是已经生成的,默认表名：flyway_schema_history，此步骤可以跳过\n1234flyway baseline# errorDatabase: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)ERROR: Unable to baseline schema history table `default`.`flyway_schema_history` as it already contains migrations\nrepairrepair\nRepairs the Flyway schema history table. This will perform the following actions:\n即 清理 failed migrations，保证版本 log 的完整性\n123flyway repairSuccessfully repaired schema history table `default`.`flyway_schema_history` (execution time 00:00.224s).\nDeploy1234flyway validateflyway migrate#test last\nReferences\nflyway.org\n\nQAQ\ndocker-compose.yml 中，关于command 的设置无效，无法映射到 conf 下，导致 flyway.url 为空\nA :\n使用 volumes ：\nvolumes:\n​        - “./flyway/sql/:/flyway/sql”\n​        - “./flyway/conf/:/flyway/conf”\n\n\nExtraConfiguration\ndocker-compose.yml\n12345678## 事实上，关于 url user 的配置放于 ./flyway/conf/flyway.conf 中，command 中的参数不重要，但是删除 也不行，会无法启动 flyway### Flyway ################################################    flyway:      image: boxfuse/flyway:5.2.4  #也可以去掉版本号，使用最新的      command: -url=jdbc:mysql://db -schemas=myschema -user=root -password=root -connectRetries=60 migrate      volumes:        - \"./flyway/sql/:/flyway/sql\"        - \"./flyway/conf/:/flyway/conf\"\n\n/flyway/conf/flyway.conf\n本次是 copy 一份 conf模版，然后配置相关信息，做 docker 映射\nflyway.conf\nflyway.conf模版\n1234# 本次单纯设置以下三项基础配置， 其余的请自行配置flyway.url=jdbc:mysql://106.14.6.94:3306/db-nameflyway.user=db-user-nameflyway.password=db-password\n\n\ndocker compose 设置flyway environment 为pro不行的～～\n123docker-compose logs flywayERROR: Missing license key. Ensure flyway.licenseKey is set to a valid Flyway license key (\"FL01\" followed by 512 hex chars)\n","plink":"https://spaco.github.io/post/flyway/"},{"title":"mysql-basic","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"Backend ServiceLNMP\n\n操作系统 ：windows / linux（centos / ubuntu）\n\nHTTP 服务器 ： Apache / Nginx\n\n作用目的是一致的, 简单说就是接收用户请求, 然后处理请求, 最后将处理结果返回给用户\n\n\n数据库\n\n关系型数据库 ：, 是指采用了关系模型来组织数据的数据库.  几种常见关系型数据库\n\n\nmysql ：\nOracle :\nSQLite :\nPostgreSQL\n\n\nextra ： 非关系型数据库Nosql (not only sql) :数据也是在逐渐增长和变得复杂、非固定结构化的. 这些所有的变化都是很难在原有的关系型数据库中管理的;\n\n\nkey-value（Redis）:\n文档型 （MongoDB）：\n常见几种nosql特点、区别以及应用场景\n关系型数据库和非关系型数据库的特性以及各自的优缺点\n\n\n\n\nLanguage\nphp\n\n\nMysql Basic官网\n当前最新版本：V8.0\nhttps://www.mysql.com/products/enterprise/database/\nDevelop Environment12mysql -Vversion 5.7.25\n什么是数据库数据库（Database）是按照数据结构来组织、存储和管理数据的仓库. \n每个数据库都有一个或多个不同的 API 用于创建, 访问, 管理, 搜索和复制所保存的数据. \n我们也可以将数据存储在文件中, 但是在文件中读写数据速度相对较慢. \n所以, 现在我们使用关系型数据库管理系统（RDBMS）来存储和管理的大数据量. 所谓的关系型数据库, 是建立在关系模型基础上的数据库, 借助于集合代数等数学概念和方法来处理数据库中的数据. \nRDBMS 即关系数据库管理系统(Relational Database Management System)的特点：\n\n1.数据以表格的形式出现\n2.每行为各种记录名称\n3.每列为记录名称所对应的数据域\n4.许多的行和列组成一张表单\n5.若干的表单组成database\n\nMySQL 是最流行的关系型数据库管理系统, 在 WEB 应用方面 MySQL 是较好的 RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一\n为什么选用Mysql12345678MySQL 是开源的, 所以你不需要支付额外的费用. MySQL 支持大型的数据库. 可以处理拥有上千万条记录的大型数据库. MySQL 使用标准的 SQL 数据语言形式. MySQL 可以运行于多个系统上, 并且支持多种语言. 这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等. MySQL 对PHP有很好的支持, PHP 是目前最流行的 Web 开发语言. MySQL 支持大型数据库, 支持 5000 万条记录的数据仓库, 32 位系统表文件最大可支持 4GB, 64 位系统支持最大的表文件为8TB. MySQL 是可以定制的, 采用了 GPL 协议, 你可以修改源码来开发自己的 MySQL 系统.\n相关概念\n数据库(database) : 数据库是一些关联表的集合\n数据表\n主键(PRIMARY KEY) : 主键是唯一的,一个数据表中只能包含一个主键. 你可以使用主键来查询数据. \n索引(index) :使用索引可快速访问数据库表中的特定信息. 索引是对数据库表中一列或多列的值进行排序的一种结构. 类似于书籍的目录\n表头(header): 每一列的名称;\n列(col): 具有相同数据类型的数据的集合;\n行(row): 每一行用来描述某条记录的具体信息;\n值(value): 行的具体信息, 每个值必须与该列的数据类型相同;\n\n安装\nhttps://www.mysql.com/downloads/\n\nConsole12## 进入mysql容器docker-compose exec mysql bash\n\nconnect\n\n1mysql -u root -p\n\ncreate database\n1234create database zeaho default character set utf8mb4 collate utf8mb4_unicode_ci;## checkshow databases;\n\ndrop database\n1234drop database zeaho;## checkshow databases;\n\nselect database\n在你连接到 MySQL 数据库后, 可能有多个可以操作的数据库, 所以你需要选择你要操作的数据库. \n成功选择了某个数据库后, 在后续的操作中都会在选择的数据库中执行\n123use zeaho;Database changed\n\ncreate datatable\n1234567891011121314151617use zeaho;CREATE TABLE `admin` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,  `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,  `nick_name` char(50) DEFAULT NULL,  `unique_name` char(16) NOT NULL,  `password` varchar(128) NOT NULL,  `is_active` tinyint(3) unsigned NOT NULL DEFAULT '1',  `remember_token` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `unique_name` (`unique_name`)) ENGINE=InnoDB AUTO_INCREMENT=43 DEFAULT CHARSET=utf8mb4;## checkshow tables;\n数据库字段具体如何选择见底部 Expansion\n\ndrop datatable 删除数据表\n1drop table admin;\n\n插入数据\n12345678910INSERT INTO table_name ( field1, field2,...fieldN )                       VALUES                       ( value1, value2,...valueN );                       ## 插入数据INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name', '176', 'secrey', '1dsddas');INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name1', '1761', 'secrey1', '1dsddas1');INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name1', '17612', 'secrey1', '1dsddas1');\n如果数据是字符型, 必须使用单引号或者双引号, 如：”value”. \n\n查询数据\n\n所有列\n1select * from admin;\n\n指定列\n1select id,nick_name from admin;\n\n去重列\n1select distinct（password）from admin;\n\n最大列, 最小列\n12select max(id) from admin;select min(id) from admin;\n\n计数\n1select count(id) from admin;\n\n指定行\n12select * from admin where id = 1 and (id is null or id is not null);select * from admin where nick_name like &apos;%name%&apos;;\n\n多表查询\n123456789101112131415161718## 插入测试数据DROP TABLE IF EXISTS `user`;CREATE TABLE `user` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,  `creator_id` bigint(20) DEFAULT NULL,  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,  `score` int(10) unsigned DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES (1, 43, 'a', 1);INSERT INTO `user` VALUES (3, NULL, 'b', 2);INSERT INTO `user` VALUES (4, NULL, 'c', 4);INSERT INTO `user` VALUES (5, NULL, 'd', 3);INSERT INTO `user` VALUES (6, NULL, 'e', 2);\n1select u.*, a.id as admin_id from user u, admin a where a.id = u.creator_id;\n\n\n\n更新数据\n123## 语法UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause]\n\n你可以同时更新一个或多个字段. \n你可以在 WHERE 子句中指定任何条件. \n你可以在一个单独表中同时更新数据. \n\n12345##单表更新UPDATE `zeaho`.`admin` SET `unique_name` = '17626' WHERE `id` = 43;##多表联合修改update user u,admin a set u.name = 'new name' where a.id = u.creator_id;\n\n删除数据\n12## 语法DELETE FROM table_name [WHERE Clause]\n123如果没有指定 WHERE 子句, MySQL 表中的所有记录将被删除. 你可以在 WHERE 子句中指定任何条件您可以在单个表中一次性删除记录.\n12345##单表删除delete from  `zeaho`.`admin` WHERE `id` = 44;##多表联合删除delete u from user u, admin a where a.id = u.creator_id and u.name = 'real_name';\n\n排序\n1SELECT field1, field2 FROM table_name ORDER BY field1, [field2...] [ASC [DESC]]\n1SELECT * from user where id &gt; 1 ORDER BY score DESC,id ASC;\n\n分组\n1234567SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name;GROUP BY 语句根据一个或多个列对结果集进行分组. 在分组的列上我们可以使用 COUNT(总数), SUM(求和), AVG(平均值),等函数.\n测试数据表\n12345678910111213CREATE TABLE `sign_in` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',  `user_id` bigint(20) unsigned NOT NULL COMMENT '用户id',  `date` date NOT NULL COMMENT '签到时间',  `score` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '上课评分',  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;## 查看测试数据INSERT INTO `sign_in` VALUES (1, 1, '2019-01-31', 1);INSERT INTO `sign_in` VALUES (2, 2, '2019-01-23', 2);INSERT INTO `sign_in` VALUES (3, 2, '2019-01-19', 5);INSERT INTO `sign_in` VALUES (4, 1, '2019-01-19', 7);\n演示：\n1234567891011## COUNT## 查询签到次数SELECT `user_id`, COUNT(*) FROM  sign_in GROUP BY user_id;## SUM## 查询评分总数SELECT `user_id`, SUM(score) FROM  sign_in GROUP BY user_id;## AVG## 查询平均得分SELECT `user_id`, AVG(score) FROM  sign_in GROUP BY user_id;\n\n\nExpansion\n数据库字段的选择\n\n","plink":"https://spaco.github.io/post/mysql-basic/"},{"title":"elasticsearch-build-with-docker-compose","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"ElasticsearchForewordWhy ES\n成熟\n高可用\n高扩展\n\nDevelopment Environment\nelasticsearch\n12## version6.6.0\n\nkibana\n12## version6.6.0\n\n\nPoint Conception\nApache Lucene\nLucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程序界面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。\n\nInverted Index\nLucene实现快速搜索的核心就是倒排索引\n\n全文搜索引擎\n全文搜索引擎是目前广泛应用的搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。\n\nJava\nElasticsearch是使用 Java 开发的\n\nSolr\nSolr是用Java编写、运行在Servlet容器（如Apache Tomcat或Jetty）的一个独立的全文搜索服务器。 Solr采用了Lucene Java搜索库为核心的全文索引和搜索，并具有类似REST的HTTP/XML和JSON的API。 Solr强大的外部配置功能使得无需进行Java编码，便可对其进行调整以适应多种类型的应用程序。Solr有一个插件架构，以支持更多的高级定制。\n\nNear Realtime (NRT)\nElasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可以搜索的时间只有轻微的延迟（通常是1秒\n\nCluster\n集群是一个或多个节点(服务器)的集合，它们共同保存你的整个数据，并提供跨所有节点的联合索引和搜索功能。一个集群由一个唯一的名称标识，默认这个唯一标识的名称是”elasticsearch”。这个名称很重要，因为如果节点被设置为按其名称加入集群，那么节点只能是集群的一部分。\n确保不要在不同的环境中用相同的集群名称，否则可能导致节点加入到错误的集群中。例如，你可以使用”logging-dev”, “logging-test”, “logging-prod”分别用于开发、测试和正式集群的名字。\n\nNode\n节点是一个单独的服务器，它是集群的一部分，存储数据，并参与集群的索引和搜索功能。就像集群一样，节点由一个名称来标识，默认情况下，该名称是在启动时分配给节点的随机通用唯一标识符(UUID)。如果不想用默认的节点名，可以定义任何想要的节点名。这个名称对于管理来说很重要，因为你希望识别网络中的哪些服务器对应于你的Elasticsearch集群中的哪些节点。\n一个节点可以通过配置集群名称来加入到一个特定的集群中。默认情况下，每个节点都被设置加入到一个名字叫”elasticsearch”的集群中，这就意味着如果你启动了很多个节点，并且假设它们彼此可以互相发现，那么它们将自动形成并加入到一个名为”elasticsearch”的集群中。\n一个集群可以有任意数量的节点。此外，如果在你的网络上当前没有运行任何节点，那么此时启动一个节点将默认形成一个单节点的名字叫”elasticsearch”的集群。\n\nIndex\n索引是具有某种相似特征的文档的集合。例如，你可以有一个顾客数据索引，产品目录索引和订单数据索引。索引有一个名称标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。\n\nDocument\n文档是可以被索引的基本信息单元，类似数据库的单条表数据\n\n\nInstall\nDocker\n12345## Elasticsearch DockerfileFROM docker.elastic.co/elasticsearch/elasticsearch:6.6.0EXPOSE 9200 9300\n12345## Kibana DockerfileFROM docker.elastic.co/kibana/kibana:6.6.0EXPOSE 5601\n\nOthers\n\n\nBuild &amp; Start1docker-compose up -d elasticsearch kibana\nCheck\nElasticsearch\nOpen localhost:9200 with your browser\n1234567891011121314151617&#123;  \"name\": \"aJRPWzC\",  \"cluster_name\": \"laradock-cluster\",  \"cluster_uuid\": \"Bd8hjDXlTNSS5yQIondlDg\",  \"version\": &#123;    \"number\": \"6.6.0\",    \"build_flavor\": \"default\",    \"build_type\": \"tar\",    \"build_hash\": \"a9861f4\",    \"build_date\": \"2019-01-24T11:27:09.439740Z\",    \"build_snapshot\": false,    \"lucene_version\": \"7.6.0\",    \"minimum_wire_compatibility_version\": \"5.6.0\",    \"minimum_index_compatibility_version\": \"5.0.0\"  &#125;,  \"tagline\": \"You Know, for Search\"&#125;\n\nKibana\nOpen localhost:5601 with your browser\n\n\nAPIIndex\nCreate Index\n12345678PUT index_name## PUT twitter&#123;  \"acknowledged\" : true,  \"shards_acknowledged\" : true,  \"index\" : \"twitter\"&#125;\n\nIndex List\n1curl -X GET \"localhost:9200/_cat/indices?v\"\n\n\nDocument\nCreate Document\nPUT index_name/_doc\n指定id\n1234567## 指定idPUT twitter/_doc/1&#123;    \"user\" : \"kimchy\",    \"post_date\" : \"2009-11-15T14:12:12\",    \"message\" : \"trying out Elasticsearch\"&#125;\nResult:\n1234567891011121314&#123;  \"_index\" : \"twitter\",  \"_type\" : \"_doc\",  \"_id\" : \"1\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : &#123;    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  &#125;,  \"_seq_no\" : 0,  \"_primary_term\" : 1&#125;\n不指定id\nPOST index_name/_doc\n123456POST twitter/_doc/&#123;    \"user\" : \"kimchy\",    \"post_date\" : \"2009-11-15T14:12:12\",    \"message\" : \"trying out Elasticsearch\"&#125;\n1234567891011121314&#123;  \"_index\" : \"twitter\",  \"_type\" : \"_doc\",  \"_id\" : \"TGap7GgBR1R5Vn49jL0L\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : &#123;    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  &#125;,  \"_seq_no\" : 0,  \"_primary_term\" : 1&#125;\n\nUpdate Document\nPUT index_name/_doc/primark_key\n1234PUT twitter/_doc/1&#123;    \"user\":\"new-kimchy\"&#125;\nResult:\n1234567891011121314&#123;    \"_index\": \"twitter\",    \"_type\": \"_doc\",    \"_id\": \"1\",    \"_version\": 2,    \"result\": \"updated\",    \"_shards\": &#123;        \"total\": 2,        \"successful\": 1,        \"failed\": 0    &#125;,    \"_seq_no\": 1,    \"_primary_term\": 1&#125;\n\nDelete Document\nDELETE index_name/_doc/primark_key\n1DELETE /twitter/_doc/2\nResult:\n1234567891011121314&#123;    \"_index\": \"twitter\",    \"_type\": \"_doc\",    \"_id\": \"2\",    \"_version\": 3,    \"result\": \"deleted\",    \"_shards\": &#123;        \"total\": 2,        \"successful\": 1,        \"failed\": 0    &#125;,    \"_seq_no\": 4,    \"_primary_term\": 1&#125;\n\nSearch Document\n\nEasy Search\nGET /index_name/_search?q=key:value\n1GET /twitter/_search?q=user:kimchy\nResult\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123;    \"took\": 35,    \"timed_out\": false,    \"_shards\": &#123;        \"total\": 5,        \"successful\": 5,        \"skipped\": 0,        \"failed\": 0    &#125;,    \"hits\": &#123;        \"total\": 3,        \"max_score\": 0.2876821,        \"hits\": [            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"TGap7GgBR1R5Vn49jL0L\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"kimchy\",                    \"post_date\": \"2009-11-15T14:12:12\",                    \"message\": \"trying out Elasticsearch\"                &#125;            &#125;,            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"1\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"new-kimchy\"                &#125;            &#125;,            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"3\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"kimchy\",                    \"post_date\": \"2009-11-15T14:12:12\",                    \"messages\": \"trying out Elasticsearch\"                &#125;            &#125;        ]    &#125;&#125;\n\nRequest Body Search\nES 提供了一种JSON风格的 Query DSL (domain specific language)\n使用request body 传递参数，更加灵活\n123456GET /twitter/_search&#123;    \"query\" : &#123;        \"term\" : &#123; \"user\" : \"kimchy\" &#125;    &#125;&#125;\nResult\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123;  \"took\" : 3,  \"timed_out\" : false,  \"_shards\" : &#123;    \"total\" : 5,    \"successful\" : 5,    \"skipped\" : 0,    \"failed\" : 0  &#125;,  \"hits\" : &#123;    \"total\" : 3,    \"max_score\" : 0.2876821,    \"hits\" : [      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"TGap7GgBR1R5Vn49jL0L\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"kimchy\",          \"post_date\" : \"2009-11-15T14:12:12\",          \"message\" : \"trying out Elasticsearch\"        &#125;      &#125;,      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"1\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"new-kimchy\"        &#125;      &#125;,      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"3\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"kimchy\",          \"post_date\" : \"2009-11-15T14:12:12\",          \"messages\" : \"trying out Elasticsearch\"        &#125;      &#125;    ]  &#125;&#125;\n\n\n\n\nTest数据量为 223479条\n12345## mysql 用时:11.081sSELECT * FROM company WHERE company_name LIKE \"%建%\"## es &lt; 1slocalhost:9200/company-100/_doc/_search?q=company_name:建\nExtra\n本次测试223479条mysql数据为60.58MB，导入ES后,查看http://localhost:9200/_cat/indices?v，数据为106.6MB\n\nReferences\nhttp://solr-vs-elasticsearch.com/\nelasticsearch document\n为什么Elasticsearch/Lucene检索可以比MySQL快\n百度指数对比\n\n","plink":"https://spaco.github.io/post/elasticsearch-build-with-docker-compose/"},{"title":"mysql-transaction","date":"2018-12-09T00:00:00.000Z","updated":"2018-12-09T00:00:00.000Z","content":"数据库事务（Database Transaction）,是指作为单个逻辑工作单元执行的一系列操作，要么完全执行，要么完全地不执行\n案例\nA 转账给B 6元,  需要保证，A减少 6 元，B增加 6 元，缺一不可\n\nDevelopment Environment\nmysql \n1version: 5.7\n\n\n相关概念\nACID特性\nAtomicity ： 原子性\n一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位\nConsistency ： 一致性\n事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到\nIsolation ： 隔离性\n数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）\nDurability ： 持久性\n事务完成后，事务对数据库的所有更新将被保存到数据库，不可回滚\n\n事务隔离级别\nread-uncommitted  ： 读未提交\nread-committed  ： 读已提交 \nrepeatable-read  ：  可重复读   (mysql5.7默认级别)\nserializable  ：  串行化\n\n\nACIDCreate test data123456789101112# 创建数据库create database transaction default character set utf8mb4 collate utf8mb4_unicode_ci;# 创建数据表CREATE TABLE `transaction`.`account`  (  `id` bigint(11) UNSIGNED NOT NULL AUTO_INCREMENT,  `name` varchar(55) NULL COMMENT '姓名',  `balance` decimal(10, 2) NULL COMMENT '余额',  PRIMARY KEY (`id`)) COMMENT = '账号表';# 插入测试数据INSERT INTO `transaction`.`account`(`name`, `balance`) VALUES ('joe', 450);INSERT INTO `transaction`.`account`(`name`, `balance`) VALUES ('she', 600);\n隔离级别 举例说明\nread-uncommitted\n\n打开客户端 A ,并设置当前事务级别为read-uncommitted（未提交读），并查询表account的初始值\n1234567891011121314151617# 进入 mysql 命令行mysql -uroot -proot# 设置当前窗口事务级别为 read uncommittedset session transaction isolation level read uncommitted;# Query OK, 0 rows affected (0.00 sec)use transaction;start transaction;select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 B ,同样设置当前事务级别为 read uncommitted ，并更新数据\n12345mysql -uroot -prootset session transaction isolation level read uncommitted;use transaction;start transaction;update account set balance = balance-50 where id = 1;\n\n返回客户端 A，B 的事务未提交, 窗口 A 仍然可以查看更新后的数据\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n返回客户端 B,假设因为异常数据回滚，那么此时客户端 A 返回给用户的数据就是 脏数据\n12345678910111213141516171819202122232425# 客户端 Bselect * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)# Q1:回滚之前，id=1 id=2两条数据是否可写？# 回滚rollback;select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 A ,执行减少 50 的更新操作，结果并不是400-50=350, 而是 400，用户把钱全转出去，操作结束发现还剩50\n在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用 read-committed 的隔离级别\n1234567891011121314151617181920212223# 客户端 Amysql&gt; select * from account;  # 此步骤是在客户端 B 未rollback 时执行+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)# 以下命令是在rollback 已执行的情况下运行mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n\n\nread committed\n\n打开一个客户端 A，并设置当前事务模式为read committed，查询表account的所有记录：\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.01 sec)\n\n打开客户端 B, 开启一个事务，并更新数据\n12345678910111213141516# 客户端 Bmysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 A, 查看所有记录，未读取到 B 已经更新的数据 ,  解决了脏读\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n打开客户端 B, 提交事务\n123456789mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+commit;\n\n打开客户端 A, 执行查看所有的查询，发现与上一步结果不一致,产生 不可重复读 问题\n1234567891011121314151617mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n\n\nrepeatable read\n\n打开客户端 A, 查询表account的所有记录\n123456789set session transaction isolation level repeatable read;start transaction;mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A的事务提交之前，打开另一个客户端B，更新表account\n1234567891011mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.01 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A查询表account的所有记录，与上一步查询结果一致，没有出现不可重复读的问题\n12345678910111213141516mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A，接着执行balance = balance - 50 where id = 1，balance没有变成400-50=350，balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）\n1234567891011121314151617181920212223mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; update balance = balance - 50 where id = 1;mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  300.00 ||  2 | she  |  600.00 |+----+------+---------+commit;\n\n重新打开客户端B，插入一条新数据\n1234567891011mysql&gt; insert into account values(4,'kid',700);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 ||  4 | kid  |  700.00 |+----+------+---------+\n\n在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读\n1234567mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n\n\nserializable\n\n打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值：\n1234567891011121314mysql&gt; set session transaction isolation level serializable;Query OK, 0 rows affected (0.00 sec)mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 ||  4 | kid  |  700.00 |+----+------+---------+\n\n打开一个客户端 B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到\n1234set session transaction isolation level serializable;mysql&gt; insert into account values(5,'tom',0);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\n\n\n\n查看隔离级别mysql默认的事务处理级别是’REPEATABLE-READ’,也就是可重复读\n\n查看当前会话隔离级别\n\nselect @@tx_isolation;\n\n查看系统当前隔离级别\n\nselect @@global.tx_isolation;\n\n设置当前会话隔离级别\n\nset session transaction isolatin level repeatable read;\n\n设置系统当前隔离级别\n\nset global transaction isolation level repeatable read;\n","plink":"https://spaco.github.io/post/mysql-transaction/"},{"title":"php-garbage-collection","date":"2018-12-09T00:00:00.000Z","updated":"2018-12-09T00:00:00.000Z","content":"Explains Garbage Collection (also known as GC) of PHPPHP LanguagePHP 是脚本语言，所谓脚本语言，就是说PHP并不是独立运行的，要运行PHP代码需要PHP解析器，用户编写的PHP代码最终都会被PHP解析器解析执行，PHP的执行是通过 Zend engine（ZE, Zend引擎），ZE是用C编写的，用户编写的PHP代码最终都会被翻译成PHP的虚拟机ZE的虚拟指令（OPCODES）来执行，也就说最终会被翻译成一条条的指令\n概念\nGarbage Collection : GC\n\nPHP 5.2以前, PHP使用引用计数(Reference counting)来做资源管理，PHP 5.3才引入GC\n\nzval  ：所有的变量都是用一个结构 zval 结构来保存的\n\nvalue : 值，是真正保存数据的关键部分，定义为一个联合体(union)\ntype : 储存变量的类型 \nis_ref ：被 &amp; 引用的数量\nrefcount ：引用计数，记录了当前的 zval 被引用的次数（这里的引用并不是真正的 &amp; ，而是有几个变量指向它）\n\n\nCopy On Write  \n\nChange On Write\n\n过程\nPHP5.2 : Reference Counting : 引用计数，GC根本算法\nPHP5.3 : Concurrent Cycle Collection in Reference Counted Systems\n\nfunction : memory_get_usage\n\nfunction : xdebug_debug_zval() : 需要安装xdebug\n\nfunction : debug_zval_dump  当不使用xdebug时，可以作为替代xdebug_debug_zval 的方法\n\n\nIntrodution\nzval\n声明一个变量\n1$addr = 'i value';\nPHP内部都是使用 zval 来表示变量的，那对于上面的脚本，ZE是如何把 $addr 变量 和内部的 zval 结构联系起来的呢？变量都是有名字的（本例中变量名为 $addr ），而 zval 中并没有相应的字段来体现变量名。PHP内部有一个机制，来实现变量名到 zval 的映射，在PHP中，所有的变量都会存储在一个 hash table中，当你创建一个变量的时候，PHP会为这个变量分配一个 zval，填入相应的信息，然后将这个变量的名字和指向这个 zval 的指针填入一个数组中。当你获取这个变量的时候，PHP会通过查找 hash table，取得对应的 zval\n注意：数组和对象这类复合类型在生成zval时，会为每个单元生成一个 zval\n\n\n\n\n释放内存\n我们经常说每个变量都有一个内存地址，那这个 zval 和变量的内存地址，这俩有什么关系吗？定义一个变量会开辟一块内存，这块内存好比一个盒子，盒子里放了zval，zval里保存了变量的相关信息，需要开辟多大的内存，是由zval所占空间大小决定的，zval是内存对象，垃圾回收的时候会把zval和内存地址（盒子）分别释放掉\n\nrefcount  is_ref\n123$a = 'string';$b = $a;unset($a);\n第一行代码创建变量 a ,申请了 6 字节内存，\n第二行代码定义了变量 b, 将 a 的值赋予 b\n第三行代码释放了变量 a\n如果对于每一个变量重新分配内存，那么变量 a b要申请 12 字节的内存，并且变量 a,还是个无用的数据（被unset了），那么有没有什么方法节省这块资源呢？将变量 a b对应的指针指向同一个 zval 即可\nrefcount\nrefcount 指的是变量被引用的次数（reference count ?）,这里的引用并不是真正的 &amp; ，而是有几个变量指向它\n12$a = 1;$b = $a;\n第一行，创建了一个变量 a，变量值是 1。 此时保存int 1 的这个 zval 的 refcount 为 1第二行，创建了一个新的整形变量（通过赋值的方式），变量也指向刚才创建的 zval，并将这个 zval 的 refcount 加1，此时这个 zval 的 refcount 为2所以，这个时候（通过值传递的方式赋值给别的变量），并没有产生新的 zval，两个变量指向同一 zval，通过一个计数器来共用 zval 及内存地址，以达到节省内存空间的目的当一个变量被第一次创建的时候，它对应的 zval 结构的 refcount 的值会被初始化为 1，因为只有这一个变量在用它。但是当你把这个变量赋值给别的变量时，refcount 属性便会 加1 变成 2，因为现在有两个变量在用这个 zval 结构了\n\ndebug_zval_dump\n1234$a = 1;debug_zval_dump($a);$b = $a;debug_zval_dump($a);\n输出：\n12long(1) refcount(2)long(1) refcount(3)\n如果你奇怪 ，var的refcount应该是1啊？我们知道，对于简单变量，PHP是以传值的形式传参数的。也就是说，当执行debug_zval_dump($var)的时候，var会以传值的方式传递给debug_zval_dump，也就是会导致var的refcount加1，所以只要能看到，当变量赋值给一个变量以后，能导致zval的refcount加 1\n例子：\n123456$a = 1;$b = $a;$c = $b;$d = $a;# long(1) refcount(5)debug_zval_dump($a);\n\nunset\n当 unset(var) 的时候，它删除符号表里的var的信息，准备清理它对应的zval及内存空间，这时它发现var对应的zval结构的 refcount 值是 &gt; 1，也就是说，还有另外一个变量在一起用着这个zval，所以unset只需把这个zval的refcount减去1就行了\n例子：\n123456$a = 1;$b = $a;unset($a);# long(1) refcount(2)debug_zval_dump($b);\n\nCopy On Write\n写入时复制是指：在 用变量对变量进行赋值时，这些相同值的变量指向同一块内存，只有当这些指向同一块内存的 相同值的变量 中的某一个变量的值 发生改变的时候，才需要进行变量分离，即：将 值发生改变的变量分离出来\n使用场景：变量的多次赋值；函数的参数传递。\nPHP中，Zend引擎为了区分同一块内存是否被多个变量引用，在zval结构中定义了ref_count和is_ref两个变量。\nref_count定义了内存被变量引用的次数，次数为0时销毁\nis_ref定义了变量是否被强制引用，被强制引用时，值为1\n1234$a = 1;$b = &amp;$a;$a 的 is_ref = 1;\n例子：\n12345678$a = 1;$b = $a;$a = 2;# long(2) refcount(2)debug_zval_dump($a);# long(1) refcount(2)debug_zval_dump($b);\nPHP在修改一个变量以前，会首先查看这个变量的refcount，如果refcount大于1，PHP就会执行一个分离的过程（在Zend引擎中，分离是破坏一个引用对的过程）对于上面的代码，当执行到第三行的时候，PHP发现var想要改变，并且它指向的zval的refcount大于1，那么PHP就会复制一个新的zval出来，改变其值，将改变的变量指向新的zval（，并将原zval的refcount减1，并修改symbol_table里该变量的指针，使得 a 和 b 分离(Separation)。这个机制就是所谓的copy on write（写时复制，这里的写包括普通变量的修改及数组对象里的增加、删除单元操作）\n\nChange On Write\n使用变量复制的时候 ，PHP内部并不是真正的复制，而是采用指向相同的zval结构来节约开销。那么，对于PHP中的引用，又是如何实现呢\n123456$a = 1;$reference = &amp;$a;$a = 2;# refcount(2)  is_ref(1)xdebug_debug_zval( 'a' );\n代码运行结果，$a 会被改为 2, 这个过程叫做 change on write, ZE 如何得知是否采用 Separation ？这个需要用到 \n$a 的 is_ref属性，它代表是否被 &amp; 引用，变量的 is_ref 默认为 0 ，大于 0则表示被引用，当 is_ref &gt; 0 或者 refcount = 1,此时不需要 Separation，而是直接修改 zval 的值\n123if($if_ref || $refcount = 1)&#123;    # alter zval instead of Separation&#125;\n尽管已经存在写时复制和写时改变，但仍然还存在一些不能通过is_ref和refcount来解决的问题\n123$var = 1;$var_dup = $a;$var_ref = &amp;$var;\n当执行第二行代码的时候,变量的值必须分离成两份完全独立的存在，也就是说php将一个zval的isref从0设为1之前，当然此时refcount还没有增加，会看该zval的refcount，如果refcount&gt;1，则会分离, 将var_dup分离出去，并将var和var_ref做change on write关联。也就是，refcount=2, is_ref=1.所以内存会给变量var_dup 分配出一个新的zval，类型与值同 var和var_ref指向的zval一样，是新分配出来的，尽管他们拥有同样的值，但是必须通过两个zval来实现。试想一下，如果三者指向同一个zval的话，改变 $vardup的值，那么var和 var_ref 也会受到影响，这样是错误的\n\n类似的：\n123$a = 1;$b = &amp;$a;$c = $a;\n\n\ndebug_zval_dump 参数是引用的话，refcount永远为1\n12345$a = 1;$b = &amp;$a;# long(1) refcount(1)debug_zval_dump($a);\nPHP先看变量指向的zval是否被引用，如果是引用，则不再产生新的zval甭管哪个变量引用了它，比如有个变量a被引用了，b=&amp;a，就算自己引用自己a=&amp;a，a所指向的zval都不会被复制，改变其中一个变量的值，另一个值也被改变（change on write）如果is_ref为0且refcount大于1，改变其中一个变量时，复制新的zval（copy on write）\n\n\nReference CountingPHP5.2中使用的内存回收算法是Reference Counting，中文叫做“引用计数”，其思想非常直观和简洁：为每个内存对象分配一个计数器，当一个内存对象建立时计数器初始化为1（因此此时总是有一个变量引用此对象），以后每有一个新变量引用此内存对象，则计数器加1，而每当减少一个引用此内存对象的变量则计数器减1，当垃圾回收机制运作的时候，将所有计数器为0的内存对象销毁并回收其占用的内存。而PHP中内存对象就是zval，而计数器就是refcount。\nImportant : Reference Counting Basics\n出现的问题 ： 引用的值为变量自身，内存泄漏 -&gt; 泄露实例\n123$a = array( 'one' );$a[] =&amp; $a;xdebug_debug_zval( 'a' );\n12345# 类似如下a: (refcount=2, is_ref=1)=array (   0 =&gt; (refcount=1, is_ref=0)='one',   1 =&gt; (refcount=2, is_ref=1)=...)\n图示：\n\n能看到数组变量 (a) 同时也是这个数组的第二个元素(1) 指向的变量容器中“refcount”为 2。上面的输出结果中的”…”说明发生了递归操作, 显然在这种情况下意味着”…”指向原始数组。\n跟刚刚一样，对一个变量调用unset，将删除这个符号，且它指向的变量容器中的引用次数也减1。所以，如果我们在执行完上面的代码后，对变量 a 调用unset, 那么变量 $a 和数组元素 “1” 所指向的变量容器的引用次数减1, 从”2”变成”1”. 下例可以说明:\n12345678unset($a);xdebug_debug_zval( 'a' );(refcount=1, is_ref=1)=array (   0 =&gt; (refcount=1, is_ref=0)='one',   1 =&gt; (refcount=1, is_ref=1)=...)\n\n清理变量容器的问题(Cleanup Problems)尽管不再有某个作用域中的任何符号指向这个结构(就是变量容器)，由于数组元素“1”仍然指向数组本身，所以这个容器不能被清除 。因为没有另外的符号指向它，用户没有办法清除这个结构，结果就会导致内存泄漏。庆幸的是，php将在脚本执行结束时清除这个数据结构，但是在php清除之前，将耗费不少内存。如果你要实现分析算法，或者要做其他像一个子元素指向它的父元素这样的事情，这种情况就会经常发生。当然，同样的情况也会发生在对象上，实际上对象更有可能出现这种情况，因为对象总是隐式的被引用。\n如果上面的情况发生仅仅一两次倒没什么，但是如果出现几千次，甚至几十万次的内存泄漏，这显然是个大问题。这样的问题往往发生在长时间运行的脚本中，比如请求基本上不会结束的守护进程(deamons)或者单元测试中的大的套件(sets)中。后者的例子：在给巨大的eZ(一个知名的PHP Library) 组件库的模板组件做单元测试时，就可能会出现问题。有时测试可能需要耗用2GB的内存，而测试服务器很可能没有这么大的内存。\n###回收周期(Collecting Cycles)\nPHP5.3的垃圾回收算法仍然以引用计数为基础，但是不再是使用简单计数作为回收准则，而是使用了一种同步回收算法，这个算法由IBM的工程师在论文Concurrent Cycle Collection in Reference Counted Systems中提出。 \n首先PHP会分配一个固定大小的“根缓冲区”，这个缓冲区用于存放固定数量的zval，这个数量默认是10,000，如果需要修改则需要修改源代码Zend/zend_gc.c中的常量GC_ROOT_BUFFER_MAX_ENTRIES然后重新编译。\n由上文我们可以知道，一个zval如果有引用，要么被全局符号表中的符号引用，要么被其它表示复杂类型的zval中的符号引用。因此在zval中存在一些可能根（root）。这里我们暂且不讨论PHP是如何发现这些可能根的，这是个很复杂的问题，总之PHP有办法发现这些可能根zval并将它们投入根缓冲区。\n当根缓冲区满额时，PHP就会执行垃圾回收，此回收算法如下：\n\n对每个根缓冲区中的根 zval 按照深度优先遍历算法遍历所有能遍历到的 zval ，并将每个 zval 的 refcount 减1，同时为了避免对同一 zval 多次减1（因为可能不同的根能遍历到同一个 zval ），每次对某个zval减1后就对其标记为“已减”。\n\n再次对每个缓冲区中的根 zval 深度优先遍历，如果某个 zval 的 refcount 不为0，则对其加1，否则保持其为0。\n\n清空根缓冲区中的所有根（注意是把这些 zval 从缓冲区中清除而不是销毁它们），然后销毁所有 refcount 为0的zval，并收回其内存。\n\n\n如果不能完全理解也没有关系，只需记住PHP5.3的垃圾回收算法有以下几点特性：\n\n并不是每次 refcount 减少时都进入回收周期，只有根缓冲区满额后在开始垃圾回收。\n\n可以解决循环引用问题。\n\n可以总将内存泄露保持在一个阈值以下。\n\n\nPHP 5.2 与 PHP 5.3 垃圾回收算法的性能比较参考 PHP Manual\nReferences\nPHP Manual GC\n\nzval _ 引用计数 _ 变量分离 _ 写时拷贝\n\n浅谈PHP5中垃圾回收算法(Garbage Collection)的演化\n\n\n","plink":"https://spaco.github.io/post/php-garbage-collection/"},{"title":"recommended-software-install","date":"2018-12-08T00:00:00.000Z","updated":"2018-12-08T00:00:00.000Z","content":"macprogram development\nnavicat\n\njetbrains\n\npostman\napi 调试工具\n\ntransmit \n ftp 工具\n\nsiteSucker\n爬站\n\nrds\nredis 客户端工具\n\nswithhost\n切换 hosts ,解决了来回切换测试 正式环境的问题\n\ngo2Shell\n\niterm2\niterm2 + go2shell 在 finder中打开当年目录的 bash ,可定制主题\n\n收到\n\n\nextra\nAlfred\n\ntypora\n\nPaste\n保存每次复制内容\n\nthe  Unarchiver\n解压缩软件\n\n\n\nwindowsprogram development\nnavicat\n\njetbrains\n\npostman\napi 调试工具\n\nrds\nredis 客户端工具\n\nswithhost\n切换 hosts ,解决了来回切换测试 正式环境的问题\n\n\nextra- \n","plink":"https://spaco.github.io/post/recommended-software-install/"},{"title":"zsh","date":"2018-12-05T00:00:00.000Z","updated":"2018-12-05T00:00:00.000Z","content":"##Install zsh(oh-my-zsh) &amp;&amp; plugins &amp;&amp; themes\nzsh (oh-my-zsh)Why zsh样式不错 插件多 \nInstallzsh-github\n1sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\nPluginsEnabling PluginsOnce you spot a plugin (or several) that you’d like to use with Oh My Zsh, you’ll need to enable them in the .zshrc file. You’ll find the zshrc file in your $HOME directory. Open it with your favorite text editor and you’ll see a spot to list all the plugins you want to load.\n123vi ~/.zshrc# For example, this might begin to look like this:plugins=(git autojump zsh-autosuggestions zsh-syntax-highlighting)\n###Plugin recommendation\ngitBring your own\n####zsh-syntax-highlighting\n\nGithub\n\n1234567git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting# update ~/.zshrc pluginsplugins=( [plugins...] zsh-syntax-highlighting) # refresh ~/.zshrc source ~/.zshrc\nzsh-autosuggestion\nGithub\n\n1234567git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions# update ~/.zshrc pluginsplugins=( [plugins...] zsh-autosuggestions) # refresh ~/.zshrc source ~/.zshrc\nGit-open1234567git clone https://github.com/paulirish/git-open.git $ZSH_CUSTOM/plugins/git-open# update ~/.zshrc pluginsplugins=( [plugins...] git-open) # refresh ~/.zshrc source ~/.zshrc\nThemesyspyenv\nbrew\n npm cnpm\nhttps://github.com/pyenv/pyenv#basic-github-checkout\n","plink":"https://spaco.github.io/post/zsh/"},{"title":"mq-introduction","date":"2018-11-23T00:00:00.000Z","updated":"2018-11-23T00:00:00.000Z","content":"MQ 简述什么是MQ消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它。\n主流MQ\nActiveMQ\nRabbitMQ\nKafka\nRocketMQ\nZeroMQ\n\n\n应用场景当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。\n\n异步处理\n应用解耦\n流量削峰\n其他\n\n使用与否\n使用\n\n譬如\n过安检，检测器处理能力有限，同时这些行李又不能丢了，加了个传送带，慢慢过检测器。其实这个传送带就是消息队列\n用户下单后，24小时未支付，需要取消订单。以前我们可能是定时任务循环查询，然后取消订单。实际上，我更推荐类似延迟MQ的方式，避免了很多无效的数据库查询，将一个MQ设置为24小时后才让消费者消费掉，这样很大程度上能减轻服务器压力\n帖子更新，关注者收到信息\n\n场景举例异步处理\n用户提交信息注册后，网站需要给用户发送邮件和短信\n\n传统做法\n将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端\n\n不考虑网络等其他开销，耗费时间150ms\n优化：\n引入消息队列，用户的响应时间相当于是注册信息写入数据库的时间，也就是50ms。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50ms。\n\n应用解耦\n凌晨进行数据统计task,这些task之间有一定的数据依赖关系\n\ntask3 需要使用task2的输出作为输入，task2 需要使用task1的输出作为输入，这样的话，tast1, task2, task3之间就有任务依赖关系，必须 task1 先执行，再 task2 执行，再 task3 执行。\n不使用MQ\n方案\ntask1，0:00 执行，经验执行时间为 50 分钟\ntask2，1:00 执行（为 task1 预留 10 分钟 buffer），经验执行时间也是 50 分钟\ntask3，2:00 执行（为 task2 预留 10 分钟 buffer）\n\n\n\n\n\n问题\n如果有一个任务执行时间超过了预留 buffer 的时间，将会得到错误的结果\n总任务的执行时间变长，总是要预留很多 buffer，如果前置任务提前完成，后置任务不会提前开始\n如果有一个任务的执行时间要调整，将会有多个任务的执行时间要调整\n\n\n\n使用MQ\n方案\ntask1 准时开始，结束后发一个“task1 done”的消息\ntask2 订阅 “task1 done” 的消息，收到消息后第一时间启动执行，结束后发一个 “task2 done” 的消息\ntask3 订阅 “task2 done” 的消息，收到消息后第一时间启动执行\n\n\n优点\n不需要预留 buffer，上游任务执行完，下游任务总会在第一时间被执行\n依赖多个任务，被多个任务依赖都很好处理，只需要订阅相关消息即可\n有任务执行时间变化，下游任务都不需要调整执行时间\n\n\n\nMQ只用来传递上游任务执行完成的消息，并不用于传递真正的输入输出数据。\n流量削峰\n系统A一天中大部分时间每秒请求并发数量就 100 多个，但是中午12点-1点每秒请求并发量就飙升到 10000 多个，但是系统每秒最大能处理的请求量只有 1000 多\n秒杀业务：上游发起下单操作,下游完成秒杀业务逻辑（库存检查，库存冻结，余额检查，余额冻结，订单生成，余额扣减，库存扣减，生成流水，余额解冻，库存解冻）上游下单业务简单，每秒发起了10000个请求，下游秒杀业务复杂，每秒只能处理2000个请求，很有可能上游不限速的下单，导致下游系统被压垮\n\n不使用MQ过大流量引起服务器崩溃\n使用MQ\n将非即时处理的业务逻辑进行异步化\n实例某电商网站新手机发布在即，拥有预约码的用户可优先购买手机。预约方式为：注册账户即可获得预约码，预计预约用户超过1000万\n像双11秒杀、手机预约抢购等对 IO 时延敏感业务环境下，当外部请求超过系统处理能力时，如果系统没有做相应保护，可能由于历史累计的超时请求负荷过多而导致系统处理的每个请求都因超时而无效，系统对外呈现的服务能力为 0，且这种情况下服务不能自动恢复。\n\n这种情形下，引入MQ，将非即时处理的业务逻辑进行异步化。比如服务接收请求、处理请求和返回请求三个不同的业务逻辑。\n引入 MQ 后，当预约活动开始时，海量并发访问汹涌袭来：\n\n所有客户的预约申请，页面均立即返回成功。客户便可关闭网页进行其他活动。预约码稍后推送到客户的邮箱/手机；\n\n超过千万级别的注册、预约申请，先暂存在 MQ 消息队列集群；\n\n后端服务进行处理，按照数据库实际的select、insert、update能力处理注册、预约申请；\n\n处理成功后返回结果给用户。预约结束后，用户大约在5-30min内，都收到了预约码。\n\n\n引入MQ带来的问题\n可用性降低 系统引入的外部依赖越多，越容易挂掉，MQ 挂掉之后会导致整个系统不可用。\n\n复杂度提高 重复消费、消息丢失、消息的顺序性等这些都是引入 MQ 之后需要考虑的事情\n\n一致性问题 \nA 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，就会导致数据不一致\n\n\n参考\nMQ消息队列选型\n\n\n","plink":"https://spaco.github.io/post/mq-introduction/"},{"title":"api-gateway-introduction","date":"2018-10-23T00:00:00.000Z","updated":"2018-10-23T00:00:00.000Z","content":"API GatewayForeword在非技术术语中，“网关或门是进入一个由墙围住的封闭空间的入口点。”同理，API网关是指位于防火墙或互联网后面的服务的入口点。在微服务的世界中，网关坐镇于API前面，直接面向客户并进行反向代理。\nPros and cons of using API gateways\n好处：降低构建微服务的复杂性；微服务模拟与虚拟化\n弊端：在架构上需要额外考虑更多编排与管理；路由逻辑配置要进行统一的管理\n网关会为端到端响应时间带来额外的延迟。\n潜在的性能瓶颈\n如果没有明智地选择网关，将会增加额外的运营开销和成本\n\n\n\nCommon GatewaysZuul\nKong\n","plink":"https://spaco.github.io/post/api-gateway-introduction/"},{"title":"kafka-build-with-docker-compose","date":"2018-10-05T00:00:00.000Z","updated":"2018-10-05T00:00:00.000Z","content":"Build Kafka with docker-composeKafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。此外，Kafka可以通过Kafka Connect连接到外部系统（用于数据输入/输出），并提供了Kafka Streams——一个Java流式处理库 (计算机)\nKafka是一个分布式的、高吞吐量、高可扩展性的消息系统。Kafka 基于发布/订阅模式，通过消息解耦，使生产者和消费者异步交互，无需彼此等待。Ckafka 具有数据压缩、同时支持离线和实时数据处理等优点，适用于日志压缩收集、监控数据聚合等场景\nprecondition\nkafka\n\nkafka-manager\n\nzookeeper\n本次测试 docker 已安装kafka zookeeper kafaka-manager,不讲述具体安装流程，如何安装查看结尾docker-compose.yml既可\n\n\n关键名词\nbroker：kafka集群包含一个或者多个服务器，服务器就称作broker\nproducer：负责发布消息到broker\nconsumer：消费者，从broker获取消息\ntopic：发布到kafka集群的消息类别。\npartition：每个topic划分为多个partition。\ngroup：每个partition分为多个group\n\n可用性测试   后续bash: –zookeeper ZookeeperName ： ZookeeperName指的是本地zookeeper的名字\n\n进入指定kafka容器\n1docker-compose exec kafka bash\n\n创建topic\n12345# cd KAFKA_HOME/bin/cd /opt/kafka_2.11-2.0.1/bin/kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 --partitions 1 --topic X# Created topic \"send-register-sms\".\n\n查看创建的topic\n1234# 查看zookeeper topicskafka-topics.sh --list --zookeeper zookeeper:2181# 查看某个topickafka-topics.sh --zookeeper zookeeper:2181 --describe --topic send-register-sms\n\n发送信息\n123kafka-console-producer.sh --broker-list localhost:9092 --topic=x&#123;\"phone\":\"17626041111\"&#125;\n\n新窗口接收信息\n1234567# cd KAFKA_HOME/bin/cd /opt/kafka_2.11-2.0.1/bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic x# 当出现发送的消息  success~&#123;\"phone\":\"17626041111\"&#125;\n 这个时候每次断开，再次bash进入消费的时候，会拉取所有的消息，而我们需要获取从断开点之后创建的信息\n1kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic test --consumer-property group.id=group1\n消费组\n\n\nreference\n使用Docker快速搭建Kafka开发环境\nkafka-python重复消费的问题\nkafka系列-进阶篇之消费组\nPython操作分布式流处理系统Kafka\n\n\nQAQ\nWARN [Producer clientId=console-producer] Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\ndocker-compose.yml kafka设置的 KAFKA_ADVERTISED_HOST_NAME 问题，改成 bash: ipconfig getifaddr en0  显示的ip值即可\n123REAL_IP = ipconfig getifaddr en0kafka \tKAFKA_ADVERTISED_HOST_NAME: REAL_IP\n\n修改配置后 rebuild kafka 显示 kafka uses an image, skipping  (已经把zookeeper kafka-manager 关闭)\n12345## force createdocker-compose up -d --force-recreate kafkadocker-compose up -d --force-recreate zookeeperdocker-compose up -d kafka zookeeper\n\n本地连接不用的wifi 导致ip变化\n123456docker-compose stop kafka zookeeperdocker-compose rm kafka zookeeperdocker-compose up -d --force-recreate kafkadocker-compose up -d --force-recreate zookeeperdocker-compose up -d kafka zookeeper\n\nWARN [Consumer clientId=consumer-1, groupId=group1] 1 partitions have leader brokers without a matching listener, including [test-0] (org.apache.kafka.clients.NetworkClient)\n\n\nRemarks\ngroup_id 不需要配置，用户确定名称即可\n\ndocker-compose.yml\n12345678910111213141516171819202122232425262728293031### Zookeeper ################################################    zookeeper:      image: wurstmeister/zookeeper      container_name: zookeeper      restart: always      ports:        - \"2181:2181\"### Kafka ################################################        kafka:      image: wurstmeister/kafka      container_name: kafka      ports:        - \"9092:9092\"      environment:        KAFKA_ADVERTISED_HOST_NAME: 192.168.1.112        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181      volumes:        - /var/run/docker.sock:/var/run/docker.sock### Kafka-manager ################################################     kafka-manager:      image: sheepkiller/kafka-manager                      ports:          - \"9003:9000\"           environment:        ZK_HOSTS: zookeeper:2181        APPLICATION_SECRET: \"random-secret\"        KAFKA_MANAGER_AUTH_ENABLED: \"true\"        KAFKA_MANAGER_USERNAME: \"admin\"        KAFKA_MANAGER_PASSWORD: \"secret\"\n\n\ndrwxr-xr-x@  26 ashe  staff   832B Dec  6 20:40 cache\n","plink":"https://spaco.github.io/post/kafka-build-with-docker-compose/"},{"title":"kafka-case-with-python","date":"2018-10-05T00:00:00.000Z","updated":"2018-10-05T00:00:00.000Z","content":"Kafka in pythonBuild kafkaenvironment\nkafka \n12find / -name \\*kafka_\\* | head -1 | grep -o '\\kafka[^\\n]*'kafka_2.11-2.0.1\n\npython\n12python -V    #use pyenv3.6.6\n\nzookeeper\n12345678910111213141516version:echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /172.23.0.1:41242[0](queued=0,recved=1,sent=0) /172.23.0.2:49830[1](queued=0,recved=1152,sent=1153)Latency min/avg/max: -33/0/91Received: 5129Sent: 5139Connections: 2Outstanding: 0Zxid: 0xa3Mode: standaloneNode count: 133\n\n\nTest\nInstall Python Client\nkafka-python 1.4.4\n1pip install kafka-python\n\nProducer\n1234567891011121314151617# coding=utf-8from kafka import KafkaProducerimport timeproducer = KafkaProducer(bootstrap_servers=['127.0.0.1:9092'])  #此处ip可以是多个['0.0.0.1:9092','0.0.0.2:9092','0.0.0.3:9092' ]topic_name = 'test'i=0while True:    ts = int(time.time() * 1000)    # msg = '&#123;\"phone\": 17626041117, \"extra-key\": \"extra-value\"&#125;'    msg = str(i)    print(msg)    producer.send(topic_name, msg.encode('utf-8'))  # 参数为主题和bytes数据    producer.flush()    i+=1                  time.sleep(2)\n运行：\n123456python producer.py0123\n\nconsumer\n\nbasic\n12345678910# coding=utf-8from kafka import KafkaConsumer, TopicPartitiontopic_name = 'test'groupid = 'group1'server_list = '127.0.0.1:9092'consumer = KafkaConsumer(topic_name,bootstrap_servers=server_list)for message in consumer:  print(message)\n运行：\n12345python consumer.pyConsumerRecord(topic=u'test', partition=0, offset=69, timestamp=1544090653375, timestamp_type=0, key=None, value='0', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=1, serialized_header_size=-1)ConsumerRecord(topic=u'test', partition=0, offset=70, timestamp=1544090655386, timestamp_type=0, key=None, value='1', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=1, serialized_header_size=-1)\n\n拉取未消费的信息：断开连接，再次bash进入消费的时候，会拉取所有的消息，而我们需要获取从断开点之后创建的信息\n1234567891011121314151617# coding=utf-8from kafka import KafkaConsumer, TopicPartitiontopic_name = 'test'groupid = 'group1'server_list = '127.0.0.1:9092'# offset                        consumer = KafkaConsumer(group_id=groupid,                         bootstrap_servers=server_list)partition = TopicPartition(topic_name, 0)consumer.assign([partition])print(\"start offset is \", consumer.position(partition))for message in consumer:  print(message)  file = open('consumer.log','a')  file.write(message.value + \"\\n\")\n运行：\n1python consumer.py\n\n\n\n\nreference\nkafka-python重复消费的问题\n\nPython脚本消费kafka数据\n\nPython操作分布式流处理系统Kafka\n\n\nQAQ\nvscode pip安装kafka 后，通过 iterm2 操作出现 ImportError: No module named kafka\n重装。。。\n\nkafka.errors.NoBrokersAvailable: NoBrokersAvailable\n指定的kafka host无效\n\n\nRemarks\ngroup_id 不需要配置，用户确定名称即可\n\n","plink":"https://spaco.github.io/post/kafka-case-with-python/"},{"title":"hexo-on-github-pages","date":"2018-09-01T00:00:00.000Z","updated":"2018-09-01T00:00:00.000Z","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartPrecondition\ngit : deploy to github\nnode.js : Hexo 基于 node.js开发的\n\nEnvironment\ngit \n123# versiongit --versiongit version 2.17.2 (Apple Git-113)\n\nnode.js\n123# versionnode -vv7.2.1\n\n\nInstall Hexo1npm install -g hexo-cli\nInit Hexo Folder1234mkdir spacocd spacohexo initnpm install\nRun server12hexo serverHexo is running at http://localhost:4000 . Press Ctrl+C to stop.\nCreate a new post1hexo new \"My New Post\"\nMore info: Writing\nRun server12hexo serverHexo is running at http://localhost:4000 . Press Ctrl+C to stop.\nMore info: Server\nReplace theme12345678910cd spaco/themesgit clone https://github.com/elmorec/hexo-theme-inside.git insidecd ../vim _config.yml# replace default theme to insidetheme: landscape =&gt; theme: insidehexo server# theme has changed\nDeploy to GitHubneed ssh-key already registered in GitHub\n\nCreate repostory\nyour_github_name.github.io\n\nDeployment config\n123456789vim _config.yml# like this# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:  type: git  repo: git@github.com:spaco/spaco.github.io.git  branch: master\n\n\nClean static files12hexo cleanhexo c\nGenerate static files12hexo generate # hexo g\nMore info: Generating\nDeploy to remote sites12hexo deploy# hexo d\nMore info: Deployment\nEffectiveopen your-page.github.io in the browser\nReplace domain nameReferencesgithub+Hexo搭建blog\n浅析 Hexo 搭建博客的原理\n","plink":"https://spaco.github.io/post/hexo-on-github-pages/"},{"title":"hexo-on-travis-CI","date":"2018-09-01T00:00:00.000Z","updated":"2018-09-01T00:00:00.000Z","content":"Quick Starttravis-ci 是什么一个使用yaml格式配置用于持续集成完成自动化测试部署的开源项目官网：https://travis-ci.com/\n为什么使用 travis-ci 部署 Hexo blog\n避免换电脑需要安装环境\n可以随时更改 blog 内容\n不喜欢每次 hexo g  + hexo d\n\n原理github 设置两个分支，master develop,\ntravis-ci 检测 develop 的改动，编译之后将需要的数据提交到 master\n涉及的主要内容\nGitHub-Pages\n\nTravis-CI 账号\n\ngithub token\ncoding 同样\n\n\nCreate GitHub token\n进入 github token，点击 Generate new token\n\n完善 Token description ，Select scopes\n\nsave\n\n\n\n同步github repository\n\n登陆 travis-ci\n\nhttps://travis-ci.com/account/repositories\n\n同步 repository\n点击 manage repositories on Github\n\n\n点击已同步 repository 右边的 setting\n\n配置 Environment Variables ：会在部署脚本中使用到\n\nGH_REF : github.com/spaco/spaco.github.io.git\nGH_TOKEN : 上个步骤获得的 github token\n\n\nGithub  repository setting以github一个空仓库为示范,但是已实现本地 blog 预览\n\ncreate develop branch\nset default branch = develop\n\nRun travis-ci运行 travis-ci，需要配置 .travis.yml ,默认检测此文件，详情见下方 Extra\n将 develop 编译之后的内容 提交到 master，现有如下几种方式\n\ncopy ssh key\ngithub token : master 永远只有一次 commit log\ngithub token : master commit log 保存 （推荐）\n\ngit push to develop , travis-ci run\n\nQAQ\nQ : 通过git clone theme,但是通过 travis-ci 自动部署的时候，无法提交 theme文件，因为theme所属另外一个 GitHub-repository\nA : 使用 git submodule clone theme \n123[submodule \"themes/inside\"]\tpath = themes/inside\turl = https://github.com/spaco/hexo-theme-inside.git\n\n\nExtra123456789101112131415161718192021222324252627282930language: node_jsnode_js: stable# S: Build Lifecycleinstall:- npm install#before_script:# - npm install -g gulpscript:  - hexo gafter_script:  - git clone https://$&#123;GH_REF&#125; .deploy_git  # GH_REF是最下面配置的仓库地址  - cd .deploy_git  - git checkout master  - cd ../  - mv .deploy_git/.git/ ./public/   # 这一步之前的操作是为了保留master分支的提交记录，不然每次git init的话只有1条commit  - cd ./public  - git config user.name \"spaco\"  - git config user.email \"she.ct@outlook.com\"  - git add .  - git commit -m \"Travis automatically updates the document\"  - git push --force --quiet \"https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master# E: Build LifeCyclebranches:  only:    - develop\n","plink":"https://spaco.github.io/post/hexo-on-travis-CI/"},{"title":"queue","date":"2018-08-20T00:00:00.000Z","updated":"2018-08-20T00:00:00.000Z","content":"Briefly introduce the principle of queues, the implementation of common programming languages\nQueueFIFO结构像栈一样，队列（queue）也是一种线性表，它的特性是先进先出，插入在一端，删除在另一端。就像排队一样，刚来的人入队（push）要排在队尾(rear)，每次出队(pop)的都是队首(front)\n队列（Queue）与栈一样，是一种线性存储结构，它具有如下特点：\n\n队列中的数据元素遵循     先进先出 （First In First Out）的原则，简称FIFO结构\n在队尾添加元素，在队头删除元素\n\n相关概念\n入队：队列的插入操作\n出队：队列的删除操作\n\n相关用途队列可以很好地异步处理数据传送和存储，当你频繁地向数据库中插入数据、频繁地向搜索引擎提交数据，就可采取队列来异步插入。另外，还可以将较慢的处理逻辑、有并发数量限制的处理逻辑，通过消息队列放在后台处理，例如FLV视频转换、发送手机短信、发送电子邮件等。\n图解\n入队 我们有一个存储整型元素的队列，我们依次入对：{1，2，3}\n\n\n\n出对\n\n\n\n","plink":"https://spaco.github.io/post/queue/"},{"title":"http-cache","date":"2018-08-05T00:00:00.000Z","updated":"2018-08-05T00:00:00.000Z","content":"","plink":"https://spaco.github.io/post/http-cache/"},{"title":"solr","date":"2018-06-13T00:00:00.000Z","updated":"2018-06-13T00:00:00.000Z","content":"","plink":"https://spaco.github.io/post/solr/"},{"title":"demo","date":"2015-08-20T00:00:00.000Z","updated":"2015-08-20T00:00:00.000Z","content":"Demo Demo\nHeader1Header2Header3LinkContent\n","plink":"https://spaco.github.io/post/demo/"},{"title":"RPC","date":"2015-08-20T00:00:00.000Z","updated":"2015-08-20T00:00:00.000Z","content":"RPC\nQueueFIFO结构","plink":"https://spaco.github.io/post/RPC/"}]