[{"title":"difference between mongo mongodb mongod","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"Difference between mongo mongodb mongod\nMongodMongo Daemon 即守护进程\n123456# ps -Aroot@2524adecfdfb:/# ps -APID TTY          TIME CMD  1 ?        00:03:17 mongod 57 pts/0    00:00:00 bash 83 pts/0    00:00:00 ps\nMongocommand-line shell\n1234567891011121314151617181920212223# mongo localhost:27017root@2524adecfdfb:/# mongo localhost:27017MongoDB shell version v4.0.10connecting to: mongodb://localhost:27017/test?gssapiServiceName=mongodbImplicit session: session &#123; \"id\" : UUID(\"d1bfacc3-15b2-41a6-b6fa-cf422e0506fc\") &#125;MongoDB server version: 4.0.10Server has startup warnings:2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten]2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.2019-07-25T07:14:11.075+0000 I CONTROL  [initandlisten]---Enable MongoDB's free cloud-based monitoring service, which will then receive and displaymetrics about your deployment (disk utilization, CPU, operation statistics, etc).The monitoring data will be available on a MongoDB website with a unique URL accessible to youand anyone you share the URL with. MongoDB may use this information to make productimprovements and to suggest MongoDB products and deployment options to you.To enable free monitoring, run the following command: db.enableFreeMonitoring()To permanently disable this reminder, run the following command: db.disableFreeMonitoring()---&gt;\n 连接之后，可以进行下一步操作，例如：查询数据库列表\n123456# show dbs&gt; show dbsadmin   0.000GBconfig  0.000GBlocal   0.000GBreport  0.021GB\nMongodbMongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案\n","plink":"https://spaco.github.io/post/difference-between-mongo-mongodb-mongod/"},{"title":"program noun","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"List commonly used programming nouns\nCommon\nRPC\n**远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。\n\nORM\n**对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping），是一种程序设计技术，用于实现面向对象编程语言里不同类型系统的数据之间的转换。从效果上说，它其实是创建了一个可在编程语言里使用的“虚拟对象数据库”。\n\nMVC\nMVC模式（Model–view–controller）是软件工程中的一种软件架构模式，把软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）。\n\n控制器（Controller）- 负责转发请求，对请求进行处理。\n视图（View） - 界面设计人员进行图形界面设计。\n模型（Model） - 程序员编写程序应有的功能（实现算法等等）、数据库专家进行数据管理和数据库设计(可以实现具体的功能)。\n\n\nGC\n垃圾回收（英语：Garbage Collection，缩写为GC），在计算机科学中是一种自动的存储器管理机制。当一个计算机上的动态存储器不再需要时，就应该予以释放，以让出存储器，这种存储器资源管理，称为垃圾回收。垃圾回收器可以让程序员减轻许多负担，也减少程序员犯错的机会。垃圾回收最早起源于LISP语言。[1]#cite_note-1)[2]#cite_note-2)当前许多语言如Smalltalk、Java、C#和D语言都支持垃圾回收器。\n\nOOP\n面向对象程序设计（英语：Object-oriented programming，缩写：OOP）是种具有对象)概念的程序编程典范，同时也是一种程序开发的抽象方针。它可能包含数据、属性&amp;action=edit&amp;redlink=1)、代码与方法)。对象则指的是类)的实例。它将对象)作为程序的基本单元，将程序和数据封装)其中，以提高软件的重用性、灵活性和扩展性，对象里的程序可以访问及经常修改对象相关连的数据。在面向对象程序编程里，计算机程序会被设计成彼此相关的对象[1][2]。\n面向对象程序设计可以看作一种在程序中包含各种独立而又互相调用的对象的思想，这与传统的思想刚好相反：传统的程序设计主张将程序看作一系列函数的集合，或者直接就是一系列对计算机下达的指令。面向对象程序设计中的每一个对象都应该能够接受数据、处理数据并将数据传达给其它对象，因此它们都可以被看作一个小型的“机器”，即对象。当前已经被证实的是，面向对象程序设计推广了程序的灵活性和可维护性，并且在大型项目设计中广为应用。此外，支持者声称面向对象程序设计要比以往的做法更加便于学习，因为它能够让人们更简单地设计并维护程序，使得程序更加便于分析、设计、理解。反对者在某些领域对此予以否认。\n当我们提到面向对象的时候，它不仅指一种程序设计方法。它更多意义上是一种程序开发方式。在这一方面，我们必须了解更多关于面向对象系统分析和面向对象设计（Object Oriented Design，简称OOD）方面的知识。许多流行的编程语言是面向对象的,它们的风格就是会透由对象来创出实例。\n重要的面向对象编程语言包含Common Lisp、Python、C++、Objective-C、Smalltalk、Delphi、Java、Swift)、C#、Perl、Ruby 与 PHP等。\n\nAOP\n面向切面的程序设计（Aspect-oriented programming，AOP，又译作面向方面的程序设计、剖面导向程序设计）是计算机科学中的一种程序设计思想，旨在将横切关注点与业务主体进行进一步分离，以提高程序代码的模块化程度。通过在现有代码基础上增加额外的通知（Advice）机制，能够对被声明为“切点（Pointcut）”的代码块进行统一管理与装饰，如“对所有方法名以‘set*’开头的方法添加后台日志”。该思想使得开发人员能够将与代码核心业务逻辑关系不那么密切的功能（如日志功能）添加至程序中，同时又不降低业务代码的可读性。面向切面的程序设计思想也是面向切面软件开发的基础。\n\n\nPHP\nPHP\nPHP（全称：PHP：Hypertext Preprocessor，即“PHP：超文本预处理器”）是一种开源的通用计算机脚本语言，尤其适用于网络开发并可嵌入HTML中使用。PHP的语法借鉴吸收C语言、Java和Perl等流行计算机语言的特点，易于一般程序员学习。PHP的主要目标是允许网络开发人员快速编写动态页面，但PHP也被用于其他很多领域。[1]\nPHP最初是由勒多夫在1995年开始开发的；现在PHP的标准由the PHP Group[2]维护。PHP以PHP License作为许可协议，不过因为这个协议限制了PHP名称的使用，所以和开放源代码许可协议GPL不兼容。[3]\n\n\n","plink":"https://spaco.github.io/post/program-noun/"},{"title":"php extension install","date":"2019-07-29T00:00:00.000Z","updated":"2019-07-29T00:00:00.000Z","content":"##List PHP extensions\n123456php -m# show like this[PHP Modules]libeventposixpcntl\n##Install\n###Redis\n可以使用 predis composer 扩展包的方式达成对Redis的操作，效果与Redis扩展大同小异\n####Mac\n####Ubuntu\nReferences\npredis包和phpredis扩展的区别是什么\n\n","plink":"https://spaco.github.io/post/php-extension-install/"},{"title":"laravel Facades","date":"2019-07-26T00:00:00.000Z","updated":"2019-07-26T00:00:00.000Z","content":"Laravel Facade 执行流程分析\nIntroductionFacades 为应用程序提供了一系列的静态方法，提供简洁，富有表现力的语法，同时保持比传统静态方法更多的可测试性和灵活性。\nDemo Used in code123456789101112// cache\\Illuminate\\Support\\Facades\\Cache::get('cacheKey');// redis\\Illuminate\\Support\\Facades\\Redis::get('redisKey');// auth\\Illuminate\\Support\\Facades\\Auth::id();// config\\Illuminate\\Support\\Facades\\Config::get('configKey');// log\\Illuminate\\Support\\Facades\\Log::info('logKey');// request\\Illuminate\\Support\\Facades\\Request::get('requestKey');\nHow Facades Work (以Cache为例)首先是Cache Facade文件\n123456789101112131415161718namespace Illuminate\\Support\\Facades;/*  * @see \\Illuminate\\Cache\\CacheManager * @see \\Illuminate\\Cache\\Repository */class Cache extends Facade&#123;    /**     * Get the registered name of the component.     *     * @return string     */    protected static function getFacadeAccessor()    &#123;        return 'cache';    &#125;&#125;\n代码量很少，只有一个getFacadeAccessor方法，那么它是如何可以调用其他方法的呢，主要是Cache Facade 继承的Facade类，Facade主要代码如下所示:\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081namespace Illuminate\\Support\\Facades;abstract class Facade&#123;        /**     * The application instance being facaded.     *     * @var \\Illuminate\\Contracts\\Foundation\\Application     */    protected static $app;    /**     * The resolved object instances.     *     * @var array     */    protected static $resolvedInstance;        /**     * Handle dynamic, static calls to the object.     *     * @param  string  $method     * @param  array   $args     * @return mixed     *     * @throws \\RuntimeException     */    public static function __callStatic($method, $args)    &#123;        $instance = static::getFacadeRoot();        if (! $instance) &#123;            throw new RuntimeException('A facade root has not been set.');        &#125;        return $instance-&gt;$method(...$args);    &#125;        /**     * Get the root object behind the facade.     *     * @return mixed     */    public static function getFacadeRoot()    &#123;        return static::resolveFacadeInstance(static::getFacadeAccessor());    &#125;        /**     * Resolve the facade root instance from the container.     *     * @param  object|string  $name     * @return mixed     */    protected static function resolveFacadeInstance($name)    &#123;        if (is_object($name)) &#123;            return $name;        &#125;        if (isset(static::$resolvedInstance[$name])) &#123;            return static::$resolvedInstance[$name];        &#125;        return static::$resolvedInstance[$name] = static::$app[$name];    &#125;        /**     * Get the registered name of the component.     *     * @return string     *     * @throws \\RuntimeException     */    protected static function getFacadeAccessor()    &#123;        throw new RuntimeException('Facade does not implement getFacadeAccessor method.');    &#125;  &#125;\n那么   cache 在何处定义的呢？是由框架内部的CacheServiceProvider注册，若想更深一步了解Service Providers可以参考Service Providers\n12345678910111213141516171819202122232425262728namespace Illuminate\\Cache;class CacheServiceProvider extends ServiceProvider implements DeferrableProvider&#123;      /**     * Register the service provider.     *     * @return void     */    public function register()    &#123;        $this-&gt;app-&gt;singleton('cache', function ($app) &#123;            return new CacheManager($app);        &#125;);    &#125;    /**     * Get the services provided by the provider.     *     * @return array     */    public function provides()    &#123;        return [            'cache'        ];    &#125;&#125;\n那么就很明显了，Cache::get() 实际上是调用CacheManager::get()，主要是代码是在CacheManager中，Cache Facade提供了一种便捷使用方法。\n##Find Laravel Predefined Facades\nsearch\n123$this-&gt;app-&gt;singleton('cache'$this-&gt;app-&gt;singleton('redis'$this-&gt;app-&gt;singleton('log'\n","plink":"https://spaco.github.io/post/laravel-facades/"},{"title":"difference between socket and websocket","date":"2019-07-23T00:00:00.000Z","updated":"2019-07-23T00:00:00.000Z","content":"Difference between socket and websocket \nSocket\n套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据，可对其进行像对文件一样的打开、读写和关闭等操作。套接字允许应用程序将I/O插入到网络中，并与网络中的其他应用程序进行通信。网络套接字是IP地址与端口的组合。\n——百度百科\n\nSocket是一套API接口，是建立在TCP和应用程序之间的一个抽象层，就是我们之前说的“面向抽象编程”的这个抽象，Socket这个抽象层帮我们封装了TCP/UDP等网络协议的操作，让我们可以通过Socket提供的接口进行网络通信，可以通过一个图来说明这个抽象的功能\nWebsocketwiki.websocket\n\nWebSocket是一种通信协议，可在单个TCP连接上进行全双工通信。WebSocket协议在2011年由IETF标准化为RFC 6455，后由RFC 7936补充规范。Web IDL中的WebSocket API由W3C标准化。\nWebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。\n\n简介\nWebSocket是一种与HTTP不同的协议。两者都位于OSI模型的应用层，并且都依赖于传输层的TCP协议。 虽然它们不同，但RFC 6455规定：“WebSocket设计为通过80和443端口工作，以及支持HTTP代理和中介”，从而使其与HTTP协议兼容。 为了实现兼容性，WebSocket握手使用HTTP Upgrade头[1]从HTTP协议更改为WebSocket协议。\nWebSocket协议支持Web浏览器（或其他客户端应用程序）与Web服务器之间的交互，具有较低的开销，便于实现客户端与服务器的实时数据传输。 服务器可以通过标准化的方式来实现，而无需客户端首先请求内容，并允许消息在保持连接打开的同时来回传递。通过这种方式，可以在客户端和服务器之间进行双向持续对话。 通信通过TCP端口80或443完成，这在防火墙阻止非Web网络连接的环境下是有益的。另外，Comet)之类的技术以非标准化的方式实现了类似的双向通信。\n大多数浏览器都支持该协议，包括Google Chrome、Firefox、Safari、Microsoft Edge、Internet Explorer和Opera。\n与HTTP不同，WebSocket提供全双工通信。此外，WebSocket还可以在TCP之上启用消息流。TCP单独处理字节流，没有固有的消息概念。 在WebSocket之前，使用Comet可以实现全双工通信。但是Comet存在TCP握手和HTTP头的开销，因此对于小消息来说效率很低。WebSocket协议旨在解决这些问题。\nWebSocket协议规范将ws（WebSocket）和wss（WebSocket Secure）定义为两个新的统一资源标识符（URI）方案，分别对应明文和加密连接。除了方案名称和片段ID（不支持#）之外，其余的URI组件都被定义为此URI的通用语法。\n使用浏览器开发人员工具，开发人员可以检查WebSocket握手以及WebSocket框架。\n\n背景\n现在，很多网站为了实现推送技术，所用的技术都是轮询。轮询是在特定的的时间间隔（如每秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会消耗很多的带宽资源。\n比较新的轮询技术是Comet)。这种技术虽然可以实现双向通信，但仍然需要反复发出请求。而且在Comet中普遍采用的HTTP长连接也会消耗服务器资源。\n在这种情况下，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。\nWebsocket使用ws或wss的统一资源标志符，类似于HTTPS。其中wss表示使用了TLS的Websocket。如：\n123&gt; ws://example.com/wsapi&gt; wss://secure.example.com/wsapi&gt;\n\n\nWebsocket与HTTP和HTTPS使用相同的TCP端口，可以绕过大多数防火墙的限制。默认情况下，Websocket协议使用80端口；运行在TLS之上时，默认使用443端口。\n\n优点\n\n较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。\n\n更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。\n\n保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。\n\n更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。\n\n可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。\n\n更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。\n\n\n\n握手协议\nWebSocket 是独立的、创建在 TCP 上的协议。\nWebsocket 通过 HTTP/1.1 协议的101状态码进行握手。\n为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手)”（handshaking）。\n\nSummaryWebsocket是一种应用层协议，Socket是封装了网络层操作的抽象API接口\nReferences维基WebSocket\n","plink":"https://spaco.github.io/post/difference-between-socke-and-websocket/"},{"title":"types-of-dependency-injection","date":"2019-07-15T00:00:00.000Z","updated":"2019-07-15T00:00:00.000Z","content":"Types of Dependency Injection此篇文章使用 Java 代码作为演示\n如果希望了解 Dependency Injection 和  Inversion of Control 可以参考··\nSpring通过DI（依赖注入）实现IoC（控制反转)\n建议看一下这篇文章\nhttps://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#beans-dependencies\nTypesConstructor Injection基于构造函数的DI由容器调用具有多个参数的构造函数来完成，每个参数表示一个依赖项。 调用具有特定参数的静态工厂方法来构造bean几乎是等效的，本讨论同样处理构造函数和静态工厂方法的参数。 以下示例显示了一个只能通过构造函数注入进行依赖注入的类：\n123456789101112public class SimpleMovieLister &#123;    // the SimpleMovieLister has a dependency on a MovieFinder    private MovieFinder movieFinder;    // a constructor so that the Spring container can inject a MovieFinder    public SimpleMovieLister(MovieFinder movieFinder) &#123;        this.movieFinder = movieFinder;    &#125;    // business logic that actually uses the injected MovieFinder is omitted...&#125;\nAdvantages\n能够在构造阶段就创建完整、合法的对象；\n带有参数的构造函数可以明确地告诉你创建一个合法的对象需要哪些参数\n\nDisadvantages\n构造函数依赖的太多，会显得很复杂（事实上，当一个控制器依赖太多service，这个控制器本身就是有问题的，需要拆解）\n1234567891011121314public class SimpleMovieLister &#123;    private A a;\t\tprivate B b;  \tprivate C c;  \tprivate D d;      public SimpleMovieLister(A a,B b,C c,D d) &#123;        this.a = a;      \tthis.b = b;      \tthis.c = c;      \tthis.d = d;    &#125;&#125;\n\n\nSetter Injection | Property Injection在调用无参数构造函数或无参数static工厂方法来实例化bean之后，基于setter的DI由bean上的容器调用setter方法完成。\n以下示例显示了一个只能通过使用纯setter注入进行依赖注入的类。这个类是传统的Java。它是一个POJO，它不依赖于容器特定的接口，基类或注释。\n123456789101112public class SimpleMovieLister &#123;    // the SimpleMovieLister has a dependency on the MovieFinder    private MovieFinder movieFinder;    // a setter method so that the Spring container can inject a MovieFinder    public void setMovieFinder(MovieFinder movieFinder) &#123;        this.movieFinder = movieFinder;    &#125;    // business logic that actually uses the injected MovieFinder is omitted...&#125;\nAdvantages\n如果依赖的「插件」太多时，选择 Setter 注入更优\n\nDisadvantages\n无法在构造阶段就创建完整、合法的对象；\n\n带有参数的构造函数无法明确地告诉你创建一个合法的对象需要哪些参数\n\n\nMethod Injection | Function InjectionWhat is method injection？\nSpring 中 Method Injection 分为 Lookup Method Injection （查找方法注入）和 Arbitrary Method Replacement（任意方法替换）\n在大多数应用程序场景中，容器中的大多数bean都是 单例。当单例bean需要与另一个单例bean协作或非单例bean需要与另一个非单例bean协作时，通常通过将一个bean定义为另一个bean的属性来处理依赖关系。当bean生命周期不同时会出现问题。假设单例bean A需要使用非单例（原型）bean B，可能是在A上的每个方法调用上。容器只创建一次单例bean A，因此只有一次机会来设置属性。每次需要时，容器都不能为bean A提供bean B的新实例。即 需要新实例。\nA solution is to forego some inversion of control. You can make bean A aware of the container by implementing the ApplicationContextAware interface, and by making a getBean(&quot;B&quot;) call to the container ask for (a typically new) bean B instance every time bean A needs it. The following example shows this approach:\nSummaryConstructor Injection 和 Setter Injection | Property Injection 是较常见的的注入方式，Method Injection 使用的较少。\n个人比较推荐 Constructor Injection，优点如上所述。\n还有一些文章说 Annotation Injection （注解注入）：通过注解将类注入到类属性中。个人感觉本质上和 Constructor Injection 没什么区别，都是初始化时将类注入到类属性中。\n不推荐以下写法，自己通过注解初始化类参数：\n随着版本的迭代，开发者更注重于业务本身，而会忽略初始化的参数越来越多\n1234567891011121314151617class Foo&#123;  \t/**     * @Inject A     */    private A a;      /**     * @Inject B     */    private B b;      /**     * @Inject C     */    private C c;&#125;\nReferences\nDI-wiki\nmethod-injection\ndocs.spring.io.beans-dependencies\nA quick intro to Dependency Injection: what it is, and when to use it\nDependency Injection\nspring-framework-reference.core\nJava方法注入（Method_injection）\nUnderstand Dependency Injection: Function/Method Injection\nSpring查找方法注入(Lookup method injection)的底层实现原理\nDifference Between @Resource, @Autowired and @Inject in Spring Injection\n\n","plink":"https://spaco.github.io/post/types-of-dependency-injection/"},{"title":"laravel-queue-timeout-configuration-not-working","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"laravel 设置队列超时时间，但是并没有生效\nDevelopment environmentslaravel : v5.5   \n12# https://laravel.com/docs/5.5/installationlaravel5.5 server requirements : PHP &gt;= 7.0.0\nphp : v7.1.30\ncodeController123456789101112131415&lt;?phpnamespace App\\Http\\Controllers;use App\\Jobs\\Test;class QueueController extends Controller&#123;    public function index()    &#123;        echo 'queue start';        Test::dispatch()-&gt;onQueue('testQueue');        echo 'queue end';    &#125;&#125;\nJob123456789101112131415161718192021222324252627282930&lt;?phpnamespace App\\Jobs;use App\\User;use Illuminate\\Bus\\Queueable;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;use Illuminate\\Support\\Facades\\Log;class Test implements ShouldQueue&#123;    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;    public $tries = 5;    public $timeout = 5;    public function __construct()    &#123;    &#125;    public function handle()    &#123;        Log::error('queue start');        sleep(10);        Log::error('queue end');    &#125;&#125;\n调用控制器，会发现，队列设置的超时时间无效\n12[2019-07-04 03:16:38][42] Processing: App\\Jobs\\Test[2019-07-04 03:16:48][42] Processed:  App\\Jobs\\Test\n日志同样会被打印\n12local.ERROR: queue start local.ERROR: queue end\n这是为什么呢\n Timeout settings not kill job in queue Laravel 5.4\n1234Timeouts also require PHP 7.1 to work.Ref: Worker::registerTimeoutHandlerRef: Worker::supportsAsyncSignals\nLaravel Queue Worker\n123456789101112131415161718192021222324252627282930313233# Illuminate\\Queue\\Worker    /**     * Register the worker timeout handler (PHP 7.1+).     *     * @param  \\Illuminate\\Contracts\\Queue\\Job|null  $job     * @param  WorkerOptions  $options     * @return void     */    protected function registerTimeoutHandler($job, WorkerOptions $options)    &#123;        if ($this-&gt;supportsAsyncSignals()) &#123;            // We will register a signal handler for the alarm signal so that we can kill this            // process if it is running too long because it has frozen. This uses the async            // signals supported in recent versions of PHP to accomplish it conveniently.            pcntl_signal(SIGALRM, function () &#123;                $this-&gt;kill(1);            &#125;);            $timeout = $this-&gt;timeoutForJob($job, $options);            pcntl_alarm($timeout &gt; 0 ? $timeout + $options-&gt;sleep : 0);        &#125;    &#125;    /**     * Determine if \"async\" signals are supported.     *     * @return bool     */    protected function supportsAsyncSignals()    &#123;        return version_compare(PHP_VERSION, '7.1.0') &gt;= 0 &amp;&amp;               extension_loaded('pcntl');    &#125;\n从上述代码可以看出，registerTimeoutHandler 超时处理需要两个条件\n\nphp 版本 &gt;= 7.1\n已安装 pcntl 扩展\n\n命令行执行以下命令查看 pcntl 扩展情况\n1php -m | grep pcntl\nSolution\n安装 pcntl 扩展\n\nphp 版本 &gt;= 7.1\n\n\nReferences\nTimeout settings not kill job in queue Laravel 5.4\n\npcntl extension\n\n\n","plink":"https://spaco.github.io/post/laravel-queue-timeout-configuration-not-working/"},{"title":"upgrade-mac-php-version.md","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"mac 本地 php 版本较低，升级至 7.2\nUpgradeupdate brew如未安装 brew，参考 https://brew.sh/ 安装\n123brew updatebrew search php\n12345$ brew search php==&gt; Formulaebrew-php-switcher         php-cs-fixer              phplint                   phpstanphp                       php@7.1                   phpmd                     phpunitphp-code-sniffer          php@7.2                   phpmyadmin\nInstall1brew install php@7.2\n安装完成之后，执行php -v 查看PHP版本，显示仍然是老版本\n修改本地PHP版本1brew link php@7.2\n出现以下提示\n因为mac用的是zsh，所以会将PATH 写入 ~/.zshrc,个人根据提示执行命令即可\n123456$ brew link php@7.2Warning: php@7.2 is keg-only and must be linked with --forceIf you need to have this software first in your PATH instead consider running:  echo 'export PATH=\"/usr/local/opt/php@7.2/bin:$PATH\"' &gt;&gt; ~/.zshrc  echo 'export PATH=\"/usr/local/opt/php@7.2/sbin:$PATH\"' &gt;&gt; ~/.zshrc\n执行完之后，刷新配置\n1source ~/.zshrc\n执行php -v 查看PHP版本\n123php -vPHP 7.2.19 (cli) (built: Jun 17 2019 09:03:55) ( NTS )\nSuccess\n","plink":"https://spaco.github.io/post/upgrade-mac-php-version.md/"},{"title":"phpunit","date":"2019-07-04T00:00:00.000Z","updated":"2019-07-04T00:00:00.000Z","content":"PHPUnit是一个面向PHP程序员的测试框架，这是一个xUnit的体系结构的单元测试框架\nInstall我们用一个 PHP Archive (PHAR) 来包含你需要使用的PHPUnit，可以从这里下载它，使其可执行，并把它放到你的 $PATH 里, 如:\n1234wget http://phar.phpunit.cn/phpunit.pharchmod +x phpunit.pharsudo mv phpunit.phar /usr/local/bin/phpunitphpunit --version\nUsed in phpstormLanguages &amp; Frameworks  -&gt;  PHP  -&gt; Debug  -&gt; Test Frameworks\nPath to phpunit.phar. -&gt; /usr/local/bin/phpunit\n","plink":"https://spaco.github.io/post/phpunit/"},{"title":"laravel-envoy","date":"2019-07-02T00:00:00.000Z","updated":"2019-07-02T00:00:00.000Z","content":"IntroductionWhat is laravel-envoySuppose you hava a samll project of your own,put it on a remote server. Every time you develop a function for thissmall project, you have to go online. The general operation will be the following.\n\nconnect to server ssh username@ip\nenter the project  cd workspace/my project\nupdate local code to the latest  git pull\n\nDoing this thing manually for too long,It feels bad ～\nLaravel Envoy provides a clean, minimal syntax for defining common tasks you run on your remote servers. Using Blade style syntax, you can easily setup tasks for deployment, Artisan commands, and more. Currently, Envoy only supports the Mac and Linux operating systems.\nAllows you to do all of the above with a minimum of configuration,just by executing the following line of commands from the local command line.\n1envoy run deploy\nInstallFirst, install Envoy using the Composer global require command:\n1composer global require laravel/envoy\nSince global Composer libraries can sometimes cause package version conflicts, you may wish to consider using cgr, which is a drop-in replacement for the composer global requirecommand. The cgr library’s installation instructions can be found on GitHub.\nAfter installed,you can see it in the ~/.composer/vendor/bin directory\nMake sure to place the~/.composer/vendor/bindirectory in your PATH so theenvoyexecutable is found when running theenvoycommand in your terminal.\nexecuting the following line of commands from the local command line.\n 1export PATH=\"$PATH:$HOME/.composer/vendor/bin\"\nor \n1234567# i am using zsh, update .bash_profile is also usefulvim ~/.bash_profile# add this lineexport PATH=\"$PATH:$HOME/.composer/vendor/bin\"# refresh .bash_profilesource ~/.bash_profile\nIn order to test whether the installation was successful\n1234envoy --version# show like thisLaravel Envoy 1.5.0\nUpdating Envoy1composer global update\nTo view a list of all available Envoy commands, you may use the list command:\n1envoy list\nWriting TasksFirst, in your project root directory , execute the following command to initialize\n1234envoy init root@127.0.0.1# show like thisEnvoy file created!\nEnvoy.blade.php is created\n123456@servers(['web' =&gt; 'root@127.0.0.1'])@task('deploy')    cd /path/to/site    git pull origin master@endtask\nVariablesIf needed, you may pass option values into Envoy tasks using the command line:\n1envoy run deploy --branch=master\n1234567891011@servers(['web' =&gt; '192.168.1.1'])@task('deploy', ['on' =&gt; 'web'])    cd site    @if ($branch)        git pull origin &#123;&#123; $branch &#125;&#125;    @endif    php artisan migrate@endtask\nStoriesStories group a set of tasks under a single, convenient name, allowing you to group small, focused tasks into large tasks. For instance, a deploy story may run the git and composertasks by listing the task names within its definition:\n1234567891011121314@servers(['web' =&gt; '192.168.1.1'])@story('deploy')    git    composer@endstory@task('git')    git pull origin master@endtask@task('composer')    composer install@endtask\nOnce the story has been written, you may run it just like a typical task:\n1envoy run deploy\nAttention: \n123456789101112131415@servers(['web' =&gt; '192.168.1.1'])@story('deploy')    task1    task2@endstory@task('task1')  \tcd ~/code    pwd@endtask@task('task2')    composer install@endtask\n在story里，只能使用tasks, 并且第一个 task cd 进入 code 目录，不代表第二个 task 在 code 目录中 \n12345@story('deploy')  \tcd /workspace/project   // error!    task1    task2@endstory\n1234567# about pwd# task1/root/code# task2/root\nMultiple ServersEnvoy allows you to easily run a task across multiple servers. First, add additional servers to your @servers declaration. Each server should be assigned a unique name. Once you have defined your additional servers, list each of the servers in the task’s on array:\n1234567@servers(['web-1' =&gt; '192.168.1.1', 'web-2' =&gt; '192.168.1.2'])@task('deploy', ['on' =&gt; ['web-1', 'web-2']])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nParallel Execution默认情况下，将在每个服务器上串行执行任务。换句话说，任务将在继续在第二台服务器上执行之前在第一台服务器上完成运行。如果要并行运行多个服务器上的任务，请将该parallel选项添加到任务声明中：\n1234567@servers(['web-1' =&gt; '192.168.1.1', 'web-2' =&gt; '192.168.1.2'])@task('deploy', ['on' =&gt; ['web-1', 'web-2'], 'parallel' =&gt; true])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nRunning Tasks1envoy run deploy\nConfirming Task Execution如果要在服务器上运行给定任务之前提示您进行确认，则应将该confirm指令添加到任务声明中。此选项对于破坏性操作特别有用：\n12345@task('deploy', ['on' =&gt; 'web', 'confirm' =&gt; true])    cd site    git pull origin &#123;&#123; $branch &#125;&#125;    php artisan migrate@endtask\nNotificationsto be continued\n","plink":"https://spaco.github.io/post/laravel-envoy/"},{"title":"laravel-login","date":"2019-06-14T00:00:00.000Z","updated":"2019-06-14T00:00:00.000Z","content":"Quick Start123456composer create-project --prefer-dist laravel/laravel principle &amp;&amp; cd principlephp artisan make:auth# database configurationvim .envphp artisan db:seed --class=UsersTableSeederphp artisan serve\nLogin RouteAuth::routes();\n12# config/app.php'Auth' =&gt; Illuminate\\Support\\Facades\\Auth::class\n12345# Illuminate\\Support\\Facades\\Auth  public static function routes(array $options = [])  &#123;      static::$app-&gt;make('router')-&gt;auth($options);  &#125;\n1234567# Illuminate\\Routing\\RoutingServiceProviderprotected function registerRouter()&#123;    $this-&gt;app-&gt;singleton('router', function ($app) &#123;        return new Router($app['events'], $app);    &#125;);&#125;\n123456789101112131415161718192021222324# Illuminate\\Routing\\Routerpublic function auth(array $options = [])&#123;    // Authentication Routes...    $this-&gt;get('login', 'Auth\\LoginController@showLoginForm')-&gt;name('login');    $this-&gt;post('login', 'Auth\\LoginController@login');    $this-&gt;post('logout', 'Auth\\LoginController@logout')-&gt;name('logout');    // Registration Routes...    if ($options['register'] ?? true) &#123;        $this-&gt;get('register', 'Auth\\RegisterController@showRegistrationForm')-&gt;name('register');        $this-&gt;post('register', 'Auth\\RegisterController@register');    &#125;    // Password Reset Routes...    if ($options['reset'] ?? true) &#123;        $this-&gt;resetPassword();    &#125;    // Email Verification Routes...    if ($options['verify'] ?? false) &#123;        $this-&gt;emailVerification();    &#125;&#125;\nLogin Action Explainresource codeaccording to Auth::routes(), source code =&gt; Auth\\LoginController@login\n1234567891011# App\\Http\\Controllers\\Auth\\LoginControllernamespace App\\Http\\Controllers\\Auth;use App\\Http\\Controllers\\Controller;use Illuminate\\Foundation\\Auth\\AuthenticatesUsers;class LoginController extends Controller&#123;    use AuthenticatesUsers;&#125;\nIn fact, the main code implementation is in AuthenticatesUsers Trait\n1234567891011121314151617181920212223242526# Illuminate\\Foundation\\Auth\\    public function login(Request $request)    &#123;        $this-&gt;validateLogin($request);        // If the class is using the ThrottlesLogins trait, we can automatically throttle        // the login attempts for this application. We'll key this by the username and        // the IP address of the client making these requests into this application.        if (method_exists($this, 'hasTooManyLoginAttempts') &amp;&amp;            $this-&gt;hasTooManyLoginAttempts($request)) &#123;            $this-&gt;fireLockoutEvent($request);            return $this-&gt;sendLockoutResponse($request);        &#125;        if ($this-&gt;attemptLogin($request)) &#123;            return $this-&gt;sendLoginResponse($request);        &#125;        // If the login attempt was unsuccessful we will increment the number of attempts        // to login and redirect the user back to the login form. Of course, when this        // user surpasses their maximum number of attempts they will get locked out.        $this-&gt;incrementLoginAttempts($request);        return $this-&gt;sendFailedLoginResponse($request);    &#125;\nexplain\nvalidate login form\nrate limiting\nattempt login &amp;&amp; return success response\nincrement login attempts count for rate limiting\nreturn fail response \n\n\nMore important is attempt login\n\nattempt login12345678910if ($this-&gt;attemptLogin($request)) &#123;    return $this-&gt;sendLoginResponse($request);&#125;protected function attemptLogin(Request $request)&#123;    return $this-&gt;guard()-&gt;attempt(        $this-&gt;credentials($request), $request-&gt;filled('remember')    );&#125;\nIn fact, the main code implementation is in Illuminate\\Auth\\SessionGuard  Class\n\nSessionGuard  attempt method\n\n12345678910111213141516171819202122public function attempt(array $credentials = [], $remember = false)&#123;    $this-&gt;fireAttemptEvent($credentials, $remember);    $this-&gt;lastAttempted = $user = $this-&gt;provider-&gt;retrieveByCredentials($credentials);    // If an implementation of UserInterface was returned, we'll ask the provider    // to validate the user against the given credentials, and if they are in    // fact valid we'll log the users into the application and return true.    if ($this-&gt;hasValidCredentials($user, $credentials)) &#123;        $this-&gt;login($user, $remember);        return true;    &#125;    // If the authentication attempt fails we will fire an event so that the user    // may be notified of any suspicious attempts to access their account from    // an unrecognized user. A developer may listen to this event as needed.    $this-&gt;fireFailedEvent($user, $credentials);    return false;&#125;\n\nThe essence is to save a session\n\n1234567  # Illuminate\\Auth\\SessionGuardprotected function updateSession($id)  &#123;      $this-&gt;session-&gt;put($this-&gt;getName(), $id);      $this-&gt;session-&gt;migrate(true);  &#125;\n12345 # Illuminate\\Auth\\SessionGuardpublic function getName() &#123;     return 'login_'.$this-&gt;name.'_'.sha1(static::class); &#125;\n","plink":"https://spaco.github.io/post/laravel-login/"},{"title":"laravel-reset-password","date":"2019-05-20T00:00:00.000Z","updated":"2019-05-20T00:00:00.000Z","content":"Reset PasswordEnvironment[TOC]\nLarval5.8\n\n首先是 ResetPasswordController 的 reset 方法，其实是由引入的 trait ResetsPasswords 内部实现的\n\n123use Illuminate\\Foundation\\Auth\\ResetsPasswords;use ResetsPasswords;\n","thumbnail":"https://spaco.oss-cn-hangzhou.aliyuncs.com/banners/ZhUwdBwIDiIefFYJ.jpg?x-oss-process=image/resize,m_fixed,h_1280,w_720","plink":"https://spaco.github.io/post/laravel-reset-password/"},{"title":"composer-package-build","date":"2019-02-14T00:00:00.000Z","updated":"2019-02-14T00:00:00.000Z","content":"Build composer packagecomposerbuild your composer package\ncreate package floder\n12mkdir package-namecd package-name\n\ninit\n123456789101112131415161718192021222324252627282930313233343536373839 ashe@ashedeMacBook-Pro  ~/code/composer-package/express   master  composer init  Welcome to the Composer config generatorThis command will guide you through creating your composer.json config.Package name (&lt;vendor&gt;/&lt;name&gt;) [ashe/express]: spaco/expressDescription []: get express phpAuthor [spaco &lt;she.ct@outlook.com&gt;, n to skip]:Minimum Stability []: devPackage Type (e.g. library, project, metapackage, composer-plugin) []: libraryLicense []: MITDefine your dependencies.Would you like to define your dependencies (require) interactively [yes]?Search for a package:Would you like to define your dev dependencies (require-dev) interactively [yes]?Search for a package:&#123;    \"name\": \"spaco/express\",    \"description\": \"get express php\",    \"type\": \"library\",    \"license\": \"MIT\",    \"authors\": [        &#123;            \"name\": \"spaco\",            \"email\": \"she.ct@outlook.com\"        &#125;    ],    \"minimum-stability\": \"dev\",    \"require\": &#123;&#125;&#125;Do you confirm generation [yes]?\n此时composer.json生成完毕\n\n\n","plink":"https://spaco.github.io/post/composer-package-build/"},{"title":"flyway","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"FlywayIntroductionVersion control for your database.Robust schema evolution across all your environments.With ease, pleasure and plain SQL.\n数据库的版本控制。跨所有环境的强大架构演变。轻松，愉快和简单的SQL\n官网\nHow Flyway works\nDevelopment environment\nflyway \n1version : 5.2.4\n\nmysql\n1version : 5.7\n\n\nInstalldocker-boxfuse-flyway\n关注 Supported Volumes\n见底部 docker-compose.yml\nConfiguration见底部  Configuration \nTestCreating the first migrationNow create a first migration in the /sql directory called V1__Create_person_table.sql\n1vim V1__Create_person_table.sql\n1234create table PERSON (    ID int not null,    NAME varchar(100) not null);\nConnect docker12docker-compose up -d flywaydocker-compose exec flyway bash\nMigrating the databaseflyway migrate\n1flyway migrate\nIf all went well, you should see the following output:\n123Creating Schema History table: `default`.`flyway_schema_history`Current version of schema `default`: &lt;&lt; Empty Schema &gt;&gt;Migrating schema `default` to version 1 - Create person table\nversion记录，可以在 db 的 flyway_schema_history 数据表中看到\n\nAdding a second migrationIf you now add a second migration to the /sql directory called V2__Add_people.sql\n1vim ./flyway/sql/V2__Add_people.sql\n123insert into PERSON (ID, NAME) values (1, 'Axel');insert into PERSON (ID, NAME) values (2, 'Mr. Foo');insert into PERSON (ID, NAME) values (3, 'Ms. Bar');\nand execute it by issuing:\n1flyway migrate\nyou now get:\n12345Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)Successfully validated 2 migrations (execution time 00:00.137s)Current version of schema `default`: 1Migrating schema `default` to version 2 - Add peopleSuccessfully applied 1 migration to schema `default` (execution time 00:00.523s)\nmigrate version 同样可以在 db 的 flyway_schema_history 数据表看到\nOther commandflyway clean  ：慎用flyway clean\nDrops all objects (tables, views, procedures, triggers, …) in the configured schemas.\nThe schemas are cleaned in the order specified by theschemasproperty.\n删除所有的 表 视图 过程 触发器     所有～～\n1flyway clean\n123Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)Successfully cleaned schema `default` (execution time 00:00.224s)# 此时所有的表都没了\nflyway infoflyway clean\nPrints the details and status information about all the migrations.\n打印有关所有迁移的详细信息和状态信息。\nflyway validate : 可作为 migration 前置命令flyway validate\n假设 开发A 创建了 V2__Add_user.sql , 开发 B 创建了 `V2__Add_user2.sql’,造成版本差错\n此时：ERROR: Found more than one migration with version 2\n1flyway validate\n12345Database: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)ERROR: Found more than one migration with version 2   # 版本2 migration more than oneOffenders:-&gt; /flyway/sql/V2__Add_people.sql (SQL)-&gt; /flyway/sql/V2__Add_people2.sql (SQL)\nundo ： not supported by Flyway Community Editionundo the most recently applied versioned migration.\nundo\nundo Important notes  ！！！\n\nThis should be complemented with a proper, well tested, backup and restore strategy ： \n\nundo fail : you end up creating home-made alternatives for restoring backups, which need to be properly tested as well.\n\nmaintain backwards compatibility between the DB and all versions of the code currently deployed in production :This way a failed migration is not a disaster. The old version of the application is still compatible with the DB, so you can simply roll back the application code （即 迁移失败不可怕，回滚code保证老代码适应DB）\n\n撤消最近应用的版本化迁移 -target=** 确定版本名\n1flyway undo\nundo is not supported by Flyway Community Edition\n1ERROR: Flyway Pro Edition or Flyway Enterprise Edition upgrade required: undo is not supported by Flyway Community Edition.\nbaselinebaseline\nBaselines an existing database, excluding all migrations up to and including baselineVersion\n生成 版本历史记录库，按照默认流程，版本记录库是已经生成的,默认表名：flyway_schema_history，此步骤可以跳过\n1234flyway baseline# errorDatabase: jdbc:mysql://106.14.6.94:3306/default (MySQL 5.7)ERROR: Unable to baseline schema history table `default`.`flyway_schema_history` as it already contains migrations\nrepairrepair\nRepairs the Flyway schema history table. This will perform the following actions:\n即 清理 failed migrations，保证版本 log 的完整性\n123flyway repairSuccessfully repaired schema history table `default`.`flyway_schema_history` (execution time 00:00.224s).\nDeploy1234flyway validateflyway migrate#test last\nReferences\nflyway.org\n\nQAQ\ndocker-compose.yml 中，关于command 的设置无效，无法映射到 conf 下，导致 flyway.url 为空\nA :\n使用 volumes ：\nvolumes:\n​        - “./flyway/sql/:/flyway/sql”\n​        - “./flyway/conf/:/flyway/conf”\n\n\nExtraConfiguration\ndocker-compose.yml\n12345678## 事实上，关于 url user 的配置放于 ./flyway/conf/flyway.conf 中，command 中的参数不重要，但是删除 也不行，会无法启动 flyway### Flyway ################################################    flyway:      image: boxfuse/flyway:5.2.4  #也可以去掉版本号，使用最新的      command: -url=jdbc:mysql://db -schemas=myschema -user=root -password=root -connectRetries=60 migrate      volumes:        - \"./flyway/sql/:/flyway/sql\"        - \"./flyway/conf/:/flyway/conf\"\n\n/flyway/conf/flyway.conf\n本次是 copy 一份 conf模版，然后配置相关信息，做 docker 映射\nflyway.conf\nflyway.conf模版\n1234# 本次单纯设置以下三项基础配置， 其余的请自行配置flyway.url=jdbc:mysql://106.14.6.94:3306/db-nameflyway.user=db-user-nameflyway.password=db-password\n\n\ndocker compose 设置flyway environment 为pro不行的～～\n123docker-compose logs flywayERROR: Missing license key. Ensure flyway.licenseKey is set to a valid Flyway license key (\"FL01\" followed by 512 hex chars)\n","plink":"https://spaco.github.io/post/flyway/"},{"title":"mysql-basic","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"Backend ServiceLNMP\n\n操作系统 ：windows / linux（centos / ubuntu）\n\nHTTP 服务器 ： Apache / Nginx\n\n作用目的是一致的, 简单说就是接收用户请求, 然后处理请求, 最后将处理结果返回给用户\n\n\n数据库\n\n关系型数据库 ：, 是指采用了关系模型来组织数据的数据库.  几种常见关系型数据库\n\n\nmysql ：\nOracle :\nSQLite :\nPostgreSQL\n\n\nextra ： 非关系型数据库Nosql (not only sql) :数据也是在逐渐增长和变得复杂、非固定结构化的. 这些所有的变化都是很难在原有的关系型数据库中管理的;\n\n\nkey-value（Redis）:\n文档型 （MongoDB）：\n常见几种nosql特点、区别以及应用场景\n关系型数据库和非关系型数据库的特性以及各自的优缺点\n\n\n\n\nLanguage\nphp\n\n\nMysql Basic官网\n当前最新版本：V8.0\nhttps://www.mysql.com/products/enterprise/database/\nDevelop Environment12mysql -Vversion 5.7.25\n什么是数据库数据库（Database）是按照数据结构来组织、存储和管理数据的仓库. \n每个数据库都有一个或多个不同的 API 用于创建, 访问, 管理, 搜索和复制所保存的数据. \n我们也可以将数据存储在文件中, 但是在文件中读写数据速度相对较慢. \n所以, 现在我们使用关系型数据库管理系统（RDBMS）来存储和管理的大数据量. 所谓的关系型数据库, 是建立在关系模型基础上的数据库, 借助于集合代数等数学概念和方法来处理数据库中的数据. \nRDBMS 即关系数据库管理系统(Relational Database Management System)的特点：\n\n1.数据以表格的形式出现\n2.每行为各种记录名称\n3.每列为记录名称所对应的数据域\n4.许多的行和列组成一张表单\n5.若干的表单组成database\n\nMySQL 是最流行的关系型数据库管理系统, 在 WEB 应用方面 MySQL 是较好的 RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一\n为什么选用Mysql12345678MySQL 是开源的, 所以你不需要支付额外的费用. MySQL 支持大型的数据库. 可以处理拥有上千万条记录的大型数据库. MySQL 使用标准的 SQL 数据语言形式. MySQL 可以运行于多个系统上, 并且支持多种语言. 这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等. MySQL 对PHP有很好的支持, PHP 是目前最流行的 Web 开发语言. MySQL 支持大型数据库, 支持 5000 万条记录的数据仓库, 32 位系统表文件最大可支持 4GB, 64 位系统支持最大的表文件为8TB. MySQL 是可以定制的, 采用了 GPL 协议, 你可以修改源码来开发自己的 MySQL 系统.\n相关概念\n数据库(database) : 数据库是一些关联表的集合\n数据表\n主键(PRIMARY KEY) : 主键是唯一的,一个数据表中只能包含一个主键. 你可以使用主键来查询数据. \n索引(index) :使用索引可快速访问数据库表中的特定信息. 索引是对数据库表中一列或多列的值进行排序的一种结构. 类似于书籍的目录\n表头(header): 每一列的名称;\n列(col): 具有相同数据类型的数据的集合;\n行(row): 每一行用来描述某条记录的具体信息;\n值(value): 行的具体信息, 每个值必须与该列的数据类型相同;\n\n安装\nhttps://www.mysql.com/downloads/\n\nConsole12## 进入mysql容器docker-compose exec mysql bash\n\nconnect\n\n1mysql -u root -p\n\ncreate database\n1234create database zeaho default character set utf8mb4 collate utf8mb4_unicode_ci;## checkshow databases;\n\ndrop database\n1234drop database zeaho;## checkshow databases;\n\nselect database\n在你连接到 MySQL 数据库后, 可能有多个可以操作的数据库, 所以你需要选择你要操作的数据库. \n成功选择了某个数据库后, 在后续的操作中都会在选择的数据库中执行\n123use zeaho;Database changed\n\ncreate datatable\n1234567891011121314151617use zeaho;CREATE TABLE `admin` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,  `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,  `nick_name` char(50) DEFAULT NULL,  `unique_name` char(16) NOT NULL,  `password` varchar(128) NOT NULL,  `is_active` tinyint(3) unsigned NOT NULL DEFAULT '1',  `remember_token` varchar(255) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `unique_name` (`unique_name`)) ENGINE=InnoDB AUTO_INCREMENT=43 DEFAULT CHARSET=utf8mb4;## checkshow tables;\n数据库字段具体如何选择见底部 Expansion\n\ndrop datatable 删除数据表\n1drop table admin;\n\n插入数据\n12345678910INSERT INTO table_name ( field1, field2,...fieldN )                       VALUES                       ( value1, value2,...valueN );                       ## 插入数据INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name', '176', 'secrey', '1dsddas');INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name1', '1761', 'secrey1', '1dsddas1');INSERT INTO `zeaho`.`admin`(`nick_name`, `unique_name`, `password`, `remember_token`) VALUES ('name1', '17612', 'secrey1', '1dsddas1');\n如果数据是字符型, 必须使用单引号或者双引号, 如：”value”. \n\n查询数据\n\n所有列\n1select * from admin;\n\n指定列\n1select id,nick_name from admin;\n\n去重列\n1select distinct（password）from admin;\n\n最大列, 最小列\n12select max(id) from admin;select min(id) from admin;\n\n计数\n1select count(id) from admin;\n\n指定行\n12select * from admin where id = 1 and (id is null or id is not null);select * from admin where nick_name like &apos;%name%&apos;;\n\n多表查询\n123456789101112131415161718## 插入测试数据DROP TABLE IF EXISTS `user`;CREATE TABLE `user` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,  `creator_id` bigint(20) DEFAULT NULL,  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,  `score` int(10) unsigned DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES (1, 43, 'a', 1);INSERT INTO `user` VALUES (3, NULL, 'b', 2);INSERT INTO `user` VALUES (4, NULL, 'c', 4);INSERT INTO `user` VALUES (5, NULL, 'd', 3);INSERT INTO `user` VALUES (6, NULL, 'e', 2);\n1select u.*, a.id as admin_id from user u, admin a where a.id = u.creator_id;\n\n\n\n更新数据\n123## 语法UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause]\n\n你可以同时更新一个或多个字段. \n你可以在 WHERE 子句中指定任何条件. \n你可以在一个单独表中同时更新数据. \n\n12345##单表更新UPDATE `zeaho`.`admin` SET `unique_name` = '17626' WHERE `id` = 43;##多表联合修改update user u,admin a set u.name = 'new name' where a.id = u.creator_id;\n\n删除数据\n12## 语法DELETE FROM table_name [WHERE Clause]\n123如果没有指定 WHERE 子句, MySQL 表中的所有记录将被删除. 你可以在 WHERE 子句中指定任何条件您可以在单个表中一次性删除记录.\n12345##单表删除delete from  `zeaho`.`admin` WHERE `id` = 44;##多表联合删除delete u from user u, admin a where a.id = u.creator_id and u.name = 'real_name';\n\n排序\n1SELECT field1, field2 FROM table_name ORDER BY field1, [field2...] [ASC [DESC]]\n1SELECT * from user where id &gt; 1 ORDER BY score DESC,id ASC;\n\n分组\n1234567SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name;GROUP BY 语句根据一个或多个列对结果集进行分组. 在分组的列上我们可以使用 COUNT(总数), SUM(求和), AVG(平均值),等函数.\n测试数据表\n12345678910111213CREATE TABLE `sign_in` (  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',  `user_id` bigint(20) unsigned NOT NULL COMMENT '用户id',  `date` date NOT NULL COMMENT '签到时间',  `score` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '上课评分',  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;## 查看测试数据INSERT INTO `sign_in` VALUES (1, 1, '2019-01-31', 1);INSERT INTO `sign_in` VALUES (2, 2, '2019-01-23', 2);INSERT INTO `sign_in` VALUES (3, 2, '2019-01-19', 5);INSERT INTO `sign_in` VALUES (4, 1, '2019-01-19', 7);\n演示：\n1234567891011## COUNT## 查询签到次数SELECT `user_id`, COUNT(*) FROM  sign_in GROUP BY user_id;## SUM## 查询评分总数SELECT `user_id`, SUM(score) FROM  sign_in GROUP BY user_id;## AVG## 查询平均得分SELECT `user_id`, AVG(score) FROM  sign_in GROUP BY user_id;\n\n\nExpansion\n数据库字段的选择\n\n","plink":"https://spaco.github.io/post/mysql-basic/"},{"title":"elasticsearch-build-with-docker-compose","date":"2018-12-14T00:00:00.000Z","updated":"2018-12-14T00:00:00.000Z","content":"ElasticsearchForewordWhy ES\n成熟\n高可用\n高扩展\n\nDevelopment Environment\nelasticsearch\n12## version6.6.0\n\nkibana\n12## version6.6.0\n\n\nPoint Conception\nApache Lucene\nLucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程序界面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。\n\nInverted Index\nLucene实现快速搜索的核心就是倒排索引\n\n全文搜索引擎\n全文搜索引擎是目前广泛应用的搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。\n\nJava\nElasticsearch是使用 Java 开发的\n\nSolr\nSolr是用Java编写、运行在Servlet容器（如Apache Tomcat或Jetty）的一个独立的全文搜索服务器。 Solr采用了Lucene Java搜索库为核心的全文索引和搜索，并具有类似REST的HTTP/XML和JSON的API。 Solr强大的外部配置功能使得无需进行Java编码，便可对其进行调整以适应多种类型的应用程序。Solr有一个插件架构，以支持更多的高级定制。\n\nNear Realtime (NRT)\nElasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可以搜索的时间只有轻微的延迟（通常是1秒\n\nCluster\n集群是一个或多个节点(服务器)的集合，它们共同保存你的整个数据，并提供跨所有节点的联合索引和搜索功能。一个集群由一个唯一的名称标识，默认这个唯一标识的名称是”elasticsearch”。这个名称很重要，因为如果节点被设置为按其名称加入集群，那么节点只能是集群的一部分。\n确保不要在不同的环境中用相同的集群名称，否则可能导致节点加入到错误的集群中。例如，你可以使用”logging-dev”, “logging-test”, “logging-prod”分别用于开发、测试和正式集群的名字。\n\nNode\n节点是一个单独的服务器，它是集群的一部分，存储数据，并参与集群的索引和搜索功能。就像集群一样，节点由一个名称来标识，默认情况下，该名称是在启动时分配给节点的随机通用唯一标识符(UUID)。如果不想用默认的节点名，可以定义任何想要的节点名。这个名称对于管理来说很重要，因为你希望识别网络中的哪些服务器对应于你的Elasticsearch集群中的哪些节点。\n一个节点可以通过配置集群名称来加入到一个特定的集群中。默认情况下，每个节点都被设置加入到一个名字叫”elasticsearch”的集群中，这就意味着如果你启动了很多个节点，并且假设它们彼此可以互相发现，那么它们将自动形成并加入到一个名为”elasticsearch”的集群中。\n一个集群可以有任意数量的节点。此外，如果在你的网络上当前没有运行任何节点，那么此时启动一个节点将默认形成一个单节点的名字叫”elasticsearch”的集群。\n\nIndex\n索引是具有某种相似特征的文档的集合。例如，你可以有一个顾客数据索引，产品目录索引和订单数据索引。索引有一个名称标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。\n\nDocument\n文档是可以被索引的基本信息单元，类似数据库的单条表数据\n\n\nInstall\nDocker\n12345## Elasticsearch DockerfileFROM docker.elastic.co/elasticsearch/elasticsearch:6.6.0EXPOSE 9200 9300\n12345## Kibana DockerfileFROM docker.elastic.co/kibana/kibana:6.6.0EXPOSE 5601\n\nOthers\n\n\nBuild &amp; Start1docker-compose up -d elasticsearch kibana\nCheck\nElasticsearch\nOpen localhost:9200 with your browser\n1234567891011121314151617&#123;  \"name\": \"aJRPWzC\",  \"cluster_name\": \"laradock-cluster\",  \"cluster_uuid\": \"Bd8hjDXlTNSS5yQIondlDg\",  \"version\": &#123;    \"number\": \"6.6.0\",    \"build_flavor\": \"default\",    \"build_type\": \"tar\",    \"build_hash\": \"a9861f4\",    \"build_date\": \"2019-01-24T11:27:09.439740Z\",    \"build_snapshot\": false,    \"lucene_version\": \"7.6.0\",    \"minimum_wire_compatibility_version\": \"5.6.0\",    \"minimum_index_compatibility_version\": \"5.0.0\"  &#125;,  \"tagline\": \"You Know, for Search\"&#125;\n\nKibana\nOpen localhost:5601 with your browser\n\n\nAPIIndex\nCreate Index\n12345678PUT index_name## PUT twitter&#123;  \"acknowledged\" : true,  \"shards_acknowledged\" : true,  \"index\" : \"twitter\"&#125;\n\nIndex List\n1curl -X GET \"localhost:9200/_cat/indices?v\"\n\n\nDocument\nCreate Document\nPUT index_name/_doc\n指定id\n1234567## 指定idPUT twitter/_doc/1&#123;    \"user\" : \"kimchy\",    \"post_date\" : \"2009-11-15T14:12:12\",    \"message\" : \"trying out Elasticsearch\"&#125;\nResult:\n1234567891011121314&#123;  \"_index\" : \"twitter\",  \"_type\" : \"_doc\",  \"_id\" : \"1\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : &#123;    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  &#125;,  \"_seq_no\" : 0,  \"_primary_term\" : 1&#125;\n不指定id\nPOST index_name/_doc\n123456POST twitter/_doc/&#123;    \"user\" : \"kimchy\",    \"post_date\" : \"2009-11-15T14:12:12\",    \"message\" : \"trying out Elasticsearch\"&#125;\n1234567891011121314&#123;  \"_index\" : \"twitter\",  \"_type\" : \"_doc\",  \"_id\" : \"TGap7GgBR1R5Vn49jL0L\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : &#123;    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  &#125;,  \"_seq_no\" : 0,  \"_primary_term\" : 1&#125;\n\nUpdate Document\nPUT index_name/_doc/primark_key\n1234PUT twitter/_doc/1&#123;    \"user\":\"new-kimchy\"&#125;\nResult:\n1234567891011121314&#123;    \"_index\": \"twitter\",    \"_type\": \"_doc\",    \"_id\": \"1\",    \"_version\": 2,    \"result\": \"updated\",    \"_shards\": &#123;        \"total\": 2,        \"successful\": 1,        \"failed\": 0    &#125;,    \"_seq_no\": 1,    \"_primary_term\": 1&#125;\n\nDelete Document\nDELETE index_name/_doc/primark_key\n1DELETE /twitter/_doc/2\nResult:\n1234567891011121314&#123;    \"_index\": \"twitter\",    \"_type\": \"_doc\",    \"_id\": \"2\",    \"_version\": 3,    \"result\": \"deleted\",    \"_shards\": &#123;        \"total\": 2,        \"successful\": 1,        \"failed\": 0    &#125;,    \"_seq_no\": 4,    \"_primary_term\": 1&#125;\n\nSearch Document\n\nEasy Search\nGET /index_name/_search?q=key:value\n1GET /twitter/_search?q=user:kimchy\nResult\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123;    \"took\": 35,    \"timed_out\": false,    \"_shards\": &#123;        \"total\": 5,        \"successful\": 5,        \"skipped\": 0,        \"failed\": 0    &#125;,    \"hits\": &#123;        \"total\": 3,        \"max_score\": 0.2876821,        \"hits\": [            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"TGap7GgBR1R5Vn49jL0L\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"kimchy\",                    \"post_date\": \"2009-11-15T14:12:12\",                    \"message\": \"trying out Elasticsearch\"                &#125;            &#125;,            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"1\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"new-kimchy\"                &#125;            &#125;,            &#123;                \"_index\": \"twitter\",                \"_type\": \"_doc\",                \"_id\": \"3\",                \"_score\": 0.2876821,                \"_source\": &#123;                    \"user\": \"kimchy\",                    \"post_date\": \"2009-11-15T14:12:12\",                    \"messages\": \"trying out Elasticsearch\"                &#125;            &#125;        ]    &#125;&#125;\n\nRequest Body Search\nES 提供了一种JSON风格的 Query DSL (domain specific language)\n使用request body 传递参数，更加灵活\n123456GET /twitter/_search&#123;    \"query\" : &#123;        \"term\" : &#123; \"user\" : \"kimchy\" &#125;    &#125;&#125;\nResult\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123;  \"took\" : 3,  \"timed_out\" : false,  \"_shards\" : &#123;    \"total\" : 5,    \"successful\" : 5,    \"skipped\" : 0,    \"failed\" : 0  &#125;,  \"hits\" : &#123;    \"total\" : 3,    \"max_score\" : 0.2876821,    \"hits\" : [      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"TGap7GgBR1R5Vn49jL0L\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"kimchy\",          \"post_date\" : \"2009-11-15T14:12:12\",          \"message\" : \"trying out Elasticsearch\"        &#125;      &#125;,      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"1\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"new-kimchy\"        &#125;      &#125;,      &#123;        \"_index\" : \"twitter\",        \"_type\" : \"_doc\",        \"_id\" : \"3\",        \"_score\" : 0.2876821,        \"_source\" : &#123;          \"user\" : \"kimchy\",          \"post_date\" : \"2009-11-15T14:12:12\",          \"messages\" : \"trying out Elasticsearch\"        &#125;      &#125;    ]  &#125;&#125;\n\n\n\n\nTest数据量为 223479条\n12345## mysql 用时:11.081sSELECT * FROM company WHERE company_name LIKE \"%建%\"## es &lt; 1slocalhost:9200/company-100/_doc/_search?q=company_name:建\nExtra\n本次测试223479条mysql数据为60.58MB，导入ES后,查看http://localhost:9200/_cat/indices?v，数据为106.6MB\n\nReferences\nhttp://solr-vs-elasticsearch.com/\nelasticsearch document\n为什么Elasticsearch/Lucene检索可以比MySQL快\n百度指数对比\n\n","plink":"https://spaco.github.io/post/elasticsearch-build-with-docker-compose/"},{"title":"mysql-transaction","date":"2018-12-09T00:00:00.000Z","updated":"2018-12-09T00:00:00.000Z","content":"数据库事务（Database Transaction）,是指作为单个逻辑工作单元执行的一系列操作，要么完全执行，要么完全地不执行\n案例\nA 转账给B 6元,  需要保证，A减少 6 元，B增加 6 元，缺一不可\n\nDevelopment Environment\nmysql \n1version: 5.7\n\n\n相关概念\nACID特性\nAtomicity ： 原子性\n一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位\nConsistency ： 一致性\n事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到\nIsolation ： 隔离性\n数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）\nDurability ： 持久性\n事务完成后，事务对数据库的所有更新将被保存到数据库，不可回滚\n\n事务隔离级别\nread-uncommitted  ： 读未提交\nread-committed  ： 读已提交 \nrepeatable-read  ：  可重复读   (mysql5.7默认级别)\nserializable  ：  串行化\n\n\nACIDCreate test data123456789101112# 创建数据库create database transaction default character set utf8mb4 collate utf8mb4_unicode_ci;# 创建数据表CREATE TABLE `transaction`.`account`  (  `id` bigint(11) UNSIGNED NOT NULL AUTO_INCREMENT,  `name` varchar(55) NULL COMMENT '姓名',  `balance` decimal(10, 2) NULL COMMENT '余额',  PRIMARY KEY (`id`)) COMMENT = '账号表';# 插入测试数据INSERT INTO `transaction`.`account`(`name`, `balance`) VALUES ('joe', 450);INSERT INTO `transaction`.`account`(`name`, `balance`) VALUES ('she', 600);\n隔离级别 举例说明\nread-uncommitted\n\n打开客户端 A ,并设置当前事务级别为read-uncommitted（未提交读），并查询表account的初始值\n1234567891011121314151617# 进入 mysql 命令行mysql -uroot -proot# 设置当前窗口事务级别为 read uncommittedset session transaction isolation level read uncommitted;# Query OK, 0 rows affected (0.00 sec)use transaction;start transaction;select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 B ,同样设置当前事务级别为 read uncommitted ，并更新数据\n12345mysql -uroot -prootset session transaction isolation level read uncommitted;use transaction;start transaction;update account set balance = balance-50 where id = 1;\n\n返回客户端 A，B 的事务未提交, 窗口 A 仍然可以查看更新后的数据\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n返回客户端 B,假设因为异常数据回滚，那么此时客户端 A 返回给用户的数据就是 脏数据\n12345678910111213141516171819202122232425# 客户端 Bselect * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)# Q1:回滚之前，id=1 id=2两条数据是否可写？# 回滚rollback;select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 A ,执行减少 50 的更新操作，结果并不是400-50=350, 而是 400，用户把钱全转出去，操作结束发现还剩50\n在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用 read-committed 的隔离级别\n1234567891011121314151617181920212223# 客户端 Amysql&gt; select * from account;  # 此步骤是在客户端 B 未rollback 时执行+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)# 以下命令是在rollback 已执行的情况下运行mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n\n\nread committed\n\n打开一个客户端 A，并设置当前事务模式为read committed，查询表account的所有记录：\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.01 sec)\n\n打开客户端 B, 开启一个事务，并更新数据\n12345678910111213141516# 客户端 Bmysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n打开客户端 A, 查看所有记录，未读取到 B 已经更新的数据 ,  解决了脏读\n12345678mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n打开客户端 B, 提交事务\n123456789mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+commit;\n\n打开客户端 A, 执行查看所有的查询，发现与上一步结果不一致,产生 不可重复读 问题\n1234567891011121314151617mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  450.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)\n\n\n\nrepeatable read\n\n打开客户端 A, 查询表account的所有记录\n123456789set session transaction isolation level repeatable read;start transaction;mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A的事务提交之前，打开另一个客户端B，更新表account\n1234567891011mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.01 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A查询表account的所有记录，与上一步查询结果一致，没有出现不可重复读的问题\n12345678910111213141516mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n在客户端A，接着执行balance = balance - 50 where id = 1，balance没有变成400-50=350，balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）\n1234567891011121314151617181920212223mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 |+----+------+---------+2 rows in set (0.00 sec)mysql&gt; update balance = balance - 50 where id = 1;mysql&gt; update account set balance = balance-50 where id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  300.00 ||  2 | she  |  600.00 |+----+------+---------+commit;\n\n重新打开客户端B，插入一条新数据\n1234567891011mysql&gt; insert into account values(4,'kid',700);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 ||  4 | kid  |  700.00 |+----+------+---------+\n\n在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读\n1234567mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  350.00 ||  2 | she  |  600.00 |+----+------+---------+\n\n\n\nserializable\n\n打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值：\n1234567891011121314mysql&gt; set session transaction isolation level serializable;Query OK, 0 rows affected (0.00 sec)mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from account;+----+------+---------+| id | name | balance |+----+------+---------+|  1 | joe  |  400.00 ||  2 | she  |  600.00 ||  4 | kid  |  700.00 |+----+------+---------+\n\n打开一个客户端 B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到\n1234set session transaction isolation level serializable;mysql&gt; insert into account values(5,'tom',0);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\n\n\n\n查看隔离级别mysql默认的事务处理级别是’REPEATABLE-READ’,也就是可重复读\n\n查看当前会话隔离级别\n\nselect @@tx_isolation;\n\n查看系统当前隔离级别\n\nselect @@global.tx_isolation;\n\n设置当前会话隔离级别\n\nset session transaction isolatin level repeatable read;\n\n设置系统当前隔离级别\n\nset global transaction isolation level repeatable read;\n","plink":"https://spaco.github.io/post/mysql-transaction/"},{"title":"php-garbage-collection","date":"2018-12-09T00:00:00.000Z","updated":"2018-12-09T00:00:00.000Z","content":"Explains Garbage Collection (also known as GC) of PHPPHP LanguagePHP 是脚本语言，所谓脚本语言，就是说PHP并不是独立运行的，要运行PHP代码需要PHP解析器，用户编写的PHP代码最终都会被PHP解析器解析执行，PHP的执行是通过 Zend engine（ZE, Zend引擎），ZE是用C编写的，用户编写的PHP代码最终都会被翻译成PHP的虚拟机ZE的虚拟指令（OPCODES）来执行，也就说最终会被翻译成一条条的指令\n概念\nGarbage Collection : GC\n\nPHP 5.2以前, PHP使用引用计数(Reference counting)来做资源管理，PHP 5.3才引入GC\n\nzval  ：所有的变量都是用一个结构 zval 结构来保存的\n\nvalue : 值，是真正保存数据的关键部分，定义为一个联合体(union)\ntype : 储存变量的类型 \nis_ref ：被 &amp; 引用的数量\nrefcount ：引用计数，记录了当前的 zval 被引用的次数（这里的引用并不是真正的 &amp; ，而是有几个变量指向它）\n\n\nCopy On Write  \n\nChange On Write\n\n过程\nPHP5.2 : Reference Counting : 引用计数，GC根本算法\nPHP5.3 : Concurrent Cycle Collection in Reference Counted Systems\n\nfunction : memory_get_usage\n\nfunction : xdebug_debug_zval() : 需要安装xdebug\n\nfunction : debug_zval_dump  当不使用xdebug时，可以作为替代xdebug_debug_zval 的方法\n\n\nIntrodution\nzval\n声明一个变量\n1$addr = 'i value';\nPHP内部都是使用 zval 来表示变量的，那对于上面的脚本，ZE是如何把 $addr 变量 和内部的 zval 结构联系起来的呢？变量都是有名字的（本例中变量名为 $addr ），而 zval 中并没有相应的字段来体现变量名。PHP内部有一个机制，来实现变量名到 zval 的映射，在PHP中，所有的变量都会存储在一个 hash table中，当你创建一个变量的时候，PHP会为这个变量分配一个 zval，填入相应的信息，然后将这个变量的名字和指向这个 zval 的指针填入一个数组中。当你获取这个变量的时候，PHP会通过查找 hash table，取得对应的 zval\n注意：数组和对象这类复合类型在生成zval时，会为每个单元生成一个 zval\n\n\n\n\n释放内存\n我们经常说每个变量都有一个内存地址，那这个 zval 和变量的内存地址，这俩有什么关系吗？定义一个变量会开辟一块内存，这块内存好比一个盒子，盒子里放了zval，zval里保存了变量的相关信息，需要开辟多大的内存，是由zval所占空间大小决定的，zval是内存对象，垃圾回收的时候会把zval和内存地址（盒子）分别释放掉\n\nrefcount  is_ref\n123$a = 'string';$b = $a;unset($a);\n第一行代码创建变量 a ,申请了 6 字节内存，\n第二行代码定义了变量 b, 将 a 的值赋予 b\n第三行代码释放了变量 a\n如果对于每一个变量重新分配内存，那么变量 a b要申请 12 字节的内存，并且变量 a,还是个无用的数据（被unset了），那么有没有什么方法节省这块资源呢？将变量 a b对应的指针指向同一个 zval 即可\nrefcount\nrefcount 指的是变量被引用的次数（reference count ?）,这里的引用并不是真正的 &amp; ，而是有几个变量指向它\n12$a = 1;$b = $a;\n第一行，创建了一个变量 a，变量值是 1。 此时保存int 1 的这个 zval 的 refcount 为 1第二行，创建了一个新的整形变量（通过赋值的方式），变量也指向刚才创建的 zval，并将这个 zval 的 refcount 加1，此时这个 zval 的 refcount 为2所以，这个时候（通过值传递的方式赋值给别的变量），并没有产生新的 zval，两个变量指向同一 zval，通过一个计数器来共用 zval 及内存地址，以达到节省内存空间的目的当一个变量被第一次创建的时候，它对应的 zval 结构的 refcount 的值会被初始化为 1，因为只有这一个变量在用它。但是当你把这个变量赋值给别的变量时，refcount 属性便会 加1 变成 2，因为现在有两个变量在用这个 zval 结构了\n\ndebug_zval_dump\n1234$a = 1;debug_zval_dump($a);$b = $a;debug_zval_dump($a);\n输出：\n12long(1) refcount(2)long(1) refcount(3)\n如果你奇怪 ，var的refcount应该是1啊？我们知道，对于简单变量，PHP是以传值的形式传参数的。也就是说，当执行debug_zval_dump($var)的时候，var会以传值的方式传递给debug_zval_dump，也就是会导致var的refcount加1，所以只要能看到，当变量赋值给一个变量以后，能导致zval的refcount加 1\n例子：\n123456$a = 1;$b = $a;$c = $b;$d = $a;# long(1) refcount(5)debug_zval_dump($a);\n\nunset\n当 unset(var) 的时候，它删除符号表里的var的信息，准备清理它对应的zval及内存空间，这时它发现var对应的zval结构的 refcount 值是 &gt; 1，也就是说，还有另外一个变量在一起用着这个zval，所以unset只需把这个zval的refcount减去1就行了\n例子：\n123456$a = 1;$b = $a;unset($a);# long(1) refcount(2)debug_zval_dump($b);\n\nCopy On Write\n写入时复制是指：在 用变量对变量进行赋值时，这些相同值的变量指向同一块内存，只有当这些指向同一块内存的 相同值的变量 中的某一个变量的值 发生改变的时候，才需要进行变量分离，即：将 值发生改变的变量分离出来\n使用场景：变量的多次赋值；函数的参数传递。\nPHP中，Zend引擎为了区分同一块内存是否被多个变量引用，在zval结构中定义了ref_count和is_ref两个变量。\nref_count定义了内存被变量引用的次数，次数为0时销毁\nis_ref定义了变量是否被强制引用，被强制引用时，值为1\n1234$a = 1;$b = &amp;$a;$a 的 is_ref = 1;\n例子：\n12345678$a = 1;$b = $a;$a = 2;# long(2) refcount(2)debug_zval_dump($a);# long(1) refcount(2)debug_zval_dump($b);\nPHP在修改一个变量以前，会首先查看这个变量的refcount，如果refcount大于1，PHP就会执行一个分离的过程（在Zend引擎中，分离是破坏一个引用对的过程）对于上面的代码，当执行到第三行的时候，PHP发现var想要改变，并且它指向的zval的refcount大于1，那么PHP就会复制一个新的zval出来，改变其值，将改变的变量指向新的zval（，并将原zval的refcount减1，并修改symbol_table里该变量的指针，使得 a 和 b 分离(Separation)。这个机制就是所谓的copy on write（写时复制，这里的写包括普通变量的修改及数组对象里的增加、删除单元操作）\n\nChange On Write\n使用变量复制的时候 ，PHP内部并不是真正的复制，而是采用指向相同的zval结构来节约开销。那么，对于PHP中的引用，又是如何实现呢\n123456$a = 1;$reference = &amp;$a;$a = 2;# refcount(2)  is_ref(1)xdebug_debug_zval( 'a' );\n代码运行结果，$a 会被改为 2, 这个过程叫做 change on write, ZE 如何得知是否采用 Separation ？这个需要用到 \n$a 的 is_ref属性，它代表是否被 &amp; 引用，变量的 is_ref 默认为 0 ，大于 0则表示被引用，当 is_ref &gt; 0 或者 refcount = 1,此时不需要 Separation，而是直接修改 zval 的值\n123if($if_ref || $refcount = 1)&#123;    # alter zval instead of Separation&#125;\n尽管已经存在写时复制和写时改变，但仍然还存在一些不能通过is_ref和refcount来解决的问题\n123$var = 1;$var_dup = $a;$var_ref = &amp;$var;\n当执行第二行代码的时候,变量的值必须分离成两份完全独立的存在，也就是说php将一个zval的isref从0设为1之前，当然此时refcount还没有增加，会看该zval的refcount，如果refcount&gt;1，则会分离, 将var_dup分离出去，并将var和var_ref做change on write关联。也就是，refcount=2, is_ref=1.所以内存会给变量var_dup 分配出一个新的zval，类型与值同 var和var_ref指向的zval一样，是新分配出来的，尽管他们拥有同样的值，但是必须通过两个zval来实现。试想一下，如果三者指向同一个zval的话，改变 $vardup的值，那么var和 var_ref 也会受到影响，这样是错误的\n\n类似的：\n123$a = 1;$b = &amp;$a;$c = $a;\n\n\ndebug_zval_dump 参数是引用的话，refcount永远为1\n12345$a = 1;$b = &amp;$a;# long(1) refcount(1)debug_zval_dump($a);\nPHP先看变量指向的zval是否被引用，如果是引用，则不再产生新的zval甭管哪个变量引用了它，比如有个变量a被引用了，b=&amp;a，就算自己引用自己a=&amp;a，a所指向的zval都不会被复制，改变其中一个变量的值，另一个值也被改变（change on write）如果is_ref为0且refcount大于1，改变其中一个变量时，复制新的zval（copy on write）\n\n\nReference CountingPHP5.2中使用的内存回收算法是Reference Counting，中文叫做“引用计数”，其思想非常直观和简洁：为每个内存对象分配一个计数器，当一个内存对象建立时计数器初始化为1（因此此时总是有一个变量引用此对象），以后每有一个新变量引用此内存对象，则计数器加1，而每当减少一个引用此内存对象的变量则计数器减1，当垃圾回收机制运作的时候，将所有计数器为0的内存对象销毁并回收其占用的内存。而PHP中内存对象就是zval，而计数器就是refcount。\nImportant : Reference Counting Basics\n出现的问题 ： 引用的值为变量自身，内存泄漏 -&gt; 泄露实例\n123$a = array( 'one' );$a[] =&amp; $a;xdebug_debug_zval( 'a' );\n12345# 类似如下a: (refcount=2, is_ref=1)=array (   0 =&gt; (refcount=1, is_ref=0)='one',   1 =&gt; (refcount=2, is_ref=1)=...)\n图示：\n\n能看到数组变量 (a) 同时也是这个数组的第二个元素(1) 指向的变量容器中“refcount”为 2。上面的输出结果中的”…”说明发生了递归操作, 显然在这种情况下意味着”…”指向原始数组。\n跟刚刚一样，对一个变量调用unset，将删除这个符号，且它指向的变量容器中的引用次数也减1。所以，如果我们在执行完上面的代码后，对变量 a 调用unset, 那么变量 $a 和数组元素 “1” 所指向的变量容器的引用次数减1, 从”2”变成”1”. 下例可以说明:\n12345678unset($a);xdebug_debug_zval( 'a' );(refcount=1, is_ref=1)=array (   0 =&gt; (refcount=1, is_ref=0)='one',   1 =&gt; (refcount=1, is_ref=1)=...)\n\n清理变量容器的问题(Cleanup Problems)尽管不再有某个作用域中的任何符号指向这个结构(就是变量容器)，由于数组元素“1”仍然指向数组本身，所以这个容器不能被清除 。因为没有另外的符号指向它，用户没有办法清除这个结构，结果就会导致内存泄漏。庆幸的是，php将在脚本执行结束时清除这个数据结构，但是在php清除之前，将耗费不少内存。如果你要实现分析算法，或者要做其他像一个子元素指向它的父元素这样的事情，这种情况就会经常发生。当然，同样的情况也会发生在对象上，实际上对象更有可能出现这种情况，因为对象总是隐式的被引用。\n如果上面的情况发生仅仅一两次倒没什么，但是如果出现几千次，甚至几十万次的内存泄漏，这显然是个大问题。这样的问题往往发生在长时间运行的脚本中，比如请求基本上不会结束的守护进程(deamons)或者单元测试中的大的套件(sets)中。后者的例子：在给巨大的eZ(一个知名的PHP Library) 组件库的模板组件做单元测试时，就可能会出现问题。有时测试可能需要耗用2GB的内存，而测试服务器很可能没有这么大的内存。\n###回收周期(Collecting Cycles)\nPHP5.3的垃圾回收算法仍然以引用计数为基础，但是不再是使用简单计数作为回收准则，而是使用了一种同步回收算法，这个算法由IBM的工程师在论文Concurrent Cycle Collection in Reference Counted Systems中提出。 \n首先PHP会分配一个固定大小的“根缓冲区”，这个缓冲区用于存放固定数量的zval，这个数量默认是10,000，如果需要修改则需要修改源代码Zend/zend_gc.c中的常量GC_ROOT_BUFFER_MAX_ENTRIES然后重新编译。\n由上文我们可以知道，一个zval如果有引用，要么被全局符号表中的符号引用，要么被其它表示复杂类型的zval中的符号引用。因此在zval中存在一些可能根（root）。这里我们暂且不讨论PHP是如何发现这些可能根的，这是个很复杂的问题，总之PHP有办法发现这些可能根zval并将它们投入根缓冲区。\n当根缓冲区满额时，PHP就会执行垃圾回收，此回收算法如下：\n\n对每个根缓冲区中的根 zval 按照深度优先遍历算法遍历所有能遍历到的 zval ，并将每个 zval 的 refcount 减1，同时为了避免对同一 zval 多次减1（因为可能不同的根能遍历到同一个 zval ），每次对某个zval减1后就对其标记为“已减”。\n\n再次对每个缓冲区中的根 zval 深度优先遍历，如果某个 zval 的 refcount 不为0，则对其加1，否则保持其为0。\n\n清空根缓冲区中的所有根（注意是把这些 zval 从缓冲区中清除而不是销毁它们），然后销毁所有 refcount 为0的zval，并收回其内存。\n\n\n如果不能完全理解也没有关系，只需记住PHP5.3的垃圾回收算法有以下几点特性：\n\n并不是每次 refcount 减少时都进入回收周期，只有根缓冲区满额后在开始垃圾回收。\n\n可以解决循环引用问题。\n\n可以总将内存泄露保持在一个阈值以下。\n\n\nPHP 5.2 与 PHP 5.3 垃圾回收算法的性能比较参考 PHP Manual\nReferences\nPHP Manual GC\n\nzval _ 引用计数 _ 变量分离 _ 写时拷贝\n\n浅谈PHP5中垃圾回收算法(Garbage Collection)的演化\n\n\n","plink":"https://spaco.github.io/post/php-garbage-collection/"},{"title":"recommended-software-install","date":"2018-12-08T00:00:00.000Z","updated":"2018-12-08T00:00:00.000Z","content":"macprogram development\nnavicat\n\njetbrains\n\npostman\napi 调试工具\n\ntransmit \n ftp 工具\n\nsiteSucker\n爬站\n\nrds\nredis 客户端工具\n\nswithhost\n切换 hosts ,解决了来回切换测试 正式环境的问题\n\ngo2Shell\n\niterm2\niterm2 + go2shell 在 finder中打开当年目录的 bash ,可定制主题\n\n收到\n\n\nextra\nAlfred\n\ntypora\n\nPaste\n保存每次复制内容\n\nthe  Unarchiver\n解压缩软件\n\n\n\nwindowsprogram development\nnavicat\n\njetbrains\n\npostman\napi 调试工具\n\nrds\nredis 客户端工具\n\nswithhost\n切换 hosts ,解决了来回切换测试 正式环境的问题\n\n\nextra- \n","plink":"https://spaco.github.io/post/recommended-software-install/"},{"title":"zsh","date":"2018-12-05T00:00:00.000Z","updated":"2018-12-05T00:00:00.000Z","content":"##Install zsh(oh-my-zsh) &amp;&amp; plugins &amp;&amp; themes\nzsh (oh-my-zsh)Why zsh样式不错 插件多 \nInstallzsh-github\n1sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\nPluginsEnabling PluginsOnce you spot a plugin (or several) that you’d like to use with Oh My Zsh, you’ll need to enable them in the .zshrc file. You’ll find the zshrc file in your $HOME directory. Open it with your favorite text editor and you’ll see a spot to list all the plugins you want to load.\n123vi ~/.zshrc# For example, this might begin to look like this:plugins=(git autojump zsh-autosuggestions zsh-syntax-highlighting)\n###Plugin recommendation\ngitBring your own\n####zsh-syntax-highlighting\n\nGithub\n\n1234567git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting# update ~/.zshrc pluginsplugins=( [plugins...] zsh-syntax-highlighting) # refresh ~/.zshrc source ~/.zshrc\nzsh-autosuggestion\nGithub\n\n1234567git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions# update ~/.zshrc pluginsplugins=( [plugins...] zsh-autosuggestions) # refresh ~/.zshrc source ~/.zshrc\nGit-open1234567git clone https://github.com/paulirish/git-open.git $ZSH_CUSTOM/plugins/git-open# update ~/.zshrc pluginsplugins=( [plugins...] git-open) # refresh ~/.zshrc source ~/.zshrc\nThemesyspyenv\nbrew\n npm cnpm\nhttps://github.com/pyenv/pyenv#basic-github-checkout\n","plink":"https://spaco.github.io/post/zsh/"},{"title":"mq-introduction","date":"2018-11-23T00:00:00.000Z","updated":"2018-11-23T00:00:00.000Z","content":"MQ 简述什么是MQ消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它。\n主流MQ\nActiveMQ\nRabbitMQ\nKafka\nRocketMQ\nZeroMQ\n\n\n应用场景当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。\n\n异步处理\n应用解耦\n流量削峰\n其他\n\n使用与否\n使用\n\n譬如\n过安检，检测器处理能力有限，同时这些行李又不能丢了，加了个传送带，慢慢过检测器。其实这个传送带就是消息队列\n用户下单后，24小时未支付，需要取消订单。以前我们可能是定时任务循环查询，然后取消订单。实际上，我更推荐类似延迟MQ的方式，避免了很多无效的数据库查询，将一个MQ设置为24小时后才让消费者消费掉，这样很大程度上能减轻服务器压力\n帖子更新，关注者收到信息\n\n场景举例异步处理\n用户提交信息注册后，网站需要给用户发送邮件和短信\n\n传统做法\n将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端\n\n不考虑网络等其他开销，耗费时间150ms\n优化：\n引入消息队列，用户的响应时间相当于是注册信息写入数据库的时间，也就是50ms。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50ms。\n\n应用解耦\n凌晨进行数据统计task,这些task之间有一定的数据依赖关系\n\ntask3 需要使用task2的输出作为输入，task2 需要使用task1的输出作为输入，这样的话，tast1, task2, task3之间就有任务依赖关系，必须 task1 先执行，再 task2 执行，再 task3 执行。\n不使用MQ\n方案\ntask1，0:00 执行，经验执行时间为 50 分钟\ntask2，1:00 执行（为 task1 预留 10 分钟 buffer），经验执行时间也是 50 分钟\ntask3，2:00 执行（为 task2 预留 10 分钟 buffer）\n\n\n\n\n\n问题\n如果有一个任务执行时间超过了预留 buffer 的时间，将会得到错误的结果\n总任务的执行时间变长，总是要预留很多 buffer，如果前置任务提前完成，后置任务不会提前开始\n如果有一个任务的执行时间要调整，将会有多个任务的执行时间要调整\n\n\n\n使用MQ\n方案\ntask1 准时开始，结束后发一个“task1 done”的消息\ntask2 订阅 “task1 done” 的消息，收到消息后第一时间启动执行，结束后发一个 “task2 done” 的消息\ntask3 订阅 “task2 done” 的消息，收到消息后第一时间启动执行\n\n\n优点\n不需要预留 buffer，上游任务执行完，下游任务总会在第一时间被执行\n依赖多个任务，被多个任务依赖都很好处理，只需要订阅相关消息即可\n有任务执行时间变化，下游任务都不需要调整执行时间\n\n\n\nMQ只用来传递上游任务执行完成的消息，并不用于传递真正的输入输出数据。\n流量削峰\n系统A一天中大部分时间每秒请求并发数量就 100 多个，但是中午12点-1点每秒请求并发量就飙升到 10000 多个，但是系统每秒最大能处理的请求量只有 1000 多\n秒杀业务：上游发起下单操作,下游完成秒杀业务逻辑（库存检查，库存冻结，余额检查，余额冻结，订单生成，余额扣减，库存扣减，生成流水，余额解冻，库存解冻）上游下单业务简单，每秒发起了10000个请求，下游秒杀业务复杂，每秒只能处理2000个请求，很有可能上游不限速的下单，导致下游系统被压垮\n\n不使用MQ过大流量引起服务器崩溃\n使用MQ\n将非即时处理的业务逻辑进行异步化\n实例某电商网站新手机发布在即，拥有预约码的用户可优先购买手机。预约方式为：注册账户即可获得预约码，预计预约用户超过1000万\n像双11秒杀、手机预约抢购等对 IO 时延敏感业务环境下，当外部请求超过系统处理能力时，如果系统没有做相应保护，可能由于历史累计的超时请求负荷过多而导致系统处理的每个请求都因超时而无效，系统对外呈现的服务能力为 0，且这种情况下服务不能自动恢复。\n\n这种情形下，引入MQ，将非即时处理的业务逻辑进行异步化。比如服务接收请求、处理请求和返回请求三个不同的业务逻辑。\n引入 MQ 后，当预约活动开始时，海量并发访问汹涌袭来：\n\n所有客户的预约申请，页面均立即返回成功。客户便可关闭网页进行其他活动。预约码稍后推送到客户的邮箱/手机；\n\n超过千万级别的注册、预约申请，先暂存在 MQ 消息队列集群；\n\n后端服务进行处理，按照数据库实际的select、insert、update能力处理注册、预约申请；\n\n处理成功后返回结果给用户。预约结束后，用户大约在5-30min内，都收到了预约码。\n\n\n引入MQ带来的问题\n可用性降低 系统引入的外部依赖越多，越容易挂掉，MQ 挂掉之后会导致整个系统不可用。\n\n复杂度提高 重复消费、消息丢失、消息的顺序性等这些都是引入 MQ 之后需要考虑的事情\n\n一致性问题 \nA 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，就会导致数据不一致\n\n\n参考\nMQ消息队列选型\n\n\n","plink":"https://spaco.github.io/post/mq-introduction/"},{"title":"api-gateway-introduction","date":"2018-10-23T00:00:00.000Z","updated":"2018-10-23T00:00:00.000Z","content":"API GatewayForeword在非技术术语中，“网关或门是进入一个由墙围住的封闭空间的入口点。”同理，API网关是指位于防火墙或互联网后面的服务的入口点。在微服务的世界中，网关坐镇于API前面，直接面向客户并进行反向代理。\nPros and cons of using API gateways\n好处：降低构建微服务的复杂性；微服务模拟与虚拟化\n弊端：在架构上需要额外考虑更多编排与管理；路由逻辑配置要进行统一的管理\n网关会为端到端响应时间带来额外的延迟。\n潜在的性能瓶颈\n如果没有明智地选择网关，将会增加额外的运营开销和成本\n\n\n\nCommon GatewaysZuul\nKong\n","plink":"https://spaco.github.io/post/api-gateway-introduction/"},{"title":"kafka-build-with-docker-compose","date":"2018-10-05T00:00:00.000Z","updated":"2018-10-05T00:00:00.000Z","content":"Build Kafka with docker-composeKafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。此外，Kafka可以通过Kafka Connect连接到外部系统（用于数据输入/输出），并提供了Kafka Streams——一个Java流式处理库 (计算机)\nKafka是一个分布式的、高吞吐量、高可扩展性的消息系统。Kafka 基于发布/订阅模式，通过消息解耦，使生产者和消费者异步交互，无需彼此等待。Ckafka 具有数据压缩、同时支持离线和实时数据处理等优点，适用于日志压缩收集、监控数据聚合等场景\nprecondition\nkafka\n\nkafka-manager\n\nzookeeper\n本次测试 docker 已安装kafka zookeeper kafaka-manager,不讲述具体安装流程，如何安装查看结尾docker-compose.yml既可\n\n\n关键名词\nbroker：kafka集群包含一个或者多个服务器，服务器就称作broker\nproducer：负责发布消息到broker\nconsumer：消费者，从broker获取消息\ntopic：发布到kafka集群的消息类别。\npartition：每个topic划分为多个partition。\ngroup：每个partition分为多个group\n\n可用性测试   后续bash: –zookeeper ZookeeperName ： ZookeeperName指的是本地zookeeper的名字\n\n进入指定kafka容器\n1docker-compose exec kafka bash\n\n创建topic\n12345# cd KAFKA_HOME/bin/cd /opt/kafka_2.11-2.0.1/bin/kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 --partitions 1 --topic X# Created topic \"send-register-sms\".\n\n查看创建的topic\n1234# 查看zookeeper topicskafka-topics.sh --list --zookeeper zookeeper:2181# 查看某个topickafka-topics.sh --zookeeper zookeeper:2181 --describe --topic send-register-sms\n\n发送信息\n123kafka-console-producer.sh --broker-list localhost:9092 --topic=x&#123;\"phone\":\"17626041111\"&#125;\n\n新窗口接收信息\n1234567# cd KAFKA_HOME/bin/cd /opt/kafka_2.11-2.0.1/bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic x# 当出现发送的消息  success~&#123;\"phone\":\"17626041111\"&#125;\n 这个时候每次断开，再次bash进入消费的时候，会拉取所有的消息，而我们需要获取从断开点之后创建的信息\n1kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic test --consumer-property group.id=group1\n消费组\n\n\nreference\n使用Docker快速搭建Kafka开发环境\nkafka-python重复消费的问题\nkafka系列-进阶篇之消费组\nPython操作分布式流处理系统Kafka\n\n\nQAQ\nWARN [Producer clientId=console-producer] Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\ndocker-compose.yml kafka设置的 KAFKA_ADVERTISED_HOST_NAME 问题，改成 bash: ipconfig getifaddr en0  显示的ip值即可\n123REAL_IP = ipconfig getifaddr en0kafka \tKAFKA_ADVERTISED_HOST_NAME: REAL_IP\n\n修改配置后 rebuild kafka 显示 kafka uses an image, skipping  (已经把zookeeper kafka-manager 关闭)\n12345## force createdocker-compose up -d --force-recreate kafkadocker-compose up -d --force-recreate zookeeperdocker-compose up -d kafka zookeeper\n\n本地连接不用的wifi 导致ip变化\n123456docker-compose stop kafka zookeeperdocker-compose rm kafka zookeeperdocker-compose up -d --force-recreate kafkadocker-compose up -d --force-recreate zookeeperdocker-compose up -d kafka zookeeper\n\nWARN [Consumer clientId=consumer-1, groupId=group1] 1 partitions have leader brokers without a matching listener, including [test-0] (org.apache.kafka.clients.NetworkClient)\n\n\nRemarks\ngroup_id 不需要配置，用户确定名称即可\n\ndocker-compose.yml\n12345678910111213141516171819202122232425262728293031### Zookeeper ################################################    zookeeper:      image: wurstmeister/zookeeper      container_name: zookeeper      restart: always      ports:        - \"2181:2181\"### Kafka ################################################        kafka:      image: wurstmeister/kafka      container_name: kafka      ports:        - \"9092:9092\"      environment:        KAFKA_ADVERTISED_HOST_NAME: 192.168.1.112        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181      volumes:        - /var/run/docker.sock:/var/run/docker.sock### Kafka-manager ################################################     kafka-manager:      image: sheepkiller/kafka-manager                      ports:          - \"9003:9000\"           environment:        ZK_HOSTS: zookeeper:2181        APPLICATION_SECRET: \"random-secret\"        KAFKA_MANAGER_AUTH_ENABLED: \"true\"        KAFKA_MANAGER_USERNAME: \"admin\"        KAFKA_MANAGER_PASSWORD: \"secret\"\n\n\ndrwxr-xr-x@  26 ashe  staff   832B Dec  6 20:40 cache\n","plink":"https://spaco.github.io/post/kafka-build-with-docker-compose/"},{"title":"kafka-case-with-python","date":"2018-10-05T00:00:00.000Z","updated":"2018-10-05T00:00:00.000Z","content":"Kafka in pythonBuild kafkaenvironment\nkafka \n12find / -name \\*kafka_\\* | head -1 | grep -o '\\kafka[^\\n]*'kafka_2.11-2.0.1\n\npython\n12python -V    #use pyenv3.6.6\n\nzookeeper\n12345678910111213141516version:echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /172.23.0.1:41242[0](queued=0,recved=1,sent=0) /172.23.0.2:49830[1](queued=0,recved=1152,sent=1153)Latency min/avg/max: -33/0/91Received: 5129Sent: 5139Connections: 2Outstanding: 0Zxid: 0xa3Mode: standaloneNode count: 133\n\n\nTest\nInstall Python Client\nkafka-python 1.4.4\n1pip install kafka-python\n\nProducer\n1234567891011121314151617# coding=utf-8from kafka import KafkaProducerimport timeproducer = KafkaProducer(bootstrap_servers=['127.0.0.1:9092'])  #此处ip可以是多个['0.0.0.1:9092','0.0.0.2:9092','0.0.0.3:9092' ]topic_name = 'test'i=0while True:    ts = int(time.time() * 1000)    # msg = '&#123;\"phone\": 17626041117, \"extra-key\": \"extra-value\"&#125;'    msg = str(i)    print(msg)    producer.send(topic_name, msg.encode('utf-8'))  # 参数为主题和bytes数据    producer.flush()    i+=1                  time.sleep(2)\n运行：\n123456python producer.py0123\n\nconsumer\n\nbasic\n12345678910# coding=utf-8from kafka import KafkaConsumer, TopicPartitiontopic_name = 'test'groupid = 'group1'server_list = '127.0.0.1:9092'consumer = KafkaConsumer(topic_name,bootstrap_servers=server_list)for message in consumer:  print(message)\n运行：\n12345python consumer.pyConsumerRecord(topic=u'test', partition=0, offset=69, timestamp=1544090653375, timestamp_type=0, key=None, value='0', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=1, serialized_header_size=-1)ConsumerRecord(topic=u'test', partition=0, offset=70, timestamp=1544090655386, timestamp_type=0, key=None, value='1', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=1, serialized_header_size=-1)\n\n拉取未消费的信息：断开连接，再次bash进入消费的时候，会拉取所有的消息，而我们需要获取从断开点之后创建的信息\n1234567891011121314151617# coding=utf-8from kafka import KafkaConsumer, TopicPartitiontopic_name = 'test'groupid = 'group1'server_list = '127.0.0.1:9092'# offset                        consumer = KafkaConsumer(group_id=groupid,                         bootstrap_servers=server_list)partition = TopicPartition(topic_name, 0)consumer.assign([partition])print(\"start offset is \", consumer.position(partition))for message in consumer:  print(message)  file = open('consumer.log','a')  file.write(message.value + \"\\n\")\n运行：\n1python consumer.py\n\n\n\n\nreference\nkafka-python重复消费的问题\n\nPython脚本消费kafka数据\n\nPython操作分布式流处理系统Kafka\n\n\nQAQ\nvscode pip安装kafka 后，通过 iterm2 操作出现 ImportError: No module named kafka\n重装。。。\n\nkafka.errors.NoBrokersAvailable: NoBrokersAvailable\n指定的kafka host无效\n\n\nRemarks\ngroup_id 不需要配置，用户确定名称即可\n\n","plink":"https://spaco.github.io/post/kafka-case-with-python/"},{"title":"hexo-on-github-pages","date":"2018-09-01T00:00:00.000Z","updated":"2018-09-01T00:00:00.000Z","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartPrecondition\ngit : deploy to github\nnode.js : Hexo 基于 node.js开发的\n\nEnvironment\ngit \n123# versiongit --versiongit version 2.17.2 (Apple Git-113)\n\nnode.js\n123# versionnode -vv7.2.1\n\n\nInstall Hexo1npm install -g hexo-cli\nInit Hexo Folder1234mkdir spacocd spacohexo initnpm install\nRun server12hexo serverHexo is running at http://localhost:4000 . Press Ctrl+C to stop.\nCreate a new post1hexo new \"My New Post\"\nMore info: Writing\nRun server12hexo serverHexo is running at http://localhost:4000 . Press Ctrl+C to stop.\nMore info: Server\nReplace theme12345678910cd spaco/themesgit clone https://github.com/elmorec/hexo-theme-inside.git insidecd ../vim _config.yml# replace default theme to insidetheme: landscape =&gt; theme: insidehexo server# theme has changed\nDeploy to GitHubneed ssh-key already registered in GitHub\n\nCreate repostory\nyour_github_name.github.io\n\nDeployment config\n123456789vim _config.yml# like this# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:  type: git  repo: git@github.com:spaco/spaco.github.io.git  branch: master\n\n\nClean static files12hexo cleanhexo c\nGenerate static files12hexo generate # hexo g\nMore info: Generating\nDeploy to remote sites12hexo deploy# hexo d\nMore info: Deployment\nEffectiveopen your-page.github.io in the browser\nReplace domain nameReferencesgithub+Hexo搭建blog\n浅析 Hexo 搭建博客的原理\n","plink":"https://spaco.github.io/post/hexo-on-github-pages/"},{"title":"hexo-on-travis-CI","date":"2018-09-01T00:00:00.000Z","updated":"2018-09-01T00:00:00.000Z","content":"Quick Starttravis-ci 是什么一个使用yaml格式配置用于持续集成完成自动化测试部署的开源项目官网：https://travis-ci.com/\n为什么使用 travis-ci 部署 Hexo blog\n避免换电脑需要安装环境\n可以随时更改 blog 内容\n不喜欢每次 hexo g  + hexo d\n\n原理github 设置两个分支，master develop,\ntravis-ci 检测 develop 的改动，编译之后将需要的数据提交到 master\n涉及的主要内容\nGitHub-Pages\n\nTravis-CI 账号\n\ngithub token\ncoding 同样\n\n\nCreate GitHub token\n进入 github token，点击 Generate new token\n\n完善 Token description ，Select scopes\n\nsave\n\n\n\n同步github repository\n\n登陆 travis-ci\n\nhttps://travis-ci.com/account/repositories\n\n同步 repository\n点击 manage repositories on Github\n\n\n点击已同步 repository 右边的 setting\n\n配置 Environment Variables ：会在部署脚本中使用到\n\nGH_REF : github.com/spaco/spaco.github.io.git\nGH_TOKEN : 上个步骤获得的 github token\n\n\nGithub  repository setting以github一个空仓库为示范,但是已实现本地 blog 预览\n\ncreate develop branch\nset default branch = develop\n\nRun travis-ci运行 travis-ci，需要配置 .travis.yml ,默认检测此文件，详情见下方 Extra\n将 develop 编译之后的内容 提交到 master，现有如下几种方式\n\ncopy ssh key\ngithub token : master 永远只有一次 commit log\ngithub token : master commit log 保存 （推荐）\n\ngit push to develop , travis-ci run\n\nQAQ\nQ : 通过git clone theme,但是通过 travis-ci 自动部署的时候，无法提交 theme文件，因为theme所属另外一个 GitHub-repository\nA : 使用 git submodule clone theme \n123[submodule \"themes/inside\"]\tpath = themes/inside\turl = https://github.com/spaco/hexo-theme-inside.git\n\n\nExtra123456789101112131415161718192021222324252627282930language: node_jsnode_js: stable# S: Build Lifecycleinstall:- npm install#before_script:# - npm install -g gulpscript:  - hexo gafter_script:  - git clone https://$&#123;GH_REF&#125; .deploy_git  # GH_REF是最下面配置的仓库地址  - cd .deploy_git  - git checkout master  - cd ../  - mv .deploy_git/.git/ ./public/   # 这一步之前的操作是为了保留master分支的提交记录，不然每次git init的话只有1条commit  - cd ./public  - git config user.name \"spaco\"  - git config user.email \"she.ct@outlook.com\"  - git add .  - git commit -m \"Travis automatically updates the document\"  - git push --force --quiet \"https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master# E: Build LifeCyclebranches:  only:    - develop\n","plink":"https://spaco.github.io/post/hexo-on-travis-CI/"},{"title":"queue","date":"2018-08-20T00:00:00.000Z","updated":"2018-08-20T00:00:00.000Z","content":"Briefly introduce the principle of queues, the implementation of common programming languages\nQueueFIFO结构像栈一样，队列（queue）也是一种线性表，它的特性是先进先出，插入在一端，删除在另一端。就像排队一样，刚来的人入队（push）要排在队尾(rear)，每次出队(pop)的都是队首(front)\n队列（Queue）与栈一样，是一种线性存储结构，它具有如下特点：\n\n队列中的数据元素遵循     先进先出 （First In First Out）的原则，简称FIFO结构\n在队尾添加元素，在队头删除元素\n\n相关概念\n入队：队列的插入操作\n出队：队列的删除操作\n\n相关用途队列可以很好地异步处理数据传送和存储，当你频繁地向数据库中插入数据、频繁地向搜索引擎提交数据，就可采取队列来异步插入。另外，还可以将较慢的处理逻辑、有并发数量限制的处理逻辑，通过消息队列放在后台处理，例如FLV视频转换、发送手机短信、发送电子邮件等。\n图解\n入队 我们有一个存储整型元素的队列，我们依次入对：{1，2，3}\n\n\n\n出对\n\n\n\n","plink":"https://spaco.github.io/post/queue/"},{"title":"http-cache","date":"2018-08-05T00:00:00.000Z","updated":"2018-08-05T00:00:00.000Z","content":"","plink":"https://spaco.github.io/post/http-cache/"},{"title":"solr","date":"2018-06-13T00:00:00.000Z","updated":"2018-06-13T00:00:00.000Z","content":"","plink":"https://spaco.github.io/post/solr/"},{"title":"demo","date":"2015-08-20T00:00:00.000Z","updated":"2015-08-20T00:00:00.000Z","content":"Demo Demo\nQueueFIFO结构","plink":"https://spaco.github.io/post/demo/"},{"title":"demo","date":"2015-08-20T00:00:00.000Z","updated":"2015-08-20T00:00:00.000Z","content":"Demo Demo\nQueueFIFO结构","plink":"https://spaco.github.io/post/demo/"}]